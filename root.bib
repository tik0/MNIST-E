@article{LeCun2010,
abstract = {The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.},
author = {LeCun, Yann and Cortes, Corinna},
journal = {AT{\&}T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},
mendeley-groups = {data-sets},
title = {{MNIST handwritten digit database}},
year = {2010}
}
@inproceedings{Ofli2013,
abstract = {Over the years, a large number of methods have been proposed to analyze human pose and motion information from images, videos, and recently from depth data. Most methods, however, have been evaluated on datasets that were too specific to each application, limited to a particular modality, and more importantly, captured under unknown conditions. To address these issues, we introduce the Berkeley Multimodal Human Action Database (MHAD) consisting of temporally synchronized and geometrically calibrated data from an optical motion capture system, multi-baseline stereo cameras from multiple views, depth sensors, accelerometers and microphones. This controlled multimodal dataset provides researchers an inclusive testbed to develop and benchmark new algorithms across multiple modalities under known capture conditions in various research domains. To demonstrate possible use of MHAD for action recognition, we compare results using the popular Bag-of-Words algorithm adapted to each modality independently with the results of various combinations of modalities using the Multiple Kernel Learning. Our comparative results show that multimodal analysis of human motion yields better action recognition rates than unimodal analysis.},
author = {Ofli, Ferda and Chaudhry, Rizwan and Kurillo, Gregorij and Vidal, Rene and Bajcsy, Ruzena},
booktitle = {Proceedings of IEEE Workshop on Applications of Computer Vision},
doi = {10.1109/WACV.2013.6474999},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ofli et al. - 2013 - Berkeley MHAD A comprehensive Multimodal Human Action Database.pdf:pdf},
isbn = {9781467350532},
issn = {21583978},
mendeley-groups = {data-sets/multi-modal},
title = {{Berkeley MHAD: A comprehensive Multimodal Human Action Database}},
year = {2013}
}
@article{LeCun1998,
abstract = {The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.$\backslash$r$\backslash$nIt is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.},
author = {{LeCun Yann} and {Cortes Corinna} and {Burges Christopher}},
file = {:home/tkorthals/Documents/Mendeley Desktop/LeCun Yann, Cortes Corinna, Burges Christopher - 1998 - THE MNIST DATABASE of handwritten digits.pdf:pdf},
isbn = {7842500200015},
journal = {The Courant Institute of Mathematical Sciences},
mendeley-groups = {data-sets},
pmid = {1000253529},
title = {{THE MNIST DATABASE of handwritten digits}},
year = {1998}
}
@inproceedings{Calvet2016,
abstract = {Using fiducial markers ensures reliable detection and identification of planar features in images. Fiducials are used in a wide range of applications, especially when a reliable visual reference is needed, e.g., to track the camera in cluttered or textureless environments. A marker designed for such applications must be robust to partial occlusions, varying distances and angles of view, and fast camera motions. In this paper, we present a robust, highly accurate fiducial system, whose markers consist of concentric rings, along with its theoretical foundations. Relying on projective properties, it allows to robustly localize the imaged marker and to accurately detect the position of the image of the (common) circle center. We demonstrate that our system can detect and accurately localize these circular fiducials under very challenging conditions and the experimental results reveal that it outperforms other recent fiducial systems.},
author = {Calvet, Lilian and Gurdjos, Pierre and Griwodz, Carsten and Gasparini, Simone},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2016.67},
file = {:home/tkorthals/Documents/Mendeley Desktop/Calvet et al. - 2016 - Detection and Accurate Localization of Circular Fiducials under Highly Challenging Conditions.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {10636919},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
title = {{Detection and Accurate Localization of Circular Fiducials under Highly Challenging Conditions}},
year = {2016}
}
@misc{Wikipedia,
author = {Wikipedia},
mendeley-groups = {data-sets},
title = {{List of datasets for machine learning research}},
url = {https://en.wikipedia.org/wiki/List{\_}of{\_}datasets{\_}for{\_}machine{\_}learning{\_}research}
}
@article{kragh2017fieldsafe,
author = {Kragh, Mikkel Fly and Christiansen, Peter and Laursen, Morten Stigaard and Larsen, Morten and Steen, Kim Arild and Green, Ole and Karstoft, Henrik and J{\o}rgensen, Rasmus Nyholm},
journal = {Sensors},
mendeley-groups = {data-sets,data-sets/multi-modal},
number = {11},
title = {{FieldSAFE: Dataset for Obstacle Detection in Agriculture}},
volume = {17},
year = {2017}
}
@misc{,
file = {:home/tkorthals/Documents/Mendeley Desktop/LeCun Yann, Cortes Corinna, Burges Christopher - 1998 - THE MNIST DATABASE of handwritten digits.pdf:pdf},
title = {nistsd19.pdf}
}
@article{,
title = {{MNIST: Webpage}},
url = {http://yann.lecun.com/exdb/mnist/}
}
@misc{,
mendeley-groups = {data-sets},
title = {{Fahion-MNIST: Github}},
url = {https://github.com/zalandoresearch/fashion-mnist}
}
@article{Xiao2017,
abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
archivePrefix = {arXiv},
arxivId = {1708.07747},
author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
eprint = {1708.07747},
file = {:home/tkorthals/Documents/Mendeley Desktop/Xiao, Rasul, Vollgraf - 2017 - Fashion-MNIST a Novel Image Dataset for Benchmarking Machine Learning Algorithms.pdf:pdf},
mendeley-groups = {data-sets},
pages = {1--6},
title = {{Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}},
url = {http://arxiv.org/abs/1708.07747},
year = {2017}
}
@article{Manuscript2010,
author = {Manuscript, Author and Quality, Retinal Image},
doi = {10.1097/OPX.0b013e3181a76e6f.Retinal},
file = {:home/tkorthals/Documents/Mendeley Desktop/Manuscript, Quality - 2010 - Retinal Image Quality and Postnatal Visual Experience during Infancy.pdf:pdf},
keywords = {a large literature now,aberrations,accommodation,both the refinement of,development in animal models,emmetropization,experience leads to abnormal,infant,retinal image quality,suggests that abnormal visual,visual,visual experience,visual experience can influence},
mendeley-groups = {VAE/Neuroscience},
number = {6},
pages = {1--10},
title = {{Retinal Image Quality and Postnatal Visual Experience during Infancy}},
volume = {86},
year = {2010}
}
@article{Erichsmeier2018,
author = {Erichsmeier, Fabian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Erichsmeier - 2018 - Automatisierte Kalibrierung einer Robotiksimulation in Gazebo mittels Kameratracking(2).pdf:pdf},
mendeley-groups = {{\_}STUDENTEN},
number = {August},
title = {{Automatisierte Kalibrierung einer Robotiksimulation in Gazebo mittels Kameratracking}},
year = {2018}
}
@misc{udacity2016,
abstract = {A necessity in building an open source self-driving car is data. Lots and lots of data. We recently open sourced 40GB of driving data to assist the participants of the Udacity Self-Driving Car Challenge {\#}2, but now we're going much bigger with a 183GB release. This data is free for anyone to use, anywhere in the world. What's Included 223GB of image frames and log data from 70 minutes of driving in Mountain View on two separate days, with one day being sunny, and the other overcast. Here is a sample of the log included in the dataset. Note: Along with an image frame from our cameras, we also include latitude, longitude, gear, brake, throttle, steering angles and speed.},
author = {Udacity},
keywords = {udacity},
mendeley-groups = {data-sets,data-sets/multi-modal},
mendeley-tags = {udacity},
title = {{Self-Driving Car: Annotated Driving Dataset}},
url = {https://github.com/udacity/self-driving-car/tree/master/annotations},
urldate = {2018-09-21},
year = {2016}
}
@article{Perry2010,
abstract = {We show that spatial continuity can enable a network to learn translation invariant representations of objects by self-organization in a hierarchical model of cortical processing in the ventral visual system. During 'continuous transformation learning', the active synapses from each overlapping transform are associatively modified onto the set of postsynaptic neurons. Because other transforms of the same object overlap with previously learned exemplars, a common set of postsynaptic neurons is activated by the new transforms, and learning of the new active inputs onto the same postsynaptic neurons is facilitated. We show that the transforms must be close for this to occur; that the temporal order of presentation of each transformed image during training is not crucial for learning to occur; that relatively large numbers of transforms can be learned; and that such continuous transformation learning can be usefully combined with temporal trace training.},
author = {Perry, G. and Rolls, E. T. and Stringer, S. M.},
doi = {10.1007/s00221-010-2309-0},
file = {:home/tkorthals/Documents/Mendeley Desktop/Perry, Rolls, Stringer - 2010 - Continuous transformation learning of translation invariant representations.pdf:pdf},
isbn = {1432-1106 (Electronic)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Continuous transformation,Inferior temporal cortex,Invariant representations,Object recognition,Trace learning},
mendeley-groups = {VAE/Neuroscience},
number = {2},
pages = {255--270},
pmid = {20544186},
title = {{Continuous transformation learning of translation invariant representations}},
volume = {204},
year = {2010}
}
@unpublished{Sullivan2018,
author = {Sullivan, Jan O},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sullivan - 2018 - Potential Field Navigation.pdf:pdf},
keywords = {Projekt Biomechatronisches Praktikum},
mendeley-groups = {{\_}STUDENTEN},
number = {August},
pages = {1--9},
title = {{Potential Field Navigation}},
year = {2018}
}
@article{Hinton1994,
abstract = {An autoencoder network uses a aset of recognition weights to convert the input veecotre into a code vectore. It then uses set of generative weights to convert the code vector inot an approximate reconstruction of the input vector. We derive and objective function for training autoencoderss based on the minimum descrption length (MDL) principle. The aim is to minimize the information required to describe both the code vector and the reconsrtuction error. WE show that this information is minimzed by choosing code vectors stochastiacally according to a Boltzmann distribution, where the generative weights define the energy of each possible code vector given the input vector. Unfortunately, if the code vectors use distributed representations, it is exponentially expensive to compute this Boltzmann distribution because it involves all possible code vectors. We show that the recognition weights of an autoencoder can be used to compute an approximation to the Boltzmann distribution and that this approixmation gives an upper bound on the description length. Even hen this bound is poor, it can be used a Lyapuov function for learning both the generative and recognition weights. We demonstrate that this approach can be used to learn factorial codes.},
author = {Hinton, Geoffrey E. and Zemel, Richard S.},
doi = {10.1021/jp906511z},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hinton, Zemel - 1994 - Autoencoders, Minimum Description Length and Helmholtz free Energy.pdf:pdf},
isbn = {1049-5258},
issn = {15205207},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {VAE/Whats More/Auto Encoder},
number = {3},
pages = {--},
pmid = {20148535},
title = {{Autoencoders, Minimum Description Length and Helmholtz free Energy}},
url = {https://www.cs.toronto.edu/{~}hinton/absps/cvq.pdf},
volume = {3},
year = {1994}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories - optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.02142v2},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
eprint = {arXiv:1507.02142v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Friston - 2010 - The free-energy principle A unified brain theory.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
mendeley-groups = {VAE/Neuroscience},
number = {2},
pages = {127--138},
pmid = {20068583},
publisher = {Nature Publishing Group},
title = {{The free-energy principle: A unified brain theory?}},
url = {http://dx.doi.org/10.1038/nrn2787},
volume = {11},
year = {2010}
}
@article{Pandey2016,
abstract = {In this paper, we address the problem of conditional modality learning, whereby one is interested in generating one modality given the other. While it is straightforward to learn a joint distribution over multiple modalities using a deep multimodal architecture, we observe that such models aren't very effective at conditional generation. Hence, we address the problem by learning conditional distributions between the modalities. We use variational methods for maximizing the corresponding conditional log-likelihood. The resultant deep model, which we refer to as conditional multimodal autoencoder (CMMA), forces the latent representation obtained from a single modality alone to be `close' to the joint representation obtained from multiple modalities. We use the proposed model to generate faces from attributes. We show that the faces generated from attributes using the proposed model, are qualitatively and quantitatively more representative of the attributes from which they were generated, than those obtained by other deep generative models. We also propose a secondary task, whereby the existing faces are modified by modifying the corresponding attributes. We observe that the modifications in face introduced by the proposed model are representative of the corresponding modifications in attributes.},
archivePrefix = {arXiv},
arxivId = {1603.01801},
author = {Pandey, Gaurav and Dukkipati, Ambedkar},
doi = {10.1109/IJCNN.2017.7965870},
eprint = {1603.01801},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pandey, Dukkipati - 2017 - Variational methods for conditional multimodal deep learning.pdf:pdf},
isbn = {9781509061815},
journal = {Proceedings of the International Joint Conference on Neural Networks},
keywords = {autoencoder,multimodal,variational},
mendeley-groups = {VAE/Multi-Modal},
pages = {308--315},
title = {{Variational methods for conditional multimodal deep learning}},
volume = {2017-May},
year = {2017}
}
@incollection{NIPS2015_5775,
abstract = {Supervised deep learning has been successfully applied for many recognition problems in machine learning and computer vision. Although it can approximate a complex many-to-one function very well when large number of training data is provided, the lack of probabilistic inference of the current supervised deep learning methods makes it difficult to model a complex structured output representations. In this work, we develop a scalable deep conditional generative model for structured output variables using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows a fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build a robust structured prediction algorithms, such as recurrent prediction network architecture, input noise-injection and multi-scale prediction training methods. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic output representations using stochastic inference. Furthermore, the proposed schemes in training methods and architecture design were complimentary, which leads to achieve strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.},
author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {Cortes, C and Lawrence, N D and Lee, D D and Sugiyama, M and Garnett, R},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sohn, Lee, Yan - 2015 - Learning Structured Output Representation using Deep Conditional Generative Models.pdf:pdf},
keywords = {CVAE},
mendeley-groups = {VAE/Multi-Modal},
mendeley-tags = {CVAE},
pages = {3483--3491},
publisher = {Curran Associates, Inc.},
title = {{Learning Structured Output Representation using Deep Conditional Generative Models}},
year = {2015}
}
@article{Denzler2002,
abstract = {—We introduce a formalism for optimal sensor parameter selection for iterative state estimation in static systems. Our optimality criterion is the reduction of uncertainty in the state estimation process, rather than an estimator-specific metric (e.g., minimum mean squared estimate error). The claim is that state estimation becomes more reliable if the uncertainty and ambiguity in the estimation process can be reduced. We use Shannon's information theory to select information-gathering actions that maximize mutual information, thus optimizing the information that the data conveys about the true state of the system. The technique explicitly takes into account the a priori probabilities governing the computation of the mutual information. Thus, a sequential decision process can be formed by treating the a priori probability at a certain time step in the decision process as the a posteriori probability of the previous time step. We demonstrate the benefits of our approach in an object recognition application using an active camera for sequential gaze control and viewpoint selection. We describe experiments with discrete and continuous density representations that suggest the effectiveness of the approach.},
author = {Denzler, Joachim and Brown, Christopher M},
doi = {10.1109/34.982896},
file = {:home/tkorthals/Documents/Mendeley Desktop/Denzler, Brown - 2002 - Information theoretic sensor data selection for active object recognition and state estimation.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
keywords = {Index Terms—Computer vision,active camera control,information theory,state estimation},
mendeley-groups = {Robotics/Active Sensing},
number = {2},
pages = {145--157},
title = {{Information theoretic sensor data selection for active object recognition and state estimation}},
volume = {24},
year = {2002}
}
@inproceedings{korthals2018_2,
abstract = {We investigate a reinforcement approach for distributed sensing based on the latent space derived from multi-modal deep generative models. Our contribution provides insights to the following benefits: Detections can be exchanged effectively between robots equipped with uni-modal sensors due to a shared latent representation of information that is trained by a Variational Auto Encoder (VAE). Sensor-fusion can be applied asynchronously due to the generative feature of the VAE. Deep Q-Networks (DQNs) are trained to minimize uncertainty in latent space by coordinating robots to a Point-of-Interest (PoI) where their sensor modality can provide beneficial information about the PoI. Additionally, we show that the decrease in uncertainty can be defined as the direct reward signal for training the DQN.},
archivePrefix = {arXiv},
arxivId = {arXiv:1809.04558v1},
author = {Korthals, Timo and Leitner, J{\"{u}}rgen and R{\"{u}}ckert, Ulrich},
booktitle = {IROS 2018 Second Workshop on Multi-robot Perception-Driven Control and Planning},
eprint = {arXiv:1809.04558v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals, Leitner, R{\"{u}}ckert - 2018 - Coordinated Heterogeneous Distributed Perception based on Latent Space Representation.pdf:pdf},
keywords = {Deep Generative Models,Distributed Sensor Network,Multi-Robotic,Sensor Fusion},
mendeley-tags = {Deep Generative Models,Distributed Sensor Network,Multi-Robotic,Sensor Fusion},
title = {{Coordinated Heterogeneous Distributed Perception based on Latent Space Representation}},
url = {https://arxiv.org/abs/1809.04558},
year = {2018}
}
@article{Mihaylova2002,
abstract = {This work surveys the major methods for model-based active sensing in robotics. Active sensing in robotics incorporates the following aspects: (i) where to position sensors, and (ii) how to make decisions for next actions, in order to maximize information gain and minimize costs. We concentrate on the second aspect: “Where should the robot move at the next time step?”. The emphasis here is on Bayesian solutions to this problem. Pros and cons of the major methods are discussed. Special attention is paid to different criteria for decision making.},
author = {Mihaylova, L and Lefebvre, T and Bruyninckx, H and Gadeyne, K and Schutter, J De},
doi = {10.1.1.18.5320},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mihaylova et al. - 2002 - Active Sensing for Robotics – A Survey.pdf:pdf},
journal = {Robotics},
keywords = {Model,active,based,costs,low cost,minimize,sensing,sensors},
mendeley-groups = {Robotics/Active Sensing,Robotics/Active Sensing/Survey},
pages = {1--8},
title = {{Active Sensing for Robotics – A Survey}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5320},
year = {2002}
}
@article{Borotschnig2000,
abstract = {We present an efficient method within an active vision framework for recognizing objects which are ambiguous from certain viewpoints. The system is allowed to reposition the camera to capture additional views and, therefore, to improve the classification result obtained from a single view. The approach uses an appearance based object representation, namely the parametric eigenspace, and augments it by probability distributions. This enables us to cope with possible variations in the input images due to errors in the pre-processing chain or changing imaging conditions. Furthermore, the use of probability distributions gives us a gauge to perform view planning. Multiple observations lead to a significant increase in recognition rate. Action planning is shown to be of great use in reducing the number of images necessary to achieve a certain recognition performance when compared to a random strategy. Keywords: action planning, object recognition, information fusion, parametric eigenspace,...},
author = {Borotschnig, H. and Paletta, L. and Prantl, M. and Pinz, A.},
doi = {10.1016/S0262-8856(99)00075-X},
file = {:home/tkorthals/Documents/Mendeley Desktop/Borotschnig et al. - 2000 - Appearance-based active object recognition.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {action planning,information fusion,object recognition,parametric eigenspace,probability theory},
mendeley-groups = {Robotics/Active Sensing},
number = {9},
pages = {715--727},
title = {{Appearance-based active object recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S026288569900075X},
volume = {18},
year = {2000}
}
@article{Kreucher2005,
abstract = {An approach that is common in the machine learning literature, known as active sensing, is applied to provide a method for managing agile sensors in a dynamic environment. We adopt an active sensing approach to scheduling sensors for multiple target tracking applications that combines particle filtering, predictive density estimation, and relative entropy maximization. Specifically, the goal of the system is to learn the number and states of a group of moving targets occupying a surveillance region. At each time step, the system computes a sensing action to take, based on an entropy measure called the R{\'{e}}nyi divergence. After the measurement is made, the system updates its probability density on the number and states of the targets. This procedure repeats at each time where a sensor is available for use. The algorithms developed here extend standard active sensing methodology to dynamically evolving objects and continuous state spaces of high dimension. It is shown using simulated measurements on real recorded target trajectories that this method of sensor management yields more than a ten fold gain in sensor efficiency when compared to periodic scanning. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Kreucher, Chris and Kastella, Keith and Hero, Alfred O.},
doi = {10.1016/j.sigpro.2004.11.004},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kreucher, Kastella, Hero - 2005 - Sensor management using an active sensing approach.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Active sensing,Joint multitarget probability density,Machine learning,Multitarget tracking,Particle filtering,Sensor management},
mendeley-groups = {Robotics/Active Sensing},
number = {3},
pages = {607--624},
title = {{Sensor management using an active sensing approach}},
volume = {85},
year = {2005}
}
@inproceedings{Larochelle:2007:EED:1273496.1273556,
address = {New York, NY, USA},
author = {Larochelle, Hugo and Erhan, Dumitru and Courville, Aaron and Bergstra, James and Bengio, Yoshua},
booktitle = {Proceedings of the 24th International Conference on Machine Learning},
doi = {10.1145/1273496.1273556},
file = {:home/tkorthals/Documents/Mendeley Desktop/Larochelle et al. - 2007 - An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation.pdf:pdf},
isbn = {978-1-59593-793-3},
mendeley-groups = {VAE/Whats More/Auto Encoder},
pages = {473--480},
publisher = {ACM},
series = {ICML '07},
title = {{An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation}},
url = {http://doi.acm.org/10.1145/1273496.1273556},
year = {2007}
}
@inproceedings{Ranzato:2006:ELS:2976456.2976599,
address = {Cambridge, MA, USA},
author = {Ranzato, Marc'Aurelio and Poultney, Christopher and Chopra, Sumit and LeCun, Yann},
booktitle = {Proceedings of the 19th International Conference on Neural Information Processing Systems},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ranzato et al. - 2006 - Efficient Learning of Sparse Representations with an Energy-based Model.pdf:pdf},
mendeley-groups = {VAE/Whats More/Auto Encoder},
pages = {1137--1144},
publisher = {MIT Press},
series = {NIPS'06},
title = {{Efficient Learning of Sparse Representations with an Energy-based Model}},
url = {http://dl.acm.org/citation.cfm?id=2976456.2976599},
year = {2006}
}
@article{Heess2017,
abstract = {The reinforcement learning paradigm allows, in principle, for complex behaviours to be learned directly from simple reward signals. In practice, however, it is common to carefully hand-design the reward function to encourage a particular solution, or to derive it from demonstration data. In this paper explore how a rich environment can help to promote the learning of complex behavior. Specifically, we train agents in diverse environmental contexts, and find that this encourages the emergence of robust behaviours that perform well across a suite of tasks. We demonstrate this principle for locomotion -- behaviours that are known for their sensitivity to the choice of reward. We train several simulated bodies on a diverse set of challenging terrains and obstacles, using a simple reward function based on forward progress. Using a novel scalable variant of policy gradient reinforcement learning, our agents learn to run, jump, crouch and turn as required by the environment without explicit reward-based guidance. A visual depiction of highlights of the learned behavior can be viewed following https://youtu.be/hx{\_}bgoTF7bs .},
archivePrefix = {arXiv},
arxivId = {1707.02286},
author = {Heess, Nicolas and TB, Dhruva and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, S. M. Ali and Riedmiller, Martin and Silver, David},
eprint = {1707.02286},
file = {:home/tkorthals/Documents/Mendeley Desktop/Heess et al. - 2017 - Emergence of Locomotion Behaviours in Rich Environments.pdf:pdf},
keywords = {Reward,rewardfunction},
mendeley-groups = {Machine Learning/RL/Google Deep Mind},
mendeley-tags = {Reward,rewardfunction},
title = {{Emergence of Locomotion Behaviours in Rich Environments}},
url = {http://arxiv.org/abs/1707.02286},
year = {2017}
}
@article{Vedantam2017,
abstract = {It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison of our method with two existing joint image-attribute VAE methods (the JMVAE method of Suzuki et.al. and the BiVCCA method of Wang et.al.) by applying them to two datasets: the MNIST-with-attributes dataset (which we introduce here), and the CelebA dataset.},
archivePrefix = {arXiv},
arxivId = {1705.10762},
author = {Vedantam, Ramakrishna and Fischer, Ian and Huang, Jonathan and Murphy, Kevin},
eprint = {1705.10762},
file = {:home/tkorthals/Documents/Mendeley Desktop/Vedantam et al. - 2017 - Generative Models of Visually Grounded Imagination.pdf:pdf},
mendeley-groups = {VAE/Multi-Modal},
pages = {1--21},
title = {{Generative Models of Visually Grounded Imagination}},
url = {http://arxiv.org/abs/1705.10762},
year = {2017}
}
@article{Wang2016_2,
abstract = {We present deep variational canonical correlation analysis (VCCA), a deep multi-view learning model that extends the latent variable model interpretation of linear CCA to nonlinear observation models parameterized by deep neural networks. We derive variational lower bounds of the data likelihood by parameterizing the posterior probability of the latent variables from the view that is available at test time. We also propose a variant of VCCA called VCCA-private that can, in addition to the "common variables" underlying both views, extract the "private variables" within each view, and disentangles the shared and private information for multi-view data without hard supervision. Experimental results on real-world datasets show that our methods are competitive across domains.},
archivePrefix = {arXiv},
arxivId = {1610.03454},
author = {Wang, Weiran and Yan, Xinchen and Lee, Honglak and Livescu, Karen},
eprint = {1610.03454},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wang et al. - 2016 - Deep Variational Canonical Correlation Analysis.pdf:pdf},
mendeley-groups = {VAE/Multi-Modal},
title = {{Deep Variational Canonical Correlation Analysis}},
url = {http://arxiv.org/abs/1610.03454},
volume = {1},
year = {2016}
}
@article{Grzes2017,
abstract = {Recent advancements in reinforcement learning confirm that reinforcement learning techniques can solve large scale prob-lems leading to high quality autonomous decision making. It is a matter of time until we will see large scale appli-cations of reinforcement learning in various sectors, such as healthcare and cyber-security, among others. However, reinforcement learning can be time-consuming because the learning algorithms have to determine the long term conse-quences of their actions using delayed feedback or rewards. Reward shaping is a method of incorporating domain knowl-edge into reinforcement learning so that the algorithms are guided faster towards more promising solutions. Under an overarching theme of episodic reinforcement learning, this paper shows a unifying analysis of potential-based reward shaping which leads to new theoretical insights into reward shaping in both model-free and model-based algorithms, as well as in multi-agent reinforcement learning.},
author = {Grze{\'{s}}, Marek},
file = {:home/tkorthals/Documents/Mendeley Desktop/Grze{\'{s}} - 2017 - Reward Shaping in Episodic Reinforcement Learning.pdf:pdf},
isbn = {9781510855076},
issn = {15582914},
journal = {Proc. of the 16th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2017)},
keywords = {Keywords Reward structures for learning,Multi-agent reinforce-ment learning,Multiagent learning,Q-learning,Reinforcement learning,Reward shaping,Sequential decision making},
mendeley-groups = {Machine Learning/Tutorials},
pages = {565--573},
title = {{Reward Shaping in Episodic Reinforcement Learning}},
year = {2017}
}
@article{Nannan2013,
abstract = {A key problem of robotic environmental sensing and monitoring is that of active sensing: How can a team of robots plan the most informative observation paths to minimize the uncertainty in modeling and predicting an environmental phenomenon? This paper presents two principled approaches to efficient information-theoretic path planning based on entropy and mutual information criteria for in situ active sensing of an important broad class of widely-occurring environmental phenomena called anisotropic fields. Our proposed algorithms are novel in addressing a trade-off between active sensing performance and time efficiency. An important practical consequence is that our algorithms can exploit the spatial correlation structure of Gaussian process-based anisotropic fields to improve time efficiency while preserving near-optimal active sensing performance. We analyze the time complexity of our algorithms and prove analytically that they scale better than state-of-the-art algorithms with increasing planning horizon length. We provide theoretical guarantees on the active sensing performance of our algorithms for a class of exploration tasks called transect sampling, which, in particular, can be improved with longer planning time and/or lower spatial correlation along the transect. Empirical evaluation on real-world anisotropic field data shows that our algorithms can perform better or at least as well as the state-of-the-art algorithms while often incurring a few orders of magnitude less computational time, even when the field conditions are less favorable.},
archivePrefix = {arXiv},
arxivId = {1302.0723},
author = {Cao, Nannan and Low, Kian Hsiang and Dolan, John M.},
doi = {10.1007/s11947-009-0181-3},
eprint = {1302.0723},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cao, Low, Dolan - 2013 - Multi-Robot Informative Path Planning for Active Sensing of Environmental Phenomena A Tale of Two Algorithms.pdf:pdf},
isbn = {978-1-4503-1993-5},
issn = {1935-5130},
keywords = {active learning,adaptive sampling,gaussian process,multi-robot exploration and mapping,non-myopic path planning},
mendeley-groups = {Robotics/Active Sensing/Survey},
pages = {6--10},
pmid = {17355401},
title = {{Multi-Robot Informative Path Planning for Active Sensing of Environmental Phenomena: A Tale of Two Algorithms}},
url = {http://arxiv.org/abs/1302.0723},
year = {2013}
}
@article{Shipeng2009,
author = {Yu, Shipeng and Krishnapuram, Balaji and Rosales, Romer and Rao, R Bharat},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yu et al. - 2009 - Active Sensing.pdf:pdf},
journal = {Aistats},
mendeley-groups = {Robotics/Active Sensing},
pages = {639--646},
title = {{Active Sensing}},
year = {2009}
}
@article{Yoon2018,
abstract = {For every prediction we might wish to make, we must decide what to observe (what source of information) and when to observe it. Because making observa- tions is costly, this decision must trade off the value of information against the cost of observation. Making observations (sensing) should be an active choice. To solve the problem of active sensing we develop a novel deep learning architecture: Deep Sensing. At training time, Deep Sensing learns how to issue predictions at various cost-performance points. To do this, it creates a different presentation at each of a variety of different performance levels, each associated with a particular set of measurement rates (costs). This requires learning how to estimate the value of real measurements vs. inferred measurements, which in turn requires learning howto infer missing (unobserved) measurements. To infer missing measurements, we develop a Multi-directional Recurrent Neural Network (M-RNN). An M-RNN differs from a bi-directional RNN in that it sequentially operates across streams in addition to within streams, and because the timing of inputs into the hidden layers is both lagged and advanced. At runtime, the operator prescribes a perfor- mance level or a cost constraint, and Deep Sensing determines what measurements to take and what to infer from those measurements, and then issues predictions. To demonstrate the power of our method, we apply it to two real-world medical datasets with significantly improved performance. 1},
author = {Yoon, Jinsung and Angeles, Los and Angeles, Los and Zame, William R and Angeles, Los and Angeles, Los and Schaar, Mihaela Van Der},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yoon et al. - 2018 - Deep Sensing Active Sensing Using Multi- Directional Recurrent Neural Networks.pdf:pdf},
mendeley-groups = {Robotics/Active Sensing},
pages = {1--19},
title = {{Deep Sensing: Active Sensing Using Multi- Directional Recurrent Neural Networks}},
year = {2018}
}
@article{Chung2004,
abstract = {In this paper, we consider the problem of active sensing using mobile nodes as a sensor network to estimate the state of a dynamic target. We propose a gradient-search-based decentralized algorithm that demonstrates the benefits of distributed sensing. We then examine the task of tracking multiple targets, and address it via a simple extension to our algorithm. Simulation results show that our simple decentralized approach performs quite well and leads to interesting cooperative behavior.},
author = {Chung, T.H. and Gupta, V. and Burdick, J.W. and Murray, R.M.},
doi = {10.1109/CDC.2004.1430327},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chung et al. - 2004 - On a decentralized active sensing strategy using mobile sensor platforms in a network.pdf:pdf},
isbn = {0-7803-8682-5},
issn = {0191-2216},
journal = {2004 43rd IEEE Conference on Decision and Control (CDC) (IEEE Cat. No.04CH37601)},
mendeley-groups = {Robotics/Active Sensing},
pages = {1914--1919 Vol.2},
title = {{On a decentralized active sensing strategy using mobile sensor platforms in a network}},
url = {http://ieeexplore.ieee.org/document/1430327/},
year = {2004}
}
@article{Vijayanarasimhan2010,
abstract = {Visual recognition and detection are computationally intensive tasks and current research efforts primarily focus on solving them without considering the computational capability of the devices they run on. In this paper we explore the challenge of deriving methods that consider constraints on computation, appropriately schedule the next best computation to perform and finally have the capability of producing reasonable results at any time when a solution is required. We specifically derive an approach for the task of object category localization and classification in cluttered, natural scenes that can not only produce anytime results but also utilize the principle of value-of-information in order to provide the most recognition bang for the computational buck. Experiments on two standard object detection challenges show that the proposed framework can triage computation effectively and attain state-of-the-art results when allowed to run till completion. Additionally, the real benefit of the proposed framework is highlighted in the experiments where we demonstrate that the method can provide reasonable recognition results even if the procedure needs to terminate before completion.},
author = {Vijayanarasimhan, Sudheendra and Kapoor, Ashish},
doi = {10.1109/CVPR.2010.5540109},
file = {:home/tkorthals/Documents/Mendeley Desktop/Vijayanarasimhan, Kapoor - 2010 - Visual recognition and detection under bounded computational resources.pdf:pdf},
isbn = {9781424469840},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
mendeley-groups = {Robotics/Active Sensing},
number = {June},
pages = {1006--1013},
title = {{Visual recognition and detection under bounded computational resources}},
year = {2010}
}
@article{Bajcsy2018,
abstract = {Despite the recent successes in robotics, artificial intelligence and computer vision, a complete artificial agent necessarily must include active perception. A multitude of ideas and methods for how to accomplish this have already appeared in the past, their broader utility perhaps impeded by insufficient computational power or costly hardware. The history of these ideas, perhaps selective due to our perspectives, is presented with the goal of organizing the past literature and highlighting the seminal contributions. We argue that those contributions are as relevant today as they were decades ago and, with the state of modern computational tools, are poised to find new life in the robotic perception systems of the next decade.},
archivePrefix = {arXiv},
arxivId = {1603.02729},
author = {Bajcsy, Ruzena and Aloimonos, Yiannis and Tsotsos, John K.},
doi = {10.1007/s10514-017-9615-3},
eprint = {1603.02729},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bajcsy, Aloimonos, Tsotsos - 2018 - Revisiting active perception.pdf:pdf},
isbn = {9780262025782},
issn = {15737527},
journal = {Autonomous Robots},
keywords = {Attention,Control,Perception,Sensing},
mendeley-groups = {Robotics/Active Sensing/Survey},
number = {2},
pages = {177--196},
publisher = {Springer US},
title = {{Revisiting active perception}},
volume = {42},
year = {2018}
}
@article{Fleer2017,
author = {Fleer, David},
doi = {10.3390/robotics6040035},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fleer - 2017 - Human-Like Room Segmentation for Domestic Cleaning Robots.pdf:pdf},
issn = {2218-6581},
journal = {Robotics},
keywords = {computer vision,domestic cleaning robots,machine learning,room segmentation},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung/M{\"{o}}ller},
number = {4},
pages = {35},
title = {{Human-Like Room Segmentation for Domestic Cleaning Robots}},
url = {http://www.mdpi.com/2218-6581/6/4/35},
volume = {6},
year = {2017}
}
@article{Fleer2017b,
abstract = {Feature-based and holistic methods present two fundamentally different approaches to relative-pose estimation from pairs of camera images. Until now, there has been a lack of direct comparisons between these methods in the literature. This makes it difficult to evaluate their relative merits for their many applications in mobile robotics. In this work, we compare a selection of such methods in the context of an autonomous domestic cleaning robot. We find that the holistic Min-Warping method gives good and fast results. Some of the feature-based methods can provide excellent and robust results, but at much slower speeds. Other such methods also achieve high speeds, but at reduced robustness to illumination changes. We also provide novel image databases and supporting data for public use.},
author = {Fleer, David and M{\"{o}}ller, Ralf},
doi = {10.1016/j.robot.2016.12.001},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fleer et al. - 2016 - relative pose of mobile robots Comparing holistic and feature-based visual methods for estimating the relative pos.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Holistic visual homing,Image databases,Local visual features,Robot localization,Visual pose estimation},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung/M{\"{o}}ller},
pages = {51--74},
publisher = {Elsevier B.V.},
title = {{Comparing holistic and feature-based visual methods for estimating the relative pose of mobile robots}},
url = {http://dx.doi.org/10.1016/j.robot.2016.12.001},
volume = {89},
year = {2017}
}
@article{Fleer2017a,
author = {Fleer, David},
doi = {10.3390/robotics6040032},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fleer - 2017 - Visual Tilt Estimation for Planar-Motion Methods in Indoor Mobile Robots.pdf:pdf},
issn = {2218-6581},
journal = {Robotics},
keywords = {autonomous mobile robots,computer vision,domestic cleaning robots,visual},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung/M{\"{o}}ller},
number = {4},
pages = {32},
title = {{Visual Tilt Estimation for Planar-Motion Methods in Indoor Mobile Robots}},
url = {http://www.mdpi.com/2218-6581/6/4/32},
volume = {6},
year = {2017}
}
@article{bengio2012,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
archivePrefix = {arXiv},
arxivId = {1206.5538},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {10.1145/1756006.1756025},
eprint = {1206.5538},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bengio, Courville, Vincent - 2012 - Representation Learning A Review and New Perspectives.pdf:pdf},
isbn = {1206.5538},
issn = {15324435},
mendeley-groups = {VAE/Neuroscience},
number = {1993},
pages = {1--30},
pmid = {23787338},
title = {{Representation Learning: A Review and New Perspectives}},
url = {http://arxiv.org/abs/1206.5538},
year = {2012}
}
@article{Fu2015,
abstract = {We present a low-cost social robot system composed of a mobile base (a robotic cleaner, 150), an Intel RealSense RGB-D camera (100), a touch screen powerful laptop (800), the ROS(Robot Operating System) (0) and the Intel RealSense SDK (0). This social robot has the capability of autonomously navigating in an unstructured and dynamic environment, avoiding collisions with stationary or dynamic obstacles and generating rich social behaviors (such as face detection, hand tracking, take pictures, interact with social networks, etc.). Taking advantage of plenty of open source packages in the ROS and Intel cutting edge perceptual computing software, this social robot system allows researchers and school students to rapidly reproduce an affordable and ideal hardware/software platform for their robotics-related research and education. Such a low-cost robot is expected to lead to faster progress in robotics-related application development and research, such as robot-human interaction, social communication, networking robots and even other non-robotic fields.},
author = {Fu, Guohe and Zhang, Xinyu},
doi = {10.1109/AIM.2015.7222806},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fu, Zhang - 2015 - ROSBOT A low-cost autonomous social robot.pdf:pdf},
isbn = {9781467391078},
issn = {2159-6247},
journal = {IEEE/ASME International Conference on Advanced Intelligent Mechatronics, AIM},
mendeley-groups = {Robotics/Robots},
pages = {1789--1794},
title = {{ROSBOT: A low-cost autonomous social robot}},
volume = {2015-Augus},
year = {2015}
}
@article{schubotz2007,
abstract = {We cannot, in the proper sense, imitate or re-enact inanimate events, such as ocean waves rolling, or even non-human animate ones, such as dogs walking. However, we can anticipate the way they change and recent studies show that our motor system becomes involved while doing so. A novel framework is presented that accounts for these findings by generalizing a predictive account of the motor system from action to event perception. It is suggested that we predict events that we cannot reproduce ourselves by exploiting an audiomotor or visuomotor representation that never amounts to a real action because it lacks proprioceptive and other interoceptive information. This view inspires thinking beyond our customary conceptualization of a 'motor' system. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
author = {Schubotz, Ricarda I.},
doi = {10.1016/j.tics.2007.02.006},
file = {:home/tkorthals/Documents/Mendeley Desktop/Schubotz - 2007 - Prediction of external events with our motor system towards a new framework.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
mendeley-groups = {VAE/Neuroscience},
number = {5},
pages = {211--218},
pmid = {17383218},
title = {{Prediction of external events with our motor system: towards a new framework}},
volume = {11},
year = {2007}
}
@article{friston2017,
abstract = {This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidence—or minimizing variational free energy—we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes' optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technicall...},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
doi = {10.1162/NECO_a_00912},
eprint = {1309.2848v1},
file = {:home/tkorthals/Documents/Mendeley Desktop//Salman et al. - 2018 - Learning to Sequence Robot Behaviors for Visual Navigation.pdf:pdf},
isbn = {0899-7667},
issn = {1530888X},
journal = {Neural Computation},
mendeley-groups = {VAE/Neuroscience},
pmid = {25602775},
title = {{Active inference: A process theory}},
year = {2017}
}
@article{Verkhratsky2015,
abstract = {Macroglial cells originate from the neuroectoderm. These cells are subclassified into astrocytes, oligodendrocytes, and NG2 glia, versatile and highly heterogeneous cellular populations with overarching functions in the maintenance of homeostasis of the nervous system. Microglial cells express a repertoire of plasmalemmal receptors for a variety of neurotransmitters, neurohormones, and neuromodulators. Albeit these cells are electrically nonexcitable, they display their excitability in the form of variations of intracellular ions, in particular Ca2+ and Na+, concentration, which can affect local and long-distance neuronal activity via metabolic and/or signaling pathways.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Verkhratsky, A. and Butt, A. and Rodriguez, J. J. and Parpura, V.},
doi = {10.1016/B978-0-12-397025-1.00205-0},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2015 - Reference , published by Elsevier , and the attached copy is provided by for non-commercial research and educational us.pdf:pdf},
isbn = {9780123970251},
issn = {0148-396X},
journal = {Brain Mapping: An Encyclopedic Reference},
pages = {101--107},
pmid = {10911016},
title = {{Astrocytes, Oligodendrocytes, and NG2 Glia: Structure and Function}},
volume = {2},
year = {2015}
}
@incollection{Schubotz_2015,
author = {Schubotz, R I},
booktitle = {Brain Mapping},
doi = {10.1016/b978-0-12-397025-1.00247-5},
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2015 - Reference , published by Elsevier , and the attached copy is provided by for non-commercial research and educational us.pdf:pdf},
mendeley-groups = {VAE/Neuroscience},
pages = {295--302},
publisher = {Elsevier},
title = {{Prediction and Expectation}},
url = {https://doi.org/10.1016{\%}2Fb978-0-12-397025-1.00247-5},
year = {2015}
}
@article{Salman2018,
abstract = {Recent literature in the robotics community has focused on learning robot behaviors that abstract out lower-level details of robot control. To fully leverage the efficacy of such behaviors, it is necessary to select and sequence them to achieve a given task. In this paper, we present an approach to both learn and sequence robot behaviors, applied to the problem of visual navigation of mobile robots. We construct a layered representation of control policies composed of low- level behaviors and a meta-level policy. The low-level behaviors enable the robot to locomote in a particular environment while avoiding obstacles, and the meta-level policy actively selects the low-level behavior most appropriate for the current situation based purely on visual feedback. We demonstrate the effectiveness of our method on three simulated robot navigation tasks: a legged hexapod robot which must successfully traverse varying terrain, a wheeled robot which must navigate a maze-like course while avoiding obstacles, and finally a wheeled robot navigating in the presence of dynamic obstacles. We show that by learning control policies in a layered manner, we gain the ability to successfully traverse new compound environments composed of distinct sub-environments, and outperform both the low-level behaviors in their respective sub-environments, as well as a hand-crafted selection of low-level policies on these compound environments.},
archivePrefix = {arXiv},
arxivId = {1803.01446},
author = {Salman, Hadi and Singhal, Puneet and Shankar, Tanmay and Yin, Peng and Salman, Ali and Paivine, William and Sartoretti, Guillaume and Travers, Matthew and Choset, Howie},
doi = {10.1162/NECO},
eprint = {1803.01446},
file = {:home/tkorthals/Documents/Mendeley Desktop//Salman et al. - 2018 - Learning to Sequence Robot Behaviors for Visual Navigation.pdf:pdf},
isbn = {0899-7667},
issn = {1530888X},
pages = {1--49},
pmid = {25602775},
title = {{Learning to Sequence Robot Behaviors for Visual Navigation}},
url = {http://arxiv.org/abs/1803.01446},
volume = {49},
year = {2018}
}
@article{friston2016,
abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
doi = {10.1016/j.neubiorev.2016.06.022},
file = {:home/tkorthals/Documents/Mendeley Desktop/Friston et al. - 2016 - Active inference and learning.pdf:pdf},
isbn = {0149-7634},
issn = {18737528},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},
mendeley-groups = {VAE/Neuroscience},
pages = {862--879},
pmid = {27375276},
publisher = {Elsevier Ltd},
title = {{Active inference and learning}},
url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.022},
volume = {68},
year = {2016}
}
@article{clark2013,
abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this “hierarchical prediction machine” approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.},
archivePrefix = {arXiv},
arxivId = {0140-525X},
author = {Clark, Andy},
doi = {10.1017/S0140525X12000477},
eprint = {0140-525X},
file = {:home/tkorthals/Documents/Mendeley Desktop/Clark - 2013 - Whatever next Predictive brains, situated agents, and the future of cognitive science.pdf:pdf},
isbn = {1469-1825 (Electronic)$\backslash$r0140-525X (Linking)},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
keywords = {Bayesian brain,action,attention,expectation,generative model,hierarchy,perception,precision,prediction,prediction error,predictive coding,top-down processing},
mendeley-groups = {VAE/Neuroscience},
number = {3},
pages = {181--204},
pmid = {23663408},
title = {{Whatever next? Predictive brains, situated agents, and the future of cognitive science}},
volume = {36},
year = {2013}
}
@article{Arvin2018,
abstract = {{\textcopyright} 2018 The Author(s) Mobile robots are playing a significant role in Higher Education science and engineering teaching, as they offer a flexible platform to explore and teach a wide-range of topics such as mechanics, electronics and software. Unfortunately the widespread adoption is limited by their high cost and the complexity of user interfaces and programming tools. To overcome these issues, a new affordable, adaptable and easy-to-use robotic platform is proposed. Mona is a low-cost, open-source and open-hardware mobile robot, which has been developed to be compatible with a number of standard programming environments. The robot has been successfully used for both education and research at The University of Manchester, UK.},
author = {Arvin, Farshad and Espinosa, Jose and Bird, Benjamin and West, Andrew and Watson, Simon and Lennox, Barry},
doi = {10.1007/s10846-018-0866-9},
file = {:home/tkorthals/Documents/Mendeley Desktop/Arvin et al. - 2018 - Mona an Affordable Open-Source Mobile Robot for Education and Research.pdf:pdf},
issn = {15730409},
journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
keywords = {Mobile robot,Open-hardware,Open-source,Robotics for education},
mendeley-groups = {Robotics/Robots},
pages = {1--15},
publisher = {Journal of Intelligent {\&} Robotic Systems},
title = {{Mona: an Affordable Open-Source Mobile Robot for Education and Research}},
year = {2018}
}
@article{Hoffman2017,
author = {Hoffman, Matthew D and Riquelme, Carlos and Johnson, Matthew J},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hoffman, Riquelme, Johnson - 2017 - The $\beta$ -VAE ' s Implicit Prior.pdf:pdf},
journal = {NIPS 2017 Bayesian Deep Learning Workshop},
mendeley-groups = {VAE/Disentagled},
number = {Nips},
pages = {0--4},
title = {{The $\beta$ -VAE ' s Implicit Prior}},
url = {http://bayesiandeeplearning.org/2017/papers/66.pdf},
year = {2017}
}
@article{Burgess2018,
abstract = {We present new intuitions and theoretical assessments of the emergence of disentangled representation in variational autoencoders. Taking a rate-distortion theory perspective, we show the circumstances under which representations aligned with the underlying generative factors of variation of data emerge when optimising the modified ELBO bound in {\$}\backslashbeta{\$}-VAE, as training progresses. From these insights, we propose a modification to the training regime of {\$}\backslashbeta{\$}-VAE, that progressively increases the information capacity of the latent code during training. This modification facilitates the robust learning of disentangled representations in {\$}\backslashbeta{\$}-VAE, without the previous trade-off in reconstruction accuracy.},
archivePrefix = {arXiv},
arxivId = {1804.03599},
author = {Burgess, Christopher P. and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
eprint = {1804.03599},
file = {:home/tkorthals/Documents/Mendeley Desktop/Burgess et al. - 2018 - Understanding disentangling in $\beta$-VAE.pdf:pdf},
mendeley-groups = {VAE/Disentagled},
number = {Nips},
title = {{Understanding disentangling in $\beta$-VAE}},
url = {http://arxiv.org/abs/1804.03599},
year = {2018}
}
@article{Higgins2017_2,
abstract = {Learning an interpretable factorised representation of the independent data gen-erative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce $\beta$-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hy-perparameter $\beta$ that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that $\beta$-VAE with appropriately tuned $\beta$ {\textgreater} 1 qualitatively outperforms VAE ($\beta$ = 1), as well as state of the art unsu-pervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, $\beta$-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter $\beta$, which can be directly optimised through a hyperparameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander and Deepmind, Google},
file = {:home/tkorthals/Documents/Mendeley Desktop/Higgins et al. - 2017 - beta-VAE Learning Basic Visual Concepts with a Constrained Variational Framework.pdf:pdf},
journal = {Iclr},
mendeley-groups = {VAE/Disentagled},
number = {July},
pages = {1--13},
title = {{beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework}},
url = {https://openreview.net/forum?id=Sy2fzU9gl},
year = {2017}
}
@incollection{Nowe2012,
abstract = {Reinforcement Learning was originally developed for Markov Decision Processes (MDPs). It allows a single agent to learn a policy that maximizes a possibly delayed reward signal in a stochastic stationary environment. It guarantees convergence to the optimal policy, provided that the agent can sufficiently experiment and the environment in which it is operating is Markovian. However, when multiple agents apply reinforcement learning in a shared environment, this might be beyond the MDP model. In such systems, the optimal policy of an agent depends not only on the environment, but on the policies of the other agents as well. These situations arise naturally in a variety of domains, such as: robotics, telecommunications, economics, distributed control, auctions, traffic light control, etc. In these domains multi-agent learning is used, either because of the complexity of the domain or because control is inherently decentralized. In such systems it is important that agents are capable of discovering good solutions to the problem at hand either by coordinating with other learners or by competing with them. This chapter focuses on the application reinforcement learning techniques in multi-agent systems. We describe a basic learning framework based on the economic research into game theory, and illustrate the additional complexity that arises in such systems. We also described a representative selection of algorithms for the different areas of multi-agent reinforcement learning research.},
author = {Nowe, Ann and Vrancx, Peter and Hauwere, Yann-Micha{\"{e}}l De},
booktitle = {Reinforcement Learning: State of the Art},
doi = {10.1007/978-3-642-27645-3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Nowe, Peter VrancxPeter VrancxYann-Micha{\"{e}}l De HauwereYann-Micha{\"{e}}l De Hauwere - 2012 - Game Theory and Multi-agent Reinforcement Learni.pdf:pdf},
isbn = {978-3-642-27644-6},
mendeley-groups = {Machine Learning/MARL},
number = {January},
title = {{Game Theory and Multi-agent Reinforcement Learning}},
url = {http://link.springer.com/10.1007/978-3-642-27645-3},
volume = {12},
year = {2012}
}
@article{Wayne2018,
abstract = {Animals execute goal-directed behaviours despite the limited range and scope of their sensors. To cope, they explore environments and store memories maintaining estimates of important information that is not presently available. Recently, progress has been made with artificial intelligence (AI) agents that learn to perform tasks from sensory input, even at a human level, by merging reinforcement learning (RL) algorithms with deep neural networks, and the excitement surrounding these results has led to the pursuit of related ideas as explanations of non-human animal learning. However, we demonstrate that contemporary RL algorithms struggle to solve simple tasks when enough information is concealed from the sensors of the agent, a property called "partial observability". An obvious requirement for handling partially observed tasks is access to extensive memory, but we show memory is not enough; it is critical that the right information be stored in the right format. We develop a model, the Memory, RL, and Inference Network (MERLIN), in which memory formation is guided by a process of predictive modeling. MERLIN facilitates the solution of tasks in 3D virtual reality environments for which partial observability is severe and memories must be maintained over long durations. Our model demonstrates a single learning agent architecture that can solve canonical behavioural tasks in psychology and neurobiology without strong simplifying assumptions about the dimensionality of sensory input or the duration of experiences.},
archivePrefix = {arXiv},
arxivId = {1803.10760},
author = {Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and Grabska-Barwinska, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z. and Santoro, Adam and Gemici, Mevlana and Reynolds, Malcolm and Harley, Tim and Abramson, Josh and Mohamed, Shakir and Rezende, Danilo and Saxton, David and Cain, Adam and Hillier, Chloe and Silver, David and Kavukcuoglu, Koray and Botvinick, Matt and Hassabis, Demis and Lillicrap, Timothy},
eprint = {1803.10760},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wayne et al. - 2018 - Unsupervised Predictive Memory in a Goal-Directed Agent.pdf:pdf},
mendeley-groups = {Machine Learning/RL},
title = {{Unsupervised Predictive Memory in a Goal-Directed Agent}},
url = {http://arxiv.org/abs/1803.10760},
year = {2018}
}
@article{Lillicrap2015,
abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.},
archivePrefix = {arXiv},
arxivId = {1509.02971},
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
doi = {10.1561/2200000006},
eprint = {1509.02971},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lillicrap et al. - 2015 - Continuous control with deep reinforcement learning.pdf:pdf},
isbn = {2200000006},
issn = {1935-8237},
keywords = {DDQN},
mendeley-groups = {Machine Learning/RL},
pmid = {24966830},
title = {{Continuous control with deep reinforcement learning}},
url = {http://arxiv.org/abs/1509.02971},
year = {2015}
}
@article{ErmonGroup2017,
author = {{Ermon Group}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ermon Group - 2017 - The variational auto-encoder.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{The variational auto-encoder}},
url = {https://ermongroup.github.io/cs228-notes/extras/vae/},
year = {2017}
}
@misc{Wikipedia,
author = {Wikipedia},
booktitle = {2018},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wikipedia - Unknown - Variational Bayesian methods.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {1--10},
title = {{Variational Bayesian methods}},
url = {https://en.wikipedia.org/wiki/Variational{\_}Bayesian{\_}methods}
}
@article{OReilly2016,
author = {OReilly},
file = {:home/tkorthals/Documents/Mendeley Desktop/OReilly - 2016 - OReilly - RL Tutorial Deep Reinforcement Learning tutorial 2017.pdf:pdf},
mendeley-groups = {Machine Learning/RL,Machine Learning/Tutorials},
title = {{OReilly - RL Tutorial Deep Reinforcement Learning tutorial 2017}},
url = {https://github.com/awjuliani/oreilly-rl-tutorial},
year = {2016}
}
@article{Juliani2016,
author = {Juliani, Arthur},
file = {:home/tkorthals/Documents/Mendeley Desktop/Juliani - 2016 - Deep Reinforcement Learning Agents.pdf:pdf},
journal = {Medium},
mendeley-groups = {Machine Learning/Tutorials},
title = {{Deep Reinforcement Learning Agents}},
url = {https://github.com/awjuliani/DeepRL-Agents},
year = {2016}
}
@article{Dilokthanakul2016,
abstract = {We study a variant of the variational autoencoder model (VAE) with a Gaussian mixture as a prior distribution, with the goal of performing unsupervised clustering through deep generative models. We observe that the known problem of over-regularisation that has been shown to arise in regular VAEs also manifests itself in our model and leads to cluster degeneracy. We show that a heuristic called minimum information constraint that has been shown to mitigate this effect in VAEs can also be applied to improve unsupervised clustering performance with our model. Furthermore we analyse the effect of this heuristic and provide an intuition of the various processes with the help of visualizations. Finally, we demonstrate the performance of our model on synthetic data, MNIST and SVHN, showing that the obtained clusters are distinct, interpretable and result in achieving competitive performance on unsupervised clustering to the state-of-the-art results.},
archivePrefix = {arXiv},
arxivId = {1611.02648},
author = {Dilokthanakul, Nat and Mediano, Pedro A. M. and Garnelo, Marta and Lee, Matthew C. H. and Salimbeni, Hugh and Arulkumaran, Kai and Shanahan, Murray},
eprint = {1611.02648},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dilokthanakul et al. - 2016 - Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders.pdf:pdf},
isbn = {1045-9227},
mendeley-groups = {VAE/Priors,VAE/Whats More},
number = {2016},
pages = {1--12},
title = {{Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders}},
url = {http://arxiv.org/abs/1611.02648},
year = {2016}
}
@article{Giordano2016,
abstract = {In Bayesian analysis, the posterior follows from the data and a choice of a prior and a likelihood. One hopes that the posterior is robust to reasonable variation in the choice of prior, since this choice is made by the modeler and is often somewhat subjective. A different, equally subjectively plausible choice of prior may result in a substantially different posterior, and so different conclusions drawn from the data. Were this to be the case, our conclusions would not be robust to the choice of prior. To determine whether our model is robust, we must quantify how sensitive our posterior is to perturbations of our prior. Variational Bayes (VB) methods are fast, approximate methods for posterior infer-ence. As with any Bayesian method, it is useful to evaluate the robustness of a VB approximate posterior to changes in the prior. In this paper, we derive VB versions of classical non-parametric local robustness measures. In particular, we show that the influence function of Gustafson (2000) has a simple, easy-to-calculate closed form expression for VB approximations. We then demonstrate how local robustness measures can be inadequate for non-local prior changes, such as replacing one prior entirely with another. We propose a simple approximate non-local robustness measure and demonstrate its effectiveness on a simulated data set.},
archivePrefix = {arXiv},
arxivId = {arXiv:1611.07469v2},
author = {Giordano, Ryan and Broderick, Tamara and Dec, M E and Jordan, Michael},
eprint = {arXiv:1611.07469v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Giordano et al. - 2016 - The Prior Influence Function in Variational Bayes.pdf:pdf},
mendeley-groups = {VAE/Priors},
number = {Nips},
title = {{The Prior Influence Function in Variational Bayes}},
year = {2016}
}
@misc{Geron,
author = {G{\'{e}}ron, Aur{\'{e}}lien},
mendeley-groups = {Machine Learning/Tutorials},
title = {{Capsule Networks}},
url = {https://www.youtube.com/watch?v=pPN8d0E3900}
}
@article{Mordatch2017,
abstract = {By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.},
archivePrefix = {arXiv},
arxivId = {1703.04908},
author = {Mordatch, Igor and Abbeel, Pieter},
eprint = {1703.04908},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mordatch, Abbeel - 2017 - Emergence of Grounded Compositional Language in Multi-Agent Populations.pdf:pdf},
isbn = {1703.04908},
mendeley-groups = {Machine Learning/RL},
title = {{Emergence of Grounded Compositional Language in Multi-Agent Populations}},
url = {http://arxiv.org/abs/1703.04908},
year = {2017}
}
@article{Zhang2016,
abstract = {While deep learning has had significant successes in computer vision thanks to the abundance of visual data, collecting sufficiently large real-world datasets for robot learning can be costly. To increase the practicality of these techniques on real robots, we propose a modular deep reinforcement learning method capable of transferring models trained in simulation to a real-world robotic task. We introduce a bottleneck between perception and control, enabling the networks to be trained independently, but then merged and fine-tuned in an end-to-end manner to further improve hand-eye coordination. On a canonical, planar visually-guided robot reaching task a fine-tuned accuracy of 1.6 pixels is achieved, a significant improvement over naive transfer (17.5 pixels), showing the potential for more complicated and broader applications. Our method provides a technique for more efficient learning and transfer of visuo-motor policies for real robotic systems without relying entirely on large real-world robot datasets.},
archivePrefix = {arXiv},
arxivId = {1610.06781},
author = {Zhang, Fangyi and Leitner, J{\"{u}}rgen and Milford, Michael and Corke, Peter},
eprint = {1610.06781},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhang et al. - 2016 - Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies.pdf:pdf},
mendeley-groups = {Machine Learning/RL},
title = {{Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies}},
url = {http://arxiv.org/abs/1610.06781},
year = {2016}
}
@misc{,
mendeley-groups = {Machine Learning/Tutorials},
title = {{Robot Control with Distributed Deep Reinforcement Learning}},
url = {https://www.youtube.com/watch?v=-YMfJLFynmA}
}
@misc{MicrosoftResearch,
author = {{Microsoft Research}},
mendeley-groups = {VAE/Tutorials},
title = {{From Deep Learning of Disentangled Representations to Higher-level Cognition}},
url = {https://www.youtube.com/watch?v=Yr1mOzC93xs}
}
@article{Lowe2017,
author = {Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lowe et al. - 2017 - Multi-agent actor-critic for mixed cooperative-competitive environments.pdf:pdf},
journal = {Nips},
mendeley-groups = {Machine Learning/RL},
number = {Nips},
pages = {6382--6393},
title = {{Multi-agent actor-critic for mixed cooperative-competitive environments}},
year = {2017}
}
@phdthesis{Cataneda2016,
abstract = {We introduce Deep Repeated Update Q-Network (DRUQN) and Deep Loosely Coupled Q-Network (DLCQN). Two novel variants of Deep Q-Network (DQN). These algorithms are designed with the intention of providing architectures that are more appropriate for handling interactions between multiple agents and robust enough to deal with the non-stationarity produced by concurrent learning. We approach this from two different fronts. DRUQN tries to address Q-Learning's tendency to favor the update of certain action-values which may lead to decreased performance in rapid changing environments. Meanwhile, DLCQN learns to decompose the state space into two: (1) states where it is sensible or necessary to act independently and (2) those where acting in coordination with another agent may lead to a better outcome. We use Pong as testing environment and compare the performance of DRUQN, DLCQN and DQN on different competitive and cooperative experiments. The results demonstrate that for some tasks DLCQN and DRUQN outperform DQN which hints at the necessity to develop and using architectures capable of coping with richer and more complex dynamics.},
author = {Cata{\~{n}}eda, Alvaro Ovalle},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cata{\~{n}}eda - 2016 - Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms.pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
title = {{Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms}},
url = {https://project-archive.inf.ed.ac.uk/msc/20162091/msc{\_}proj.pdf},
year = {2016}
}
@article{Srivastava2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different " thinned " networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
archivePrefix = {arXiv},
arxivId = {1102.4807},
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
doi = {10.1214/12-AOS1000},
eprint = {1102.4807},
file = {:home/tkorthals/Documents/Mendeley Desktop/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,model combination,neural networks,regularization},
mendeley-groups = {Machine Learning/Tutorials},
pages = {1929--1958},
pmid = {23285570},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Dhall2017,
abstract = {With the advent of autonomous vehicles, LiDAR and cameras have become an indispensable combination of sensors. They both provide rich and complementary data which can be used by various algorithms and machine learning to sense and make vital inferences about the surroundings. We propose a novel pipeline and experimental setup to find accurate rigid-body transformation for extrinsically calibrating a LiDAR and a camera. The pipeling uses 3D-3D point correspondences in LiDAR and camera frame and gives a closed form solution. We further show the accuracy of the estimate by fusing point clouds from two stereo cameras which align perfectly with the rotation and translation estimated by our method, confirming the accuracy of our method's estimates both mathematically and visually. Taking our idea of extrinsic LiDAR-camera calibration forward, we demonstrate how two cameras with no overlapping field-of-view can also be calibrated extrinsically using 3D point correspondences. The code has been made available as open-source software in the form of a ROS package, more information about which can be sought here: https://github.com/ankitdhall/lidar{\_}camera{\_}calibration .},
archivePrefix = {arXiv},
arxivId = {1705.09785},
author = {Dhall, Ankit and Chelani, Kunal and Radhakrishnan, Vishnu and Krishna, K. M.},
eprint = {1705.09785},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dhall et al. - 2017 - LiDAR-Camera Calibration using 3D-3D Point correspondences.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
pages = {1--19},
title = {{LiDAR-Camera Calibration using 3D-3D Point correspondences}},
url = {http://arxiv.org/abs/1705.09785},
year = {2017}
}
@article{Bouchacourt2017,
abstract = {We would like to learn a representation of the data which decomposes an observation into factors of variation which we can independently control. Specifically, we want to use minimal supervision to learn a latent representation that reflects the semantics behind a specific grouping of the data, where within a group the samples share a common factor of variation. For example, consider a collection of face images grouped by identity. We wish to anchor the semantics of the grouping into a relevant and disentangled representation that we can easily exploit. However, existing deep probabilistic models often assume that the observations are independent and identically distributed. We present the Multi-Level Variational Autoencoder (ML-VAE), a new deep probabilistic model for learning a disentangled representation of a set of grouped observations. The ML-VAE separates the latent representation into semantically meaningful parts by working both at the group level and the observation level, while retaining efficient test-time inference. Quantitative and qualitative evaluations show that the ML-VAE model (i) learns a semantically meaningful disentanglement of grouped data, (ii) enables manipulation of the latent representation, and (iii) generalises to unseen groups.},
archivePrefix = {arXiv},
arxivId = {1705.08841},
author = {Bouchacourt, Diane and Tomioka, Ryota and Nowozin, Sebastian},
eprint = {1705.08841},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bouchacourt, Tomioka, Nowozin - 2017 - Multi-Level Variational Autoencoder Learning Disentangled Representations from Grouped Observatio.pdf:pdf},
mendeley-groups = {VAE/Disentagled},
title = {{Multi-Level Variational Autoencoder: Learning Disentangled Representations from Grouped Observations}},
url = {http://arxiv.org/abs/1705.08841},
year = {2017}
}
@article{Li2017,
abstract = {In this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called SDVAE, which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via equation constraint. To further enhance the feature learning ability of the proposed VAE, we incorporate reinforcement learning to relieve the lack of data. The dynamic framework is capable of dealing with both image and text data with its corresponding encoder and decoder networks. Extensive experiments on image and text datasets demonstrate the effectiveness of the proposed framework.},
archivePrefix = {arXiv},
arxivId = {1709.05047},
author = {Li, Yang and Pan, Quan and Wang, Suhang and Peng, Haiyun and Yang, Tao and Cambria, Erik},
doi = {10.1109/CVPR.2017.90},
eprint = {1709.05047},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li et al. - 2017 - Disentangled Variational Auto-Encoder for Semi-supervised Learning.pdf:pdf},
isbn = {978-1-5386-0457-1},
issn = {1063-6919},
mendeley-groups = {VAE/Disentagled},
pages = {1--10},
title = {{Disentangled Variational Auto-Encoder for Semi-supervised Learning}},
url = {http://arxiv.org/abs/1709.05047},
year = {2017}
}
@misc{,
mendeley-groups = {Machine Learning/RL/Multi Agent,Machine Learning/Tutorials},
title = {{Multi-Agent Reinforcement Learning}},
url = {https://www.youtube.com/watch?v=hGEz4Aumd1U}
}
@article{Samek2017,
abstract = {With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.},
archivePrefix = {arXiv},
arxivId = {1708.08296},
author = {Samek, Wojciech and Wiegand, Thomas and M{\"{u}}ller, Klaus-Robert},
eprint = {1708.08296},
file = {:home/tkorthals/Documents/Mendeley Desktop/Samek, Wiegand, M{\"{u}}ller - 2017 - EXPLAINABLE ARTIFICIAL INTELLIGENCE UNDERSTANDING , VISUALIZING AND INTERPRETING DEEP LEARNING MODELS.pdf:pdf},
keywords = {artificial intelligence,black-box models,deep neural networks,interpretability,layer-wise relevance,propagation,sensitivity analysis},
mendeley-groups = {Machine Learning/Tutorials},
number = {1},
pages = {1--10},
title = {{Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models}},
url = {http://arxiv.org/abs/1708.08296},
year = {2017}
}
@misc{Hinton2013,
author = {Hinton, Geoffrey},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hinton - 2013 - The Origin of Variational Bayes The origin of variational Bayes.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{The Origin of Variational Bayes The origin of variational Bayes}},
year = {2013}
}
@misc{SALU2017,
author = {SALU},
file = {:home/tkorthals/Documents/Mendeley Desktop/SALU - 2017 - SGD Adam Which One Is The Best Optimizer Dogs- VS-Cats Toy Experiment.pdf:pdf},
mendeley-groups = {Machine Learning/Tutorials},
title = {{SGD {\textgreater} Adam ?? Which One Is The Best Optimizer : Dogs- VS-Cats Toy Experiment}},
year = {2017}
}
@misc{Shu2016,
author = {Shu, Rui},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shu - 2016 - Gaussian Mixture VAE Lessons in Variational Inference, Generative Models, and Deep Nets.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {1--10},
title = {{Gaussian Mixture VAE: Lessons in Variational Inference, Generative Models, and Deep Nets}},
url = {http://ruishu.io/2016/12/25/gmvae/},
year = {2016}
}
@article{Foerster2016,
abstract = {We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.},
archivePrefix = {arXiv},
arxivId = {1605.06676},
author = {Foerster, Jakob N. and Assael, Yannis M. and de Freitas, Nando and Whiteson, Shimon},
doi = {10.7551/ecal},
eprint = {1605.06676},
file = {:home/tkorthals/Documents/Mendeley Desktop/Foerster et al. - 2016 - Learning to Communicate with Deep Multi-Agent Reinforcement Learning.pdf:pdf},
isbn = {2004012439},
issn = {10495258},
mendeley-groups = {Machine Learning/RL/Multi Agent},
number = {Nips},
pages = {1--9},
title = {{Learning to Communicate with Deep Multi-Agent Reinforcement Learning}},
url = {http://arxiv.org/abs/1605.06676 https://www.youtube.com/watch?v=xL-GKD49FXs},
year = {2016}
}
@article{Corduneanu2001,
abstract = {Mixture models, in which a probability distribu-tion is represented as a linear superposition of component distributions, are widely used in sta-tistical modelling and pattern recognition. One of the key tasks in the application of mixture models is the determination of a suitable number of components. Conventional approaches based on cross-validation are computationally expen-sive, are wasteful of data, and give noisy esti-mates for the optimal number of components. A fully Bayesian treatment, based on Markov chain Monte Carlo methods for instance, will re-turn a posterior distribution over the number of components. However, in practical applications it is generally convenient, or even computation-ally essential, to select a single, most appropri-ate model. Recently it has been shown, in the context of linear latent variable models, that the use of hierarchical priors governed by continu-ous hyper-parameters whose values are set by type-II maximum likelihood, can be used to opti-mize model complexity. In this paper we extend this framework to mixture distributions by con-sidering the classical task of density estimation using mixtures of Gaussians. We show that, by setting the mixing coefficients to maximize the marginal log-likelihood, unwanted components can be suppressed, and the appropriate number of components for the mixture can be determined in a single training run without recourse to cross-validation. Our approach uses a variational treat-ment based on a factorized approximation to the posterior distribution.},
author = {Corduneanu, Adrian and Bishop, Christopher M},
doi = {10.1016/j.csda.2006.07.020},
file = {:home/tkorthals/Documents/Mendeley Desktop/Corduneanu, Bishop - 2001 - Variational Bayesian Model Selection for Mixture Distributions.pdf:pdf},
issn = {01679473},
journal = {In Artificial Intelligence and Statistics},
mendeley-groups = {VAE/Priors},
pages = {27--34},
title = {{Variational Bayesian Model Selection for Mixture Distributions}},
url = {http://research.microsoft.com/∼cmbishop},
year = {2001}
}
@article{Tzikas2008,
abstract = {The influence of this Thomas Bayes' work was immense. It was from here that "Bayesian" ideas first spread through the mathematical world, as Bayes's own article was ignored until 1780 and played no important role in scientific debate until the 20th century. It was also this article of Laplace's that introduced the mathematical techniques for the asymptotic analysis of posterior distributions that are still employed today. And it was here that the earliest example of optimum estimation can be found, the derivation and characterization of an estimator that minimized a particular measure of posterior expected loss. After more than two centuries, we mathematicians, statisticians cannot only recognize our roots in this masterpiece of our science, we can still learn from it.},
author = {Tzikas, D.G. and Likas, A.C. and Galatsanos, N.P.},
doi = {10.1109/MSP.2008.929620},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tzikas, Likas, Galatsanos - 2008 - The variational approximation for Bayesian inference.pdf:pdf},
isbn = {1053-5888},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
mendeley-groups = {VAE/Tutorials},
number = {November},
pages = {131--146},
title = {{The variational approximation for Bayesian inference}},
url = {http://www.cs.uoi.gr/{~}arly/papers/SPM08.pdf},
volume = {25},
year = {2008}
}
@article{Higgins2017,
abstract = {Domain adaptation is an important open problem in deep reinforcement learning (RL). In many scenarios of interest data is hard to obtain, so agents may learn a source policy in a setting where data is readily available, with the hope that it generalises well to the target domain. We propose a new multi-stage RL agent, DARLA (DisentAngled Representation Learning Agent), which learns to see before learning to act. DARLA's vision is based on learning a disentangled representation of the observed environment. Once DARLA can see, it is able to acquire source policies that are robust to many domain shifts - even with no access to the target domain. DARLA significantly outperforms conventional baselines in zero-shot domain adaptation scenarios, an effect that holds across a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms (DQN, A3C and EC).},
archivePrefix = {arXiv},
arxivId = {1707.08475},
author = {Higgins, Irina and Pal, Arka and Rusu, Andrei A. and Matthey, Loic and Burgess, Christopher P and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
eprint = {1707.08475},
file = {:home/tkorthals/Documents/Mendeley Desktop/Higgins et al. - 2017 - DARLA Improving Zero-Shot Transfer in Reinforcement Learning.pdf:pdf},
issn = {1938-7228},
mendeley-groups = {Machine Learning/RL},
title = {{DARLA: Improving Zero-Shot Transfer in Reinforcement Learning}},
url = {http://arxiv.org/abs/1707.08475},
year = {2017}
}
@article{Higgins2016,
abstract = {Automated discovery of early visual concepts from raw image data is a major open challenge in AI research. Addressing this problem, we propose an unsupervised approach for learning disentangled representations of the underlying factors of variation. We draw inspiration from neuroscience, and show how this can be achieved in an unsupervised generative model by applying the same learning pressures as have been suggested to act in the ventral visual stream in the brain. By enforcing redundancy reduction, encouraging statistical independence, and exposure to data with transform continuities analogous to those to which human infants are exposed, we obtain a variational autoencoder (VAE) framework capable of learning disentangled factors. Our approach makes few assumptions and works well across a wide variety of datasets. Furthermore, our solution has useful emergent properties, such as zero-shot inference and an intuitive understanding of "objectness".},
archivePrefix = {arXiv},
arxivId = {1606.05579},
author = {Higgins, Irina and Matthey, Loic and Glorot, Xavier and Pal, Arka and Uria, Benigno and Blundell, Charles and Mohamed, Shakir and Lerchner, Alexander},
eprint = {1606.05579},
file = {:home/tkorthals/Documents/Mendeley Desktop/Higgins et al. - Unknown - Early Visual Concept Learning with Unsupervised Deep Learning arXiv 1606 . 05579v3 stat . ML 20 Sep 2016.pdf:pdf},
mendeley-groups = {Machine Learning/RL,VAE/Disentagled},
title = {{Early Visual Concept Learning with Unsupervised Deep Learning}},
url = {http://arxiv.org/abs/1606.05579},
year = {2016}
}
@misc{Ciortuz2014,
author = {Ciortuz, Liviu},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ciortuz - 2014 - What is Machine Learning.pdf:pdf},
mendeley-groups = {Machine Learning/Tutorials},
pages = {0--13},
title = {{What is Machine Learning ?}},
year = {2014}
}
@article{Jaderberg,
archivePrefix = {arXiv},
arxivId = {arXiv:1807.01281v1},
author = {Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
doi = {arXiv:1807.01281},
eprint = {arXiv:1807.01281v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jaderberg et al. - Unknown - Human-level performance in first-person multiplayer games with population-based deep reinforcement learning.pdf:pdf},
mendeley-groups = {Machine Learning/RL},
title = {{Human-level performance in first-person multiplayer games with population-based deep reinforcement learning}}
}
@article{Karl2016,
abstract = {We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.},
archivePrefix = {arXiv},
arxivId = {1605.06432},
author = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},
eprint = {1605.06432},
file = {:home/tkorthals/Documents/Mendeley Desktop/Karl et al. - 2016 - Deep Variational Bayes Filters Unsupervised Learning of State Space Models from Raw Data.pdf:pdf},
mendeley-groups = {VAE/Whats More},
number = {ii},
pages = {1--13},
title = {{Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}},
url = {http://arxiv.org/abs/1605.06432},
year = {2016}
}
@misc{ArxivInsights2018,
author = {{Arxiv Insights}},
mendeley-groups = {Machine Learning/Tutorials},
title = {{An introduction to Reinforcement Learning}},
url = {https://www.youtube.com/watch?v=JgvyzIkgxF0},
year = {2018}
}
@misc{Shibuya2017,
author = {Shibuya, Naoki},
booktitle = {Towards Data Science},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shibuya - 2017 - How to Reduce Image Noises by Autoencoder.pdf:pdf},
mendeley-groups = {VAE/Denoising},
title = {{How to Reduce Image Noises by Autoencoder}},
url = {https://towardsdatascience.com/how-to-reduce-image-noises-by-autoencoder-65d5e6de543},
year = {2017}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
doi = {10.1038/nature14236},
eprint = {1502.04623},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gregor et al. - 2015 - DRAW A Recurrent Neural Network For Image Generation.pdf:pdf},
isbn = {9781510810587},
issn = {0028-0836},
mendeley-groups = {VAE},
pmid = {25719670},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
url = {http://arxiv.org/abs/1502.04623},
year = {2015}
}
@misc{Metzen2015,
author = {Metzen, Jan Hendrik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Autoencoder - 2015 - Jan Hendrik Metzen ( httpsjmetzen.github.io) Variational Autoencoder in TensorFlow Variational Autoencoder in Tenso.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Variational Autoencoder in TensorFlow}},
year = {2015}
}
@article{VanHasselt2015,
abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
archivePrefix = {arXiv},
arxivId = {1509.06461},
author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
doi = {10.1016/j.artint.2015.09.002},
eprint = {1509.06461},
file = {:home/tkorthals/Documents/Mendeley Desktop/van Hasselt, Guez, Silver - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
mendeley-groups = {Machine Learning/RL},
pmid = {26150344},
title = {{Deep Reinforcement Learning with Double Q-learning}},
url = {http://arxiv.org/abs/1509.06461},
year = {2015}
}
@misc{Makadia2018,
author = {Makadia, Mitul},
file = {:home/tkorthals/Documents/Mendeley Desktop/Makadia - 2018 - Top 8 Deep Learning Frameworks.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Top 8 Deep Learning Frameworks}},
url = {https://dzone.com/articles/8-best-deep-learning-frameworks},
year = {2018}
}
@article{Tran2017,
abstract = {We examine how learning from unaligned data can improve both the data effi-ciency of supervised tasks as well as enable alignments without any supervision. For example, consider unsupervised machine translation: the input is two corpora of English and French, and the task is to translate from one language to the other but without any pairs of English and French sentences. To address this, we de-velop feature matching auto-encoders (FMAEs). FMAEs ensure that the marginal distribution of feature layers is preserved across forward and inverse mappings between domains. FMAEs achieve state of the art for semi-supervised neural ma-chine translation with significant BLEU score differences of up to 5.7 and 6.3 over traditional supervised models. Furthermore, on English-to-German, FMAEs out-perform last year's best models such as ByteNet [8] while using only half as many supervised examples.},
author = {Tran, Dustin and Burda, Yura and Ilya, Openai and Openai, Sutskever},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tran et al. - 2017 - Feature-Matching Auto-Encoders.pdf:pdf},
journal = {NIPS 2017 Bayesian Deep Learning Workshop},
mendeley-groups = {VAE},
number = {Nips},
pages = {1--6},
title = {{Feature-Matching Auto-Encoders}},
url = {http://bayesiandeeplearning.org/2017/papers/58.pdf},
year = {2017}
}
@misc{Monn2017,
author = {Monn, Dominic and Engineer, Deep Learning},
file = {:home/tkorthals/Documents/Mendeley Desktop/Monn, Engineer - 2017 - Denoising Autoencoders explained.pdf:pdf},
mendeley-groups = {VAE/Denoising},
title = {{Denoising Autoencoders explained}},
url = {https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2},
year = {2017}
}
@misc{Porciani2013,
author = {Porciani, Cristiano},
booktitle = {Observational Cosmology},
file = {:home/tkorthals/Documents/Mendeley Desktop/Porciani - 2013 - Posterior probability and Application Markov Chain Monte Carlo method.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {60--90},
title = {{Posterior probability and Application: Markov Chain Monte Carlo method}},
url = {https://astro.uni-bonn.de/{~}kbasu/ObsCosmo/Slides2012/Lecture3{\_}2012.pdf},
year = {2013}
}
@article{Chen2016,
abstract = {Representation learning seeks to expose certain aspects of observed data in a learned representation that's amenable to downstream tasks like classification. For instance, a good representation for 2D images might be one that describes only global structure and discards information about detailed texture. In this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE model allows us to have control over what the global latent code can learn and , by designing the architecture accordingly, we can force the global latent code to discard irrelevant information such as texture in 2D images, and hence the VAE only "autoencodes" data in a lossy fashion. In addition, by leveraging autoregressive models as both prior distribution {\$}p(z){\$} and decoding distribution {\$}p(x|z){\$}, we can greatly improve generative modeling performance of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and Caltech-101 Silhouettes density estimation tasks.},
archivePrefix = {arXiv},
arxivId = {1611.02731},
author = {Chen, Xi and Kingma, Diederik P. and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
eprint = {1611.02731},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chen et al. - 2016 - Variational Lossy Autoencoder.pdf:pdf},
mendeley-groups = {VAE},
pages = {1--17},
title = {{Variational Lossy Autoencoder}},
url = {http://arxiv.org/abs/1611.02731},
year = {2016}
}
@article{Graca2009,
abstract = {We address the problem of learning structured unsupervised models with moment sparsity typical in many natural language induction tasks. For example, in unsu- pervised part-of-speech (POS) induction using hidden Markov models, we intro- duce a bias for words to be labeled by a small number of tags. In order to express this bias of posterior sparsity as opposed to parametric sparsity, we extend the pos- terior regularization framework [7]. We evaluate our methods on three languages —English, Bulgarian and Portuguese—showing consistent and significant accu- racy improvement over EM-trained HMMs, and HMMs with sparsity-inducing Dirichlet priors trained by variational EM. We increase accuracy with respect to EM by 2.3{\%}-6.5{\%} in a purely unsupervised setting as well as in a weakly- supervised setting where the closed-class words are provided. Finally, we show improvements using our method when using the induced clusters as features of a discriminative model in a semi-supervised setting.},
author = {Gra{\c{c}}a, Jo{\~{a}}o and Ganchev, Kuzman and Taskar, Ben and Pereira, Fernando},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gra{\c{c}}a et al. - 2009 - Posterior vs. Parameter Sparsity in Latent Variable Models Supplementary Material.pdf:pdf},
isbn = {9781615679119},
journal = {Advances in Neural Information Processing Systems 22 - NIPS'09},
mendeley-groups = {VAE/Tutorials},
pages = {664--672},
title = {{Posterior vs. Parameter Sparsity in Latent Variable Models Supplementary Material}},
url = {http://www.citeulike.org/user/zhengyun/article/6420309{\%}5Cnhttp://www.seas.upenn.edu/{~}taskar/pubs/nips09.pdf},
year = {2009}
}
@misc{Coursera,
author = {Coursera},
mendeley-groups = {VAE/Priors},
title = {{Learning with priors}},
url = {https://www.coursera.org/lecture/bayesian-methods-in-machine-learning/learning-with-priors-0mkuB}
}
@article{Wei2017,
abstract = {Cross-language learning allows one to use training data from one language to build models for an-other language. Many traditional approaches re-quire word-level alignment sentences from paral-lel corpora, in this paper we define a general bilin-gual training objective function requiring sentence level parallel corpus only. We propose a variational autoencoding approach for training bilingual word embeddings. The variational model introduces a continuous latent variable to explicitly model the underlying semantics of the parallel sentence pairs and to guide the generation of the sentence pairs. Our model restricts the bilingual word embeddings to represent words in exactly the same continuous vector space. Empirical results on the task of cross lingual document classification has shown that our method is effective.},
author = {Wei, Liangchen and Deng, Zhi Hong},
doi = {10.24963/ijcai.2017/582},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wei, Deng - 2017 - A variational autoencoding approach for inducing cross-lingual word embeddings.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Natural Language Processing, Natural Language Sema,Natural Language Processing, Text Classification},
mendeley-groups = {VAE/Multi-Modal},
pages = {4165--4171},
title = {{A variational autoencoding approach for inducing cross-lingual word embeddings}},
year = {2017}
}
@article{Wu2018,
abstract = {Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the MVAE on four datasets and show that we match state-of-the-art performance using many fewer parameters. In addition, we show that the MVAE is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider a case study of learning image transformations---edge detection, colorization, facial landmark segmentation, etc.---as a set of modalities. We find appealing results across this range of tasks.},
archivePrefix = {arXiv},
arxivId = {1802.05335},
author = {Wu, Mike and Goodman, Noah},
eprint = {1802.05335},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wu, Goodman - 2018 - Multimodal Generative Models for Scalable Weakly-Supervised Learning.pdf:pdf},
mendeley-groups = {VAE/Multi-Modal},
title = {{Multimodal Generative Models for Scalable Weakly-Supervised Learning}},
url = {http://arxiv.org/abs/1802.05335},
year = {2018}
}
@article{Hoffman2016,
abstract = {We rewrite the variational evidence lower bound objective (ELBO) of variational autoencoders in a way that highlights the role of the encoded data distribution. This perspective suggests that to improve our variational bounds we should improve our priors and not just the encoder and decoder.},
author = {Hoffman, Matthew D and Johnson, Matthew J and Brain, Google},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hoffman, Johnson, Brain - 2016 - ELBO surgery yet another way to carve up the variational evidence lower bound.pdf:pdf},
journal = {Advances in Approximate Bayesian Inference, NIPS Workshop},
mendeley-groups = {VAE/Priors},
number = {5},
title = {{ELBO surgery: yet another way to carve up the variational evidence lower bound}},
url = {http://approximateinference.org/accepted/HoffmanJohnson2016.pdf},
year = {2016}
}
@article{Nalisnick,
abstract = {Motivation: Overview of research on deep generative models, and why we should consider priors different than the current ones.},
author = {Nalisnick, Eric and Smyth, Padhraic},
file = {:home/tkorthals/Documents/Mendeley Desktop/Nalisnick, Smyth - Unknown - Alternative Priors for Deep Generative Models.pdf:pdf},
mendeley-groups = {VAE/Priors},
title = {{Alternative Priors for Deep Generative Models}},
url = {https://www.ics.uci.edu/{~}enalisni/nalisnick{\_}openAI{\_}talk.pdf}
}
@misc{,
mendeley-groups = {VAE/Priors},
title = {{Mixture of Gaussians Prior}},
url = {https://github.com/RuiShu/vae-experiments/tree/master/modality}
}
@article{Rezende2015,
abstract = {We present a variational inference method defined through gradient ascent on the likelihood function. This method can be used to improve existing posterior ap-proximations or as part of a recognition network in variational autoencoders. De-spite its simplicity, it proves to be competitive on standard benchmarks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.05770v6},
author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
eprint = {arXiv:1505.05770v6},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rezende, Mohamed - 2015 - Variational Inference with Normalizing Flows.pdf:pdf},
isbn = {1505.05770},
issn = {1938-7228},
journal = {NIPS Workshop},
mendeley-groups = {VAE/Tutorials},
pages = {3--6},
title = {{Variational Inference with Normalizing Flows}},
volume = {37},
year = {2015}
}
@article{Jiang2017,
abstract = {Clustering is among the most fundamental tasks in computer vision and machine learning. In this paper, we propose Variational Deep Embedding (VaDE), a novel unsupervised generative clustering approach within the framework of Variational Auto-Encoder (VAE). Specifically, VaDE models the data generative procedure with a Gaussian Mixture Model (GMM) and a deep neural network (DNN): 1) the GMM picks a cluster; 2) from which a latent embedding is generated; 3) then the DNN decodes the latent embedding into observables. Inference in VaDE is done in a variational way: a different DNN is used to encode observables to latent embeddings, so that the evidence lower bound (ELBO) can be optimized using Stochastic Gradient Variational Bayes (SGVB) estimator and the reparameterization trick. Quantitative comparisons with strong baselines are included in this paper, and experimental results show that VaDE significantly outperforms the state-of-the-art clustering methods on 4 benchmarks from various modalities. Moreover, by VaDE's generative nature, we show its capability of generating highly realistic samples for any specified cluster, without using supervised information during training. Lastly, VaDE is a flexible and extensible framework for unsupervised generative clustering, more general mixture models than GMM can be easily plugged in.},
archivePrefix = {arXiv},
arxivId = {1611.05148},
author = {Jiang, Zhuxi and Zheng, Yin and Tan, Huachun and Tang, Bangsheng and Zhou, Hanning},
doi = {10.24963/ijcai.2017/273},
eprint = {1611.05148},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jiang et al. - 2017 - Variational deep embedding An unsupervised generative approach to Clustering.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
mendeley-groups = {VAE/Priors},
pages = {1965--1972},
title = {{Variational deep embedding: An unsupervised generative approach to Clustering}},
year = {2017}
}
@article{Jang2018,
author = {Jang, Eric},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jang - 2018 - Normalizing Flows Tutorial, Part 1 Distributions and Determinants.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {1--8},
title = {{Normalizing Flows Tutorial, Part 1: Distributions and Determinants}},
url = {https://blog.evjang.com/2018/01/nf1.html},
year = {2018}
}
@misc{He2017,
author = {He, Tong},
file = {:home/tkorthals/Documents/Mendeley Desktop/He - 2017 - Posterior Approximation for Variational Inference.pdf:pdf},
mendeley-groups = {VAE/Priors},
title = {{Posterior Approximation for Variational Inference}},
year = {2017}
}
@misc{Jang,
author = {Jang, Eric},
keywords = {Twitter},
mendeley-groups = {VAE/Tutorials},
title = {{Twitter: Normalizing Flow bending the space}},
url = {https://twitter.com/zzznah/status/1019987106523992064}
}
@article{Deshpande2016,
abstract = {In this post, we'll go into summarizing a lot of the new and important developments in the field of computer vision and convolutional neural networks. We'll look at some of the most important papers that have been published over the last 5 years and discuss why they're so important. The first half of the list (AlexNet to ResNet) deals with advancements in general network architecture, while the second half is just a collection of interesting papers in other subareas. AlexNet},
author = {Deshpande, Adit},
file = {:home/tkorthals/Documents/Mendeley Desktop/Deshpande - 2016 - Understanding CNNs The 9 Deep Learning Papers You Need to Know About Part 3.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
number = {2012},
pages = {1--19},
title = {{Understanding CNNs The 9 Deep Learning Papers You Need to Know About Part 3}},
url = {https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html},
year = {2016}
}
@article{Tomczak2017,
abstract = {Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call "Variational Mixture of Posteriors" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague VAEs. We provide empirical studies on six datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks.},
archivePrefix = {arXiv},
arxivId = {1705.07120},
author = {Tomczak, Jakub M. and Welling, Max},
eprint = {1705.07120},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tomczak, Welling - 2017 - VAE with a VampPrior.pdf:pdf},
mendeley-groups = {VAE/Priors},
title = {{VAE with a VampPrior}},
url = {http://arxiv.org/abs/1705.07120},
year = {2017}
}
@misc{Kingma2016,
author = {Kingma, Diederik P.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kingma - 2016 - Pre-training with VAE.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Pre-training with VAE}},
year = {2016}
}
@article{Burgard2005,
author = {Burgard, Wolfram and Moors, Mark and Stachniss, Cyrill and Member, Student and Schneider, Frank E},
file = {:home/tkorthals/Documents/Mendeley Desktop/Burgard et al. - 2005 - Coordinated Multi-Robot Exploration.pdf:pdf},
mendeley-groups = {Robotics/Multirobotics},
number = {3},
pages = {376--386},
title = {{Coordinated Multi-Robot Exploration}},
volume = {21},
year = {2005}
}
@article{Jang2018b,
author = {Jang, Eric},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jang - 2018 - Normalizing Flows Tutorial, Part 2 Modern Normalizing Flows.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {1--8},
title = {{Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows}},
url = {https://blog.evjang.com/2018/01/nf2.html},
year = {2018}
}
@misc{Theconstructsim,
author = {Theconstructsim},
mendeley-groups = {Machine Learning/RL},
title = {{OpenAI Gym for ROS Based Robots 101}},
url = {http://www.theconstructsim.com/construct-learn-develop-robots-using-ros/robotigniteacademy{\_}learnros/ros-courses-library/openai-gym-for-robotics-ros/}
}
@article{Berthelot2018,
archivePrefix = {arXiv},
arxivId = {1807.07543},
author = {Berthelot, David and Raffel, Colin and Roy, Aurko and Goodfellow, Ian},
eprint = {1807.07543},
file = {:home/tkorthals/Documents/Mendeley Desktop/Berthelot, Goodfellow, Roy - Unknown - Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer.pdf:pdf},
mendeley-groups = {VAE},
title = {{Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer}},
url = {https://arxiv.org/abs/1807.07543},
year = {2018}
}
@article{Li2017a,
abstract = {We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions.},
archivePrefix = {arXiv},
arxivId = {1701.07274},
author = {Li, Yuxi},
doi = {10.1007/978-3-319-56991-8_32},
eprint = {1701.07274},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li - 2017 - Deep Reinforcement Learning An Overview(2).pdf:pdf},
isbn = {9781509011216},
issn = {1701.07274},
mendeley-groups = {Machine Learning/RL},
pages = {1--70},
pmid = {15040217},
title = {{Deep Reinforcement Learning: An Overview}},
url = {http://arxiv.org/abs/1701.07274 http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/},
year = {2017}
}
@misc{Moran,
author = {Moran, Ben},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moran - Unknown - Variational Bayes and the evidence lower bound.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Variational Bayes and the evidence lower bound}},
url = {https://benmoran.wordpress.com/2015/02/21/variational-bayes-and-the-evidence-lower-bound/}
}
@article{Blei2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.05683v1},
author = {Blei, David M and Bishop, Christopher M.},
doi = {10.16373/j.cnki.ahr.150049},
eprint = {arXiv:1610.05683v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Blei, Bishop - 2017 - Variational Inference.pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Blei, Bishop - 2017 - Variational Inference.ipynb:ipynb},
isbn = {0894-0282},
issn = {00237205},
keywords = {cavi,download notebook,elbo,gaussian,kl-divergence,latent variables,mean-field approximation,mixture model,normal distribution,optimization,variational inference},
mendeley-groups = {VAE/Tutorials},
pages = {1--12},
pmid = {22352717},
title = {{Variational Inference}},
year = {2017}
}
@article{Boyd-Graber,
author = {Boyd-Graber, Jordan},
mendeley-groups = {VAE/Tutorials},
title = {{Machine Learning: Variational Inference}},
url = {https://www.youtube.com/watch?v=2pEkWk-LHmU}
}
@misc{Blei,
author = {Blei, David},
mendeley-groups = {VAE/Tutorials},
title = {{Variational Inference: Foundations and Innovations}},
url = {https://www.youtube.com/watch?v=Dv86zdWjJKQ}
}
@article{Altosaar2016,
abstract = {Understanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.},
author = {Altosaar, Jaan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Altosaar - 2016 - Tutorial - What is a variational autoencoder.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Tutorial - What is a variational autoencoder?}},
url = {https://jaan.io/what-is-variational-autoencoder-vae-tutorial/},
year = {2016}
}
@article{Pu2016,
abstract = {A novel variational autoencoder is developed to model images, as well as associated labels or captions. The Deep Generative Deconvolutional Network (DGDN) is used as a decoder of the latent image features, and a deep Convolutional Neural Network (CNN) is used as an image encoder; the CNN is used to approximate a distribution for the latent DGDN features/code. The latent code is also linked to generative models for labels (Bayesian support vector machine) or captions (recurrent neural network). When predicting a label/caption for a new image at test, averaging is performed across the distribution of latent codes; this is computationally efficient as a consequence of the learned CNN-based encoder. Since the framework is capable of modeling the image in the presence/absence of associated labels/captions, a new semi-supervised setting is manifested for CNN learning with images; the framework even allows unsupervised CNN learning, based on images alone.},
archivePrefix = {arXiv},
arxivId = {1609.08976},
author = {Pu, Yunchen and Gan, Zhe and Henao, Ricardo and Yuan, Xin and Li, Chunyuan and Stevens, Andrew and Carin, Lawrence},
doi = {10.1109/ICCV.2017.245},
eprint = {1609.08976},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pu et al. - 2016 - Variational Autoencoder for Deep Learning of Images, Labels and Captions.pdf:pdf},
isbn = {978-1-5386-1032-9},
issn = {10495258},
mendeley-groups = {VAE,VAE/Tutorials},
number = {Nips},
title = {{Variational Autoencoder for Deep Learning of Images, Labels and Captions}},
url = {http://arxiv.org/abs/1609.08976},
year = {2016}
}
@article{Jang2018a,
author = {Jang, Eric},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jang - 2018 - A Beginner's Guide to Variational Methods Mean-Field Approximation.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
pages = {1--8},
title = {{A Beginner's Guide to Variational Methods: Mean-Field Approximation}},
url = {https://blog.evjang.com/2016/08/variational-bayes.html},
year = {2018}
}
@article{There2005,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06406v2},
author = {There, Bstract and Networks, Adversarial and Cnn, Pixel-},
eprint = {arXiv:1511.06406v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/There, Networks, Cnn - 2005 - Feature Map Variational Auto-Encoders.pdf:pdf},
isbn = {0898716004},
journal = {Engineering},
mendeley-groups = {VAE},
pages = {1--10},
title = {{Feature Map Variational Auto-Encoders}},
year = {2005}
}
@article{Zhao2017,
abstract = {Deep neural networks have been shown to be very successful at learning feature hierarchies in supervised learning tasks. Generative models, on the other hand, have benefited less from hierarchical models with multiple layers of latent variables. In this paper, we prove that hierarchical latent variable models do not take advantage of the hierarchical structure when trained with existing variational methods, and provide some limitations on the kind of features existing models can learn. Finally we propose an alternative architecture that do not suffer from these limitations. Our model is able to learn highly interpretable and disentangled hierarchical features on several natural image datasets with no task specific regularization or prior knowledge.},
archivePrefix = {arXiv},
arxivId = {1702.08396},
author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
eprint = {1702.08396},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhao, Song, Ermon - 2017 - Learning Hierarchical Features from Generative Models.pdf:pdf},
isbn = {9781510855144},
issn = {1938-7228},
mendeley-groups = {VAE},
title = {{Learning Hierarchical Features from Generative Models}},
url = {http://arxiv.org/abs/1702.08396},
year = {2017}
}
@article{Readme2017,
author = {Readme, Update},
file = {:home/tkorthals/Documents/Mendeley Desktop/Readme - 2017 - ML-ReadingGroup.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{ML-ReadingGroup}},
url = {https://github.com/p-i-/machinelearning-IRC-freenode/blob/master/ReadingGroup/README.md},
year = {2017}
}
@article{Gao2018,
abstract = {Advances in unsupervised learning enable reconstruction and generation of samples from complex distributions, but this success is marred by the inscrutability of the representations learned. We propose an information-theoretic approach to characterizing disentanglement and dependence in representation learning using multivariate mutual information, also called total correlation. The principle of total Cor-relation Ex-planation (CorEx) has motivated successful unsupervised learning applications across a variety of domains, but under some restrictive assumptions. Here we relax those restrictions by introducing a flexible variational lower bound to CorEx. Surprisingly, we find that this lower bound is equivalent to the one in variational autoencoders (VAE) under certain conditions. This information-theoretic view of VAE deepens our understanding of hierarchical VAE and motivates a new algorithm, AnchorVAE, that makes latent codes more interpretable through information maximization and enables generation of richer and more realistic samples.},
archivePrefix = {arXiv},
arxivId = {1802.05822},
author = {Gao, Shuyang and Brekelmans, Rob and Steeg, Greg Ver and Galstyan, Aram},
eprint = {1802.05822},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gao et al. - 2018 - Auto-Encoding Total Correlation Explanation.pdf:pdf},
mendeley-groups = {VAE},
title = {{Auto-Encoding Total Correlation Explanation}},
url = {http://arxiv.org/abs/1802.05822},
year = {2018}
}
@article{Sonderby2016,
abstract = {Variational Autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difficult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model, the Ladder Variational Autoencoder, that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally, we observe that batch normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.},
archivePrefix = {arXiv},
arxivId = {1602.02282},
author = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
eprint = {1602.02282},
file = {:home/tkorthals/Documents/Mendeley Desktop/S{\o}nderby et al. - 2016 - Ladder Variational Autoencoders.pdf:pdf},
issn = {10495258},
mendeley-groups = {VAE},
number = {Nips},
title = {{Ladder Variational Autoencoders}},
url = {http://arxiv.org/abs/1602.02282},
year = {2016}
}
@article{Jones2012,
author = {Jones, Bevan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jones - 2012 - Another Walkthrough of Variational Bayes Variational Bayes.pdf:pdf},
mendeley-groups = {VAE/Tutorials},
title = {{Another Walkthrough of Variational Bayes Variational Bayes}},
url = {https://staff.aist.go.jp/bevan.jones/vb-tutorial-slides.pdf},
year = {2012}
}
@article{Suzuki2018,
abstract = {We investigate deep generative models that can exchange multiple modalities bi-directionally, e.g., generating images from corresponding texts and vice versa. A major approach to achieve this objective is to train a model that integrates all the information of different modalities into a joint representation and then to generate one modality from the corresponding other modality via this joint representation. We simply applied this approach to variational autoencoders (VAEs), which we call a joint multimodal variational autoencoder (JMVAE). However, we found that when this model attempts to generate a large dimensional modality missing at the input, the joint representation collapses and this modality cannot be generated successfully. Furthermore, we confirmed that this difficulty cannot be resolved even using a known solution. Therefore, in this study, we propose two models to prevent this difficulty: JMVAE-kl and JMVAE-h. Results of our experiments demonstrate that these methods can prevent the difficulty above and that they generate modalities bi-directionally with equal or higher likelihood than conventional VAE methods, which generate in only one direction. Moreover, we confirm that these methods can obtain the joint representation appropriately, so that they can generate various variations of modality by moving over the joint representation or changing the value of another modality.},
archivePrefix = {arXiv},
arxivId = {1801.08702},
author = {Suzuki, Masahiro and Nakayama, Kotaro and Matsuo, Yutaka},
eprint = {1801.08702},
file = {:home/tkorthals/Documents/Mendeley Desktop/Suzuki, Nakayama, Matsuo - 2018 - Improving Bi-directional Generation between Different Modalities with Variational Autoencoders.pdf:pdf},
mendeley-groups = {VAE/Multi-Modal},
title = {{Improving Bi-directional Generation between Different Modalities with Variational Autoencoders}},
url = {http://arxiv.org/abs/1801.08702},
year = {2018}
}
@book{OKane2013,
abstract = {ROS (Robot Operating System) is rapidly becoming a de facto standard for writing interoperable and reusable robot software. This book supplements ROS's own documentation, explaining how to interact with existing ROS systems and how to create new ROS programs using C++, with special attention to common mistakes and misunderstandings. The intended audience includes new and potential ROS users.},
author = {O'Kane, Jason M. and Kane, Jason M. O.},
doi = {8-25-2014},
file = {:home/tkorthals/Documents/Mendeley Desktop/O'Kane, Kane - 2013 - A gentle introduction to ROS.pdf:pdf},
isbn = {978-1492143239},
keywords = {()},
mendeley-groups = {Robotics,Robotics/ROS},
pages = {155},
title = {{A gentle introduction to ROS}},
year = {2013}
}
@misc{Day2017,
author = {Day, Harry J.E},
file = {:home/tkorthals/Documents/Mendeley Desktop/Day - 2017 - A Dummy's Guide to Debugging ROS Systems Keep Calm And {\ldots} FIRE !.pdf:pdf},
mendeley-groups = {Robotics,Robotics/ROS},
pages = {1--10},
title = {{A Dummy's Guide to Debugging ROS Systems: Keep Calm And {\ldots} FIRE !}},
url = {http://bluesat.com.au/a-dummys-guide-to-debugging-ros-systems/},
year = {2017}
}
@article{8103116,
abstract = {The success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities. We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field. We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal representations in deep-learning architectures. We highlight two areas of research-regularization strategies and methods that learn or optimize multimodal fusion structures-as exciting areas for future work.},
author = {Ramachandram, D and Taylor, G W},
doi = {10.1109/MSP.2017.2738401},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ramachandram, Taylor - 2017 - Deep Multimodal Learning - A survey on recent advances and trends.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {Computer architecture,Emotion recognition,Face recognition,Machine learning,Sensors,Training data,complex machine-learning problems,deep multimodal learning,deep-learning architectures,image representation,learned multimodal representations,learning (artificial intelligence),multimodal fusion structures,multiple data modalities,research-regularization},
mendeley-groups = {VAE/Multi-Modal},
month = {nov},
number = {6},
pages = {96--108},
title = {{Deep Multimodal Learning: A Survey on Recent Advances and Trends}},
volume = {34},
year = {2017}
}
@article{Monaci2007,
abstract = {Real-world phenomena involve complex interactions between multiple signal modalities. As a consequence, humans are used to integrate at each instant perceptions from all their senses in order to enrich their understanding of the surrounding world. This paradigm can be also extremely useful in many signal processing and computer vision problems involving mutually related signals. The simultaneous processing of multimodal data can, in fact, reveal information that is otherwise hidden when considering the signals independently. However, in natural multimodal signals, the statistical dependencies between modalities are in general not obvious. Learning fundamental multimodal patterns could offer deep insight into the structure of such signals. In this paper, we present a novel model of multimodal signals based on their sparse decomposition over a dictionary of multimodal structures. An algorithm for iteratively learning multimodal generating functions that can be shifted at all positions in the signal is proposed, as well. The learning is defined in such a way that it can be accomplished by iteratively solving a generalized eigenvector problem, which makes the algorithm fast, flexible, and free of user-defined parameters. The proposed algorithm is applied to audiovisual sequences and it is able to discover underlying structures in the data. The detection of such audio-video patterns in audiovisual clips allows to effectively localize the sound source on the video in presence of substantial acoustic and visual distractors, outperforming state-of-the-art audiovisual localization algorithms.},
author = {Monaci, Gianluca and Jost, Philippe and Vandergheynst, Pierre and Mailh{\'{e}}, Boris and Lesage, Sylvain and Gribonval, R{\'{e}}mi},
doi = {10.1109/TIP.2007.901813},
isbn = {1057-7149 (Print)$\backslash$r1057-7149 (Linking)},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Audiovisual source localization,Dictionary learning,Multimodal data processing,Sparse representation},
mendeley-groups = {VAE/Multi-Modal},
pmid = {17784601},
title = {{Learning multimodal dictionaries}},
year = {2007}
}
@article{Ngiam2011,
abstract = {Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned ifmultiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evalu- ate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our mod- els are validated on the CUAVE and AVLet- ters datasets on audio-visual speech classifi- cation, demonstrating best published visual speech classification on AVLetters and effec- tive shared representation learning.},
archivePrefix = {arXiv},
arxivId = {1502.07209},
author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
doi = {10.1145/2647868.2654931},
eprint = {1502.07209},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ngiam et al. - 2011 - Multimodal Deep Learning.pdf:pdf},
isbn = {9781450306195},
issn = {9781450306195},
journal = {Proceedings of The 28th International Conference on Machine Learning (ICML)},
mendeley-groups = {VAE/Multi-Modal},
pmid = {2609986},
title = {{Multimodal Deep Learning}},
year = {2011}
}
@article{Sohn2014,
abstract = {Deep learning has been successfully applied to multimodal representation learn-ing problems, with a common strategy of learning joint representations that are shared across multiple modalities on top of layers of modality-specific networks. Nonetheless, there still remains a question about how to effectively learn asso-ciations between heterogeneous data modalities; in particular, a good generative model of multimodal data should be able to reason about missing data modality given the rest of data modalities. In this paper, we propose a novel multimodal representation learning framework that explicitly aims at this goal by training the model to minimize the variation of information rather than maximizing likelihood. We provide a theoretical insight into why the proposed learning objective is suf-ficient to estimate the data-generating joint distribution of multimodal data. We apply our method to restricted Boltzmann machines and introduce learning algo-rithms based on contrastive divergence and multi-prediction training. Further, we extend our method to deep networks with recurrent encoding for finetuning. In ex-periments, we demonstrate the state-of-the-art visual recognition performance on MIR-Flickr and PASCAL VOC2007 database with and without text observations.},
author = {Sohn, Kihyuk and Shang, Wenling and Lee, Honglak},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sohn, Shang, Lee - 2014 - Improved Multimodal Deep Learning with Variation of Information.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems.},
mendeley-groups = {VAE/Multi-Modal},
title = {{Improved Multimodal Deep Learning with Variation of Information}},
year = {2014}
}
@article{Deng2013,
abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
archivePrefix = {arXiv},
arxivId = {1309.1501},
author = {Deng, Li and Yu, Dong},
doi = {10.1136/bmj.319.7209.0a},
eprint = {1309.1501},
isbn = {9781405161251},
issn = {09598138},
journal = {Foundations and Trends{\textregistered} in Signal Processing},
mendeley-groups = {VAE/Multi-Modal},
pmid = {10463930},
title = {{Deep Learning: Methods and Applications}},
year = {2013}
}
@article{Ramachandram2017,
abstract = {A survey on recent advances and trends T he success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities. We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field. We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal represen-tations in deep-learning architectures. We highlight two areas of research—regularization strategies and methods that learn or optimize multimodal fusion structures—as exciting areas for future work.},
author = {Ramachandram, Dhanesh and Taylor, Graham W},
doi = {10.1109/MSP.2017.2738401},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ramachandram, Taylor - 2017 - Deep Multimodal Learning - A survey on recent advances and trends.pdf:pdf},
issn = {1053-5888},
journal = {IEEE SIgnal ProcESSIng MagazInE},
mendeley-groups = {VAE/Multi-Modal},
title = {{Deep Multimodal Learning - A survey on recent advances and trends}},
year = {2017}
}
@inproceedings{Srivastava2012a,
abstract = {A Deep Boltzmann Machine is described for learning a generative model of data that consists of multiple and diverse input modalities. The model can be used to extract a unified representation that fuses modalities together. We find that this representation is useful for classification and information retrieval tasks. The model works by learning a probability density over the space of multimodal inputs. It uses states of latent variables as representations of the input. The model can extract this representation even when some modalities are absent by sampling from the conditional distribution over them and filling them in. Our experimental results on bi-modal data consisting of images and text show that the Multimodal DBM can learn a good generative model of the joint space of image and text inputs that is useful for information retrieval from both unimodal and multimodal queries. We further demonstrate that this model significantly outperforms SVMs and LDA on discriminative tasks. Finally, we compare our model to other deep learning methods, including autoencoders and deep belief networks, and show that it achieves noticeable gains.},
author = {Srivastava, Nitish and Salakhutdinov, Ruslan},
booktitle = {Advances in neural information processing systems (NIPS)},
doi = {10.1109/CVPR.2013.49},
isbn = {978-0-7695-4989-7},
issn = {10495258},
mendeley-groups = {VAE/Multi-Modal},
pmid = {2479307},
title = {{Multimodal Learning with Deep Boltzmann Machines}},
year = {2012}
}
@article{Salakhutdinov2010,
abstract = {When modeling high-dimensional richly structured data, it is often the case that the distribution defined by the Deep Boltzmann Machine (DBM) has a rough energy landscape with many local minima that are separated by high energy barriers. The commonly used Gibbs sampler tends to get trapped in one local mode, which often results in unstable learning dynamics and leads to poor parameter estimates. In this paper, we concentrate on learning DBM's using adaptive MCMC algorithms. We first show a close connection between Fast PCD and adaptive MCMC. We then develop a Coupled Adaptive Simulated Tempering algorithm that can be used to better explore a highly multimodal energy landscape. Finally, we demonstrate that the proposed algorithm considerably improves parameter estimates, particularly when learning large-scale DBM's.},
author = {Salakhutdinov, Ruslan},
isbn = {9781605589077},
journal = {Learning},
keywords = {boring formatting information,i,machine learning},
mendeley-groups = {VAE/Multi-Modal},
title = {{Learning Deep Boltzmann Machines using Adaptive MCMC}},
year = {2010}
}
@article{Kahou2016,
abstract = {The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques, each focusing on one modality. Among these are a convolutional neural network, focusing on capturing visual information in detected faces, a deep belief net focusing on the representation of the audio stream, a K-Means based "bag-of-mouths" model, which extracts visual features around the mouth region and a relational autoencoder, which addresses spatio-temporal aspects of videos. We explore multiple methods for the combination of cues from these modalities into one common classifier. This achieves a considerably greater accuracy than predictions from our strongest single-modality classifier. Our method was the winning submission in the 2013 EmotiW challenge and achieved a test set accuracy of 47.67{\%} on the 2014 dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.01800v2},
author = {Kahou, Samira Ebrahimi and Bouthillier, Xavier and Lamblin, Pascal and Gulcehre, Caglar and Michalski, Vincent and Konda, Kishore and Jean, S{\'{e}}bastien and Froumenty, Pierre and Dauphin, Yann and Boulanger-Lewandowski, Nicolas and {Chandias Ferrari}, Raul and Mirza, Mehdi and Warde-Farley, David and Courville, Aaron and Vincent, Pascal and Memisevic, Roland and Pal, Christopher and Bengio, Yoshua},
doi = {10.1007/s12193-015-0195-2},
eprint = {arXiv:1503.01800v2},
issn = {17838738},
journal = {Journal on Multimodal User Interfaces},
keywords = {Deep learning,Emotion recognition,Model combination,Multimodal learning},
mendeley-groups = {VAE/Multi-Modal},
title = {{EmoNets: Multimodal deep learning approaches for emotion recognition in video}},
year = {2016}
}
@inproceedings{Eitel2015,
abstract = {Robust object recognition is a crucial ingredient of many, if not all, real-world robotics applications. This paper leverages recent progress on Convolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture for object recognition. Our architecture is composed of two separate CNN processing streams - one for each modality - which are consecutively combined with a late fusion network. We focus on learning with imperfect sensor data, a typical problem in real-world robotics tasks. For accurate learning, we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs. The first, an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets. The second, a data augmentation scheme for robust learning with depth images by corrupting them with realistic noise patterns. We present state-of-the-art results on the RGB-D object dataset and show recognition in challenging RGB-D real-world noisy settings.},
archivePrefix = {arXiv},
arxivId = {1507.06821},
author = {Eitel, Andreas and Springenberg, Jost Tobias and Spinello, Luciano and Riedmiller, Martin and Burgard, Wolfram},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7353446},
eprint = {1507.06821},
isbn = {9781479999941},
issn = {21530866},
mendeley-groups = {VAE/Multi-Modal},
title = {{Multimodal deep learning for robust RGB-D object recognition}},
year = {2015}
}
@article{Noda2014,
abstract = {For humans to accurately understand the world around them, multimodal integration is essential because it enhances perceptual precision and reduces ambiguity. Computational models replicating such human ability may contribute to the practical use of robots in daily human living environments; however, primarily because of scalability problems that conventional machine learning algorithms suffer from, sensory-motor information processing in robotic applications has typically been achieved via modal-dependent processes. In this paper, we propose a novel computational framework enabling the integration of sensory-motor time-series data and the self-organization of multimodal fused representations based on a deep learning approach. To evaluate our proposed model, we conducted two behavior-learning experiments utilizing a humanoid robot; the experiments consisted of object manipulation and bell-ringing tasks. From our experimental results, we show that large amounts of sensory-motor information, including raw RGB images, sound spectrums, and joint angles, are directly fused to generate higher-level multimodal representations. Further, we demonstrated that our proposed framework realizes the following three functions: (1) cross-modal memory retrieval utilizing the information complementation capability of the deep autoencoder; (2) noise-robust behavior recognition utilizing the generalization capability of multimodal features; and (3) multimodal causality acquisition and sensory-motor prediction based on the acquired causality. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
author = {Noda, Kuniaki and Arie, Hiroaki and Suga, Yuki and Ogata, Tetsuya},
doi = {10.1016/j.robot.2014.03.003},
isbn = {9781467363587},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Cross-modal memory retrieval,Deep learning,Multimodal integration,Object manipulation},
mendeley-groups = {VAE/Multi-Modal},
title = {{Multimodal integration learning of robot behavior using deep neural networks}},
year = {2014}
}
@article{Cheng2018,
abstract = {ISSN: 2168-1163 (Print) 2168-1171 (Online) Journal homepage: http://www.tandfonline.com/loi/tciv20 ABSTRACT An effective similarity measure for multi-modal images is crucial for medical image fusion in many clinical applications. The underlining correlation across modalities is usually too complex to be modelled by intensity-based statistical metrics. Therefore, approaches of learning a similarity metric are proposed in recent years. In this work, we propose a novel deep similarity learning method that trains a binary classifier to learn the correspondence of two image patches. The classification output is transformed to a continuous probability value, then used as the similarity score. Moreover, we propose to utilise multi-modal stacked denoising autoencoder to effectively pre-train the deep neural network. We train and test the proposed metric using sampled corresponding/non-corresponding computed tomography and magnetic resonance head image patches from a same subject. Comparison is made with two commonly used metrics: normalised mutual information and local cross correlation. The contributions of the multi-modal stacked denoising autoencoder and the deep structure of the neural network are also evaluated. Both the quantitative and qualitative results from the similarity ranking experiments show the advantage of the proposed metric for a highly accurate and robust similarity measure.},
author = {Cheng, Xi and Zhang, Li and Zheng, Yefeng},
doi = {10.1080/21681163.2015.1135299},
issn = {21681171},
journal = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization},
keywords = {Multi-modal medical images,deep neural network,multi-modal denoising autoencoder,similarity metric learning},
mendeley-groups = {VAE/Multi-Modal},
title = {{Deep similarity learning for multimodal medical images}},
year = {2018}
}
@article{Srivastava2012,
abstract = {We propose a Deep Belief Network archi- tecture for learning a joint representation of multimodal data. The model defines a prob- ability distribution over the space of mul- timodal inputs and allows sampling from the conditional distributions over each data modality. This makes it possible for the model to create a multimodal representation even when some data modalities are missing. Our experimental results on bi-modal data consisting of images and text show that the Multimodal DBN can learn a good generative model of the joint space of image and text in- puts that is useful for filling in missing data so it can be used both for image annotation and image retrieval. We further demonstrate that using the representation discovered by the Multimodal DBN our model can signif- icantly outperform SVMs and LDA on dis- criminative tasks. 1.},
author = {Srivastava, Nitish and Salakhutdinov, Ruslan},
journal = {International Conference on Machine Learning Workshop},
mendeley-groups = {VAE/Multi-Modal},
title = {{Learning representations for multimodal data with deep belief nets}},
year = {2012}
}
@article{Krajnik2014,
abstract = {We present a fast and precise vision-based software intended for multiple robot localization. The core component of the software is a novel and efficient algorithm for black and white pattern detection. The method is robust to variable lighting conditions, achieves sub-pixel precision and its computational complexity is independent of the processed image size. With off-the-shelf computational equipment and low-cost cameras, the core algorithm is able to process hundreds of images per second while tracking hundreds of objects with millimeter precision. In addition, we present the method's mathematical model, which allows to estimate the expected localization precision, area of coverage, and processing speed from the camera's intrinsic parameters and hardware's processing capacity. The correctness of the presented model and performance of the algorithm in real-world conditions is verified in several experiments. Apart from the method description, we also make its source code public at http://purl.org/robotics/whycon; so, it can be used as an enabling technology for various mobile robotic problems.},
author = {Krajn{\'{i}}k, Tom{\'{a}}{\v{s}} and Nitsche, Mat{\'{i}}as and Faigl, Jan and Van{\v{e}}k, Petr and Saska, Martin and Přeu{\v{c}}il, Libor and Duckett, Tom and Mejail, Marta},
doi = {10.1007/s10846-014-0041-x},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mond{\'{e}}jar-Guerra et al. - 2018 - Robust identification of fiducial markers in challenging conditions.pdf:pdf},
isbn = {0921-0296},
issn = {15730409},
journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
keywords = {Computer vision,Localization,Mobile robotics,Swarm robotics},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
title = {{A Practical Multirobot Localization System}},
year = {2014}
}
@article{MONDEJARGUERRA2018336,
abstract = {Many intelligent systems, such as assistive robots, augmented reality trainers or unmanned vehicles, need to know their physical location in the environment in order to fulfill their task. While relying exclusively on natural landmarks for that task is the preferred option, their use is somewhat limited because the proposed methods are complex, require high computational power, and are not reliable in all environments. On the other hand, artificial landmarks can be placed in order to alleviate these problems. In particular, square fiducial markers are one of the most popular tools for camera pose estimation due to their high performance and precision. However, the state-of-the-art methods still perform poorly under difficult image conditions, such as camera defocus, motion blur, small scale or non-uniform lighting. This paper proposes a method to robustly detect this type of landmarks under challenging image conditions present in realistic scenarios. To do so, we re-define the marker identification problem as a classification one based on state-of-the-art machine learning techniques. Second, we propose a procedure to create a training dataset of synthetically generated images affected by several challenging transformations. Third, we show that, in this problem, a classifier can be trained using exclusively synthetic data, performing well in real and challenging conditions. Different types of classifiers have been tested to prove the validity of our proposal (namely, Multilayer Perceptron (MLP), Convolutional Neural Network (CNN) and Support Vector Machine (SVM)), and statistical analyses have been performed in order to determine the best approach for our problem. Finally, the obtained classifiers have been compared to the ArUco and AprilTags fiducial marker systems in challenging video sequences. The results obtained show that the proposed method performs significantly better than previous approaches, making the use of this technology more reliable in a wider range of realistic scenarios such as outdoor scenes or fast moving cameras.},
author = {Mond{\'{e}}jar-Guerra, V{\'{i}}ctor and Garrido-Jurado, Sergio and Mu{\~{n}}oz-Salinas, Rafael and Mar{\'{i}}n-Jim{\'{e}}nez, Manuel J and Medina-Carnicer, Rafael},
doi = {https://doi.org/10.1016/j.eswa.2017.10.032},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mond{\'{e}}jar-Guerra et al. - 2018 - Robust identification of fiducial markers in challenging conditions.pdf:pdf},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {Augmented reality,Convolutional neural networks,Fiducial markers,Machine learning,Multilayer perceptron,Support vector machines},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {336--345},
title = {{Robust identification of fiducial markers in challenging conditions}},
url = {http://www.sciencedirect.com/science/article/pii/S0957417417307145},
volume = {93},
year = {2018}
}
@article{Tai2016,
abstract = {Deep learning techniques have been widely applied, achieving state-of-the-art results in various fields of study. This survey focuses on deep learning solutions that target learning control policies for robotics applications. We carry out our discussions on the two main paradigms for learning control with deep networks: deep reinforcement learning and imitation learning. For deep reinforcement learning (DRL), we begin from traditional reinforcement learning algorithms, showing how they are extended to the deep context and effective mechanisms that could be added on top of the DRL algorithms. We then introduce representative works that utilize DRL to solve navigation and manipulation tasks in robotics. We continue our discussion on methods addressing the challenge of the reality gap for transferring DRL policies trained in simulation to real-world scenarios, and summarize robotics simulation platforms for conducting DRL research. For imitation leaning, we go through its three main categories, behavior cloning, inverse reinforcement learning and generative adversarial imitation learning, by introducing their formulations and their corresponding robotics applications. Finally, we discuss the open challenges and research frontiers.},
archivePrefix = {arXiv},
arxivId = {1612.07139},
author = {Tai, Lei and Zhang, Jingwei and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
eprint = {1612.07139},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tai et al. - 2016 - A Survey of Deep Network Solutions for Learning Control in Robotics From Reinforcement to Imitation.pdf:pdf},
mendeley-groups = {VAE,Machine Learning/RL,Machine Learning/Tutorials},
number = {8},
pages = {1--19},
title = {{A Survey of Deep Network Solutions for Learning Control in Robotics: From Reinforcement to Imitation}},
url = {http://arxiv.org/abs/1612.07139},
volume = {14},
year = {2016}
}
@article{Dai2017,
abstract = {Variational autoencoders (VAE) represent a popular, flexible form of deep generative model that can be stochastically fit to samples from a given random process using an information-theoretic variational bound on the true underlying distribution. Once so-obtained, the model can be putatively used to generate new samples from this distribution, or to provide a low-dimensional latent representation of existing samples. While quite effective in numerous application domains, certain important mechanisms which govern the behavior of the VAE are obfuscated by the intractable integrals and resulting stochastic approximations involved. Moreover, as a highly non-convex model, it remains unclear exactly how minima of the underlying energy relate to original design purposes. We attempt to better quantify these issues by analyzing a series of tractable special cases of increasing complexity. In doing so, we unveil interesting connections with more traditional dimensionality reduction models, as well as an intrinsic yet underappreciated propensity for robustly dismissing sparse outliers when estimating latent manifolds. With respect to the latter, we demonstrate that the VAE can be viewed as the natural evolution of recent robust PCA models, capable of learning nonlinear manifolds of unknown dimension obscured by gross corruptions.},
archivePrefix = {arXiv},
arxivId = {1706.05148},
author = {Dai, Bin and Wang, Yu and Aston, John and Hua, Gang and Wipf, David},
eprint = {1706.05148},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dai et al. - 2017 - Hidden Talents of the Variational Autoencoder.pdf:pdf},
keywords = {deep generative model,robust pca,variational autoencoder},
mendeley-groups = {VAE,VAE/Tutorials},
pages = {1--41},
title = {{Hidden Talents of the Variational Autoencoder}},
url = {http://arxiv.org/abs/1706.05148},
year = {2017}
}
@article{Kingma2014,
abstract = {The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.},
archivePrefix = {arXiv},
arxivId = {1406.5298},
author = {Kingma, Diederik P. and Rezende, Danilo J. and Mohamed, Shakir and Welling, Max},
eprint = {1406.5298},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kingma et al. - 2014 - Semi-Supervised Learning with Deep Generative Models.pdf:pdf},
issn = {10495258},
mendeley-groups = {VAE},
pages = {1--9},
title = {{Semi-Supervised Learning with Deep Generative Models}},
url = {http://arxiv.org/abs/1406.5298},
year = {2014}
}
@article{2018arXiv180502944K,
archivePrefix = {arXiv},
arxivId = {cs.RO/1805.02944},
author = {Korthals, T and Exner, J and Sch{\"{o}}pping, T and Hesse, M},
eprint = {1805.02944},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals et al. - 2018 - Path Evaluation via HMM on Semantical Occupancy Grid Maps.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {Computer Science - Robotics},
primaryClass = {cs.RO},
title = {{Path Evaluation via HMM on Semantical Occupancy Grid Maps}},
year = {2018}
}
@article{Huynh2009,
abstract = {Abstract 3D rotations arise in many computer vision, computer graphics, and robotics problems and evaluation of the distance between two 3D rotations is often an essential task. This paper presents a detailed analysis of six functions for measuring distance between ... $\backslash$n},
author = {Huynh, Du Q.},
doi = {10.1007/s10851-009-0161-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Huynh - 2009 - Metrics for 3D rotations Comparison and analysis.pdf:pdf},
isbn = {1085100901},
issn = {09249907},
journal = {Journal of Mathematical Imaging and Vision},
keywords = {3D rotations,Distance functions,Lie algebra,Matrix Lie group,Quaternions},
mendeley-groups = {Vision/Registration {\&} Calibration},
title = {{Metrics for 3D rotations: Comparison and analysis}},
year = {2009}
}
@article{Horn1987,
abstract = {Finding the relationship between two coordinate systems using pairs of measurements of the coordinates of a number of points in both systems is a classic photogrammetric task. It finds applications in stereophotogrammetry and in robotics. I present here a closed-form solution to the least-squares problem for three or more points. Currently various empirical, graphical, and numerical iterative methods are in use. Derivation of the solution is simplified by use of unit quaternions to represent rotation. I emphasize a symmetry property that a solution to this problem ought to possess. The best translational offset is the difference between the centroid of the coordinates in one system and the rotated and scaled centroid of the coordinates in the other system. The best scale is equal to the ratio of the root-mean-square deviations of the coordinates in the two systems from their respective centroids. These exact results are to be preferred to approximate methods based on measurements of a few selected points. The unit quaternion representing the best rotation is the eigenvector associated with the most positive eigenvalue of a symmetric 4 × 4 matrix. The elements of this matrix are combinations of sums of products of corresponding coordinates of the points.},
author = {Horn, Berthold K. P.},
doi = {10.1364/JOSAA.4.000629},
file = {:home/tkorthals/Documents/Mendeley Desktop/Horn - 1987 - Closed-form solution of absolute orientation using unit quaternions.pdf:pdf},
isbn = {1084-7529},
issn = {1084-7529},
journal = {Journal of the Optical Society of America A},
mendeley-groups = {Vision/Registration {\&} Calibration},
title = {{Closed-form solution of absolute orientation using unit quaternions}},
year = {1987}
}
@inproceedings{Lightbody2017,
abstract = {Fiducial markers have a wide field of applications in robotics, ranging from external localisation of single robots or robotic swarms, over self-localisation in marker-augmented environ- ments, to simplifying perception by tagging objects in a robot's surrounding. We propose a new family of circular markers allowing for a computationally efficient detection, identification and full 3D position estimation. A key con- cept of our system is the separation of the detection and identification steps, where the first step is based on a compu- tationally efficient circular marker detection, and the iden- tification step is based on an open-ended ‘Necklace code', which allows for a theoretically infinite number of individ- ually identifiable markers. The experimental evaluation of the system on a real robot indicates that while the proposed algorithm achieves similar accuracy to other state-of-the-art methods, it is faster by two orders of magnitude and it can detect markers from longer distances.},
author = {Lightbody, Peter and Krajn{\'{i}}k, Tom{\'{a}}{\v{s}} and Hanheide, Marc},
booktitle = {Proceedings of the Symposium on Applied Computing - SAC '17},
doi = {10.1145/3019612.3019709},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lightbody, Krajn{\'{i}}k, Hanheide - 2017 - A versatile high-performance visual fiducial marker detection system with scalable identity encod.pdf:pdf},
isbn = {9781450344869},
keywords = {computer vision,fiducial markers,swarm robotics},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches,Vision/Tracking/Fiducial Marker},
pages = {276--282},
title = {{A versatile high-performance visual fiducial marker detection system with scalable identity encoding}},
url = {http://doi.acm.org/10.1145/3019612.3019709{\%}0Ahttp://dl.acm.org/citation.cfm?doid=3019612.3019709},
year = {2017}
}
@phdthesis{Morrison2010,
abstract = {Light Detection and Ranging (LIDAR) systems are three dimensional (3D) imaging sensors applied for mapping terrain, measuring structural dimensions, and navigating robots. Pulsed laser rangefinders provide precise range measurements that require an estimate of sensor pose for transformation into world coordinates. Pose information is frequently provided with extrinsic sources such as Global Positioning System (GPS) or an Inertial Measurement Unit (IMU). Unreliable signal availability for GPS in military environments and the high cost of IMUs limit the employment of these extrinsic sources. Determining pose intrinsically by detecting landmarks in the environment within the sensor data is more ideal. Fiducial markers with known geometric dimensions and orientation provide a means of estimating LIDAR pose and registering data. Presented is a method for landmark detection and pose estimation within range data. Cylinder, cone, and sphere geometries are assessed for use as fiducial markers. The detection algorithm extracts geometric features from LIDAR point data and tests for fit to a fiducial marker model. Geometric feature extraction compresses the data set and leads to a potential intrinsic registration method using environment and marks. The detection accuracy and pose estimation precision are examined with terrestrial LIDAR range data captured in various outdoor street environments.},
author = {{Morrison Richard}, Bmisc},
file = {:home/tkorthals/Documents/Mendeley Desktop/Morrison Richard - 2010 - Fiducial marker detection and pose estimation from LIDAR range data.pdf:pdf},
keywords = {non-vision},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
publisher = {Calhoun},
title = {{Fiducial marker detection and pose estimation from LIDAR range data}},
url = {https://calhoun.nps.edu/handle/10945/5411},
year = {2010}
}
@techreport{Mezzanine,
author = {Howard, Andrew},
file = {:home/tkorthals/Documents/Mendeley Desktop/Howard - 2002 - Mezzanine User Manual.pdf:pdf},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
title = {{Mezzanine User Manual}},
url = {https://robotics.usc.edu/publications/media/uploads/pubs/292.pdf http://playerstage.sourceforge.net/mezzanine/mezzanine.html},
year = {2002}
}
@article{Quinn2008VISNETAD,
author = {Quinn, Michael J and Mudumbai, Raghuraman and Kuo, Thomas and Ni, Zefeng and Leo, Carter De and Manjunath, B S},
file = {:home/tkorthals/Documents/Mendeley Desktop/Quinn et al. - 2008 - VISNET A distributed vision testbed.pdf:pdf},
journal = {2008 Second ACM/IEEE International Conference on Distributed Smart Cameras},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
pages = {1--8},
title = {{VISNET: A distributed vision testbed}},
year = {2008}
}
@article{Gonzales2013,
abstract = {The growing interest in ubiquitous robotics has originated in the last years the development of a high variety of testbeds. This paper presents a survey on existing ubiquitous robotics testbeds comprising networked mobile robots and networks of distributed sensors, cameras and smartphones, among others. The survey provides an insight into the testbed design, internal behavior and use, identifying trends and existing gaps and proposing guidelines for testbed developers. The level of interoperability among different ubiquitous robotics technologies is used as the main conducting criterion of the survey. Other features analyzed include testbed architectures, target experiments and usability tools. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Jim{\'{e}}nez-Gonz{\'{a}}lez, Adri{\'{a}}n and {Martinez-De Dios}, Jose Ramiro and Ollero, Anibal},
doi = {10.1016/j.robot.2013.07.006},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jim{\'{e}}nez-Gonz{\'{a}}lez, Martinez-De Dios, Ollero - 2013 - Testbeds for ubiquitous robotics A survey.pdf:pdf},
isbn = {09218890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Testbeds,Ubiquitous robotics,Wireless sensor network},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
number = {12},
pages = {1487--1501},
title = {{Testbeds for ubiquitous robotics: A survey}},
volume = {61},
year = {2013}
}
@article{De2006,
abstract = {Limited fidelity of software-based wireless network simulations has prompted many researchers to build testbeds for developing and evaluating their wireless protocols and mobile applications. Since most testbeds are tailored to the needs of specific research projects, they cannot be easily reused for other research projects that may have different requirements on physical topology, radio channel characteristics or mobility pattern. In this paper, we describe the design, implementation and evaluation of MiNT-m, an experimentation platform devised specifically to support arbitrary experiments for mobile multi-hop wireless network protocols. In addition to inheriting the miniaturization feature from its predecessor MiNT [9], MiNT-m enables flexible testbed reconfiguration on an experiment-by-experiment basis by putting each testbed node on a centrally controlled untethered mobile robot. To support mobility and reconfiguration of testbed nodes, MiNT-m includes a scalable mobile robot navigation control subsystem, which in turn consists of a vision-based robot positioning module and a collision avoidance-based trajectory planning module. Further, MiNT-m provides a comprehensive network/experiment management subsystem that affords a user full interactive control over the testbed as well as real-time visualization of the testbed activities. Finally, because MiNT-m is designed to be a shared research infrastructure that supports 24x7 operation, it incorporates a novel automatic battery recharging capability that enables testbed robots to operate without human intervention for weeks.},
author = {De, Pradipta and Raniwala, Ashish and Krishnan, Rupa and Tatavarthi, Krishna and Modi, Jatan and Syed, Nadeem Ahmed and Sharma, Srikant and Chiueh, Tzi-cker},
doi = {10.1145/1134680.1134694},
file = {:home/tkorthals/Documents/Mendeley Desktop/De et al. - 2006 - MiNT-m An Autonomous Mobile Wireless Experimentation Platform.pdf:pdf},
isbn = {1595931953},
journal = {Proceedings of the 4th international conference on Mobile systems, applications and services - MobiSys 2006},
keywords = {autonomous operation,mobility,reconfiguration,topology,wireless experimentation platform},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
pages = {124},
title = {{MiNT-m: An Autonomous Mobile Wireless Experimentation Platform}},
url = {http://doi.acm.org/10.1145/1134680.1134694{\%}5Cnhttp://dl.acm.org/ft{\_}gateway.cfm?id=1134694{\&}type=pdf{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1134680.1134694},
year = {2006}
}
@inproceedings{Pitzer2012,
abstract = {In this paper, we describe a remote lab system that allows remote$\backslash$ngroups to access a shared PR2. This lab will enable a larger and$\backslash$nmore diverse group of researchers to participate directly in state-of-the-art$\backslash$nrobotics research and will improve the reproducibility and comparability$\backslash$nof robotics experiments. We identify a set of requirements that apply$\backslash$nto all web-based remote laboratories and focus on solutions to these$\backslash$nrequirements. Specifically, we present solutions to interface, control$\backslash$nand design difficulties in the client and server-side software when$\backslash$nimplementing a remote laboratory architecture. The combination of$\backslash$nshared physical hardware and shared middleware software allows for$\backslash$nexperiments that build upon and compare against results on the same$\backslash$nplatform and in the same environment for common tasks. We describe$\backslash$nhow researchers can interact with the PR2 and its environment remotely$\backslash$nthrough a web interface, as well as develop similar interfaces to$\backslash$nvisualize and run experiments remotely.},
author = {Pitzer, Benjamin and Osentoski, Sarah and Jay, Graylin and Crick, Christopher and Jenkins, Odest Chadwicke},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224653},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pitzer et al. - 2012 - PR2 Remote Lab An environment for remote development and experimentation.pdf:pdf},
isbn = {9781467314039},
issn = {10504729},
keywords = {Pitzer2012},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
pages = {3200--3205},
title = {{PR2 Remote Lab: An environment for remote development and experimentation}},
year = {2012}
}
@article{Michael2008,
abstract = {Experimental validation is particularly important in multi-robot systems research. The differences between models and real-world conditions that may not be apparent in single robot experiments are amplified because of the large number of robots, interactions between robots, and the effects of asynchronous and distributed control, sensing, and actuation. Over the last two years, we have developed an experimental testbed to support research in multirobot systems with the goal of making it easy for users to model, design, benchmark, and validate algorithms. In this article, we describe our approach to the design of a large-scale multirobot system for the experimental verification and validation of a variety of distributed robotic applications in an indoor environment.},
author = {Michael, Nathan and Fink, Jonathan and Kumar, Vijay},
doi = {10.1109/M-RA.2007.914924},
file = {:home/tkorthals/Documents/Mendeley Desktop/Michael, Fink, Kumar - 2008 - Experimental Testbed for Large Multirobot Teams Verification and Validation.pdf:pdf},
issn = {10709932},
journal = {IEEE Robotics and Automation Magazine},
keywords = {Multirobot systems,cooperative manipulation,decentralized control,experimental robotics,formation control},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
number = {1},
pages = {53--61},
title = {{Experimental Testbed for Large Multirobot Teams: Verification and Validation}},
volume = {15},
year = {2008}
}
@inproceedings{Wagner2007,
abstract = {In this paper we present ARToolKitPlus, a successor to the popular ARToolKit pose tracking library. ARToolKitPlus has been optimized and extended for the usage on mobile devices such as smartphones, PDAs and Ultra Mobile PCs (UMPCs). We explain the need and specific requirements of pose tracking on mobile devices and how we met those requirements. To prove the applicability we performed an extensive benchmark series on a braod range of off-the-shelf handhelds.},
author = {Wagner, Daniel and Schmalstieg, Dieter},
booktitle = {Proceedings of 12th Computer Vision Winter Workshop CVWW07},
doi = {10.1.1.157.1879},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wagner, Schmalstieg - 2007 - ARToolKitPlus for Pose Tracking on Mobile Devices.pdf:pdf},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {139--146},
pmid = {6115921593490582711},
title = {{ARToolKitPlus for Pose Tracking on Mobile Devices}},
url = {http://www.icg.tu-graz.ac.at/Members/daniel/ARToolKitPlusMobilePoseTracking},
year = {2007}
}
@inproceedings{4146835,
abstract = {Not Available},
author = {Johnson, D and Stack, T and Fish, R and Flickinger, D M and Stoller, L and Ricci, R and Lepreau, J},
booktitle = {Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications},
doi = {10.1109/INFOCOM.2006.182},
file = {:home/tkorthals/Documents/Mendeley Desktop/Johnson et al. - 2006 - Mobile Emulab A Robotic Wireless and Sensor Network Testbed.pdf:pdf},
issn = {0743-166X},
keywords = {Automatic testing,Automation,Costs,Mechanical sensors,Mobile robots,Open source software,Robot sensing systems,Software testing,System testing,Wireless sensor networks},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
month = {apr},
pages = {1--12},
title = {{Mobile Emulab: A Robotic Wireless and Sensor Network Testbed}},
year = {2006}
}
@inproceedings{7989200,
abstract = {This paper describes the Robotarium - a remotely accessible, multi-robot research facility. The impetus behind the Robotarium is that multi-robot testbeds constitute an integral and essential part of the multi-robot research cycle, yet they are expensive, complex, and time-consuming to develop, operate, and maintain. These resource constraints, in turn, limit access for large groups of researchers and students, which is what the Robotarium is remedying by providing users with remote access to a state-of-the-art multi-robot test facility. This paper details the design and operation of the Robotarium and discusses the considerations one must take when making complex hardware remotely accessible. In particular, safety must be built into the system already at the design phase without overly constraining what coordinated control programs users can upload and execute, which calls for minimally invasive safety routines with provable performance guarantees.},
author = {Pickem, D and Glotfelter, P and Wang, L and Mote, M and Ames, A and Feron, E and Egerstedt, M},
booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2017.7989200},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pickem et al. - 2017 - The Robotarium A remotely accessible swarm robotics research testbed.pdf:pdf},
keywords = {Collision avoidance,Hardware,Robot kinematics,Robot sensing systems,Safety,Servers,complex hardware,coordinated control programs,design phase,minimally invasive safety routines,mobile robots,multi-robot systems,multirobot research facility,multirobot test facility,performance guarantees,remotely accessible swarm robotics research testbe,resource constraints,robotarium,telerobotics},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
pages = {1699--1706},
title = {{The Robotarium: A remotely accessible swarm robotics research testbed}},
year = {2017}
}
@inproceedings{7140055,
abstract = {RPN (Robotic Programming Network) is an initiative to bring existing remote robot laboratories to a new dimension, by adding the flexibility and power of writing ROS code in an Internet browser and running it in the remote robot with a single click. The code is executed in the robot server at full speed, i.e. without any communication delay, and the output of the process is returned back. Built upon Robot Web Tools, RPN works out-of-the-box in any ROS-based robot or simulator. This paper presents the core functionality of RPN in the context of a web-enabled ROS system, its possibilities for remote education and training, and some experimentation with simulators and real robots in which we have integrated the tool in a Moodle environment, creating some programming courses and make it open to researchers and students (http://robotprogramming.uji.es).},
author = {Casa{\~{n}}, G A and Cervera, E and Moughlbay, A A and Alemany, J and Martinet, P},
booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2015.7140055},
file = {:home/tkorthals/Documents/Mendeley Desktop/Casa{\~{n}} et al. - 2015 - ROS-based online robot programming for remote education and training.pdf:pdf},
issn = {1050-4729},
keywords = {Browsers,Information services,Internet,Internet browser,Moodle environment,Programming profession,ROS code writing,ROS-based online robot programming,RPN,Robots,Servers,Web-enabled ROS system,educational courses,online front-ends,programming courses,remote education,remote robot laboratories,remote training,robot Web tools,robot programming,robot server,robotic programming network},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches,Robotics/ROS},
pages = {6101--6106},
title = {{ROS-based online robot programming for remote education and training}},
year = {2015}
}
@inproceedings{880934,
abstract = {We address the problems of virtual object interaction and user tracking in a table-top augmented reality (AR) interface. In this setting there is a need for very accurate tracking and registration techniques and an intuitive and useful interface. This is especially true in AR interfaces for supporting face to face collaboration where users need to be able to easily cooperate with each other. We describe an accurate vision-based tracking method for table-top AR environments and tangible user interface (TUI) techniques based on this method that allow users to manipulate virtual objects in a natural and intuitive manner. Our approach is robust, allowing users to cover some of the tracking markers while still returning camera viewpoint information, overcoming one of the limitations of traditional computer vision based systems. After describing this technique we describe its use in prototype AR applications},
author = {Kato, H and Billinghurst, M and Poupyrev, I and Imamoto, K and Tachibana, K},
booktitle = {Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)},
doi = {10.1109/ISAR.2000.880934},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kato et al. - 2000 - Virtual object manipulation on a table-top AR environment.pdf:pdf},
keywords = {Augmented reality,Buildings,Collaboration,Collaborative work,Computer vision,Displays,Laboratories,Prototypes,Robustness,User interfaces,augmented reality,camera viewpoint,computer vision,face to face collaboration,image registration,table-top augmented reality interface,user interface,user interfaces,user tracking,virtual object manipulation,vision-based tracking},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {111--119},
title = {{Virtual object manipulation on a table-top AR environment}},
year = {2000}
}
@inproceedings{6225114,
abstract = {Visual marker is a useful assistive tool for service robots. Existing planar visual markers have poor accuracy and stability in pose estimation, especially in frontal direction. In this study, we developed a novel visual marker based on a new principle enabling accurate and stable pose estimation even by observation from frontal direction. The marker has moiré patterns which consist of lenticular lens and stripe pattern, which vary their appearance according to visual-line angle of observation. We can extract pose information from the pattern by a single camera. We developed a prototype of the marker and an algorithm for pose estimation, and then demonstrated its superiority to existing markers by some validation tests.},
author = {Tanaka, H and Sumi, Y and Matsumoto, Y},
booktitle = {2012 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6225114},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanaka, Sumi, Matsumoto - 2012 - A visual marker for precise pose estimation based on lenticular lenses.pdf:pdf},
issn = {1050-4729},
keywords = {Accuracy,Cameras,Estimation,Lenses,Prototypes,Robots,Visualization,assistive tool,frontal direction,lenses,lenticular lenses,moiré patterns,planar visual markers,pose estimation,robot vision,service robots,stripe pattern,visual-line angle of observation},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {5222--5227},
title = {{A visual marker for precise pose estimation based on lenticular lenses}},
year = {2012}
}
@article{Rekimoto2000,
abstract = {The CyberCode is a visual tagging system based on a 2D-barcode technology and provides several features not provided by other tagging systems. CyberCode tags can be recognized by the low-cost CMOS or CCD cameras found in more and more mobile devices, and it can also be used to determine the 3D position of the tagged object as well as its ID number. This paper describes examples of augmented reality applications based on CyberCode, and discusses some key characteristics of tagging technologies that must be taken into account when designing augmented reality environments.},
archivePrefix = {arXiv},
arxivId = {pdf scholar},
author = {Rekimoto, Jun and Ayatsuka, Yuji},
doi = {10.1145/354666.354667},
eprint = {pdf scholar},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rekimoto, Ayatsuka - 2000 - CyberCode designing augmented reality environments with visual tags.pdf:pdf},
isbn = {1581133677},
journal = {Science},
keywords = {augmented reality,cybercode,id aware augmented environments,id aware interface,introduction,merging virtual real},
mendeley-groups = {Vision,Vision/Tracking/Fiducial Marker},
number = {9},
pages = {1--10},
pmid = {2282551158664012841},
title = {{CyberCode: designing augmented reality environments with visual tags}},
url = {http://portal.acm.org/citation.cfm?id=354667},
volume = {Vol 303},
year = {2000}
}
@phdthesis{Paredes2013,
abstract = {This thesis goes into the augmented reality world and, being more specific in Vuforia uses, searching as an achievement the analysis of its characteristics. The first objective of this thesis is make a short explanation of what is understood by augmented reality and the actual different varieties of AR applications, and then the SDK's features and its architecture and elements. In other hand, to understand the basis of the detection process realized by the Vuforia's library is important to explain the approach to the considerations of image recognition, because it is the way in which Vuforia recognizes the different patterns. Another objective has been the exposition of the possible fields of applications using this library and a brief of the main steps to create an implementation always using Unity3D, due to Vuforia is only a SDK not an IDE. The reason to choose this way is due to the facilities that are provided by Unity3D when creating the application itself, because it already has implemented all necessary to access the hardware of the smartphone, as well as those that control the Vuforia's elements. In other way, the Vuforia's version used during the thesis has been the 1.5, but two months ago Qualcomm was launched the new 2.0 version, that it is not intended to form part of this study, although some of the most significant new capabilities are explained. Finally, the last and perhaps the most important objective have been the test and the results, where they have used three different smartphones to compare the values. Following this methodology has been possible to conclude which part of the results are due to the features and capabilities of the different smartphones and which part depends only of the Vuforia's library},
author = {Paredes, Josep and Simonetti, Alexandro},
file = {:home/tkorthals/Documents/Mendeley Desktop/Paredes, Simonetti - 2013 - Vuforia v1.5 SDK. Analysis and evaluation of capabilities.pdf:pdf},
keywords = {Vuforia},
mendeley-groups = {Vision,Vision/Tracking/Fiducial Marker},
number = {March},
title = {{Vuforia v1.5 SDK. Analysis and evaluation of capabilities}},
url = {https://upcommons.upc.edu/bitstream/handle/2099.1/17769/memoria.pdf},
year = {2013}
}
@misc{Vuforia,
mendeley-groups = {Vision,Vision/Tracking/Fiducial Marker},
title = {{Vuforia}},
url = {http://library.vuforia.com/},
urldate = {2018-04-11}
}
@inproceedings{Rice2006,
abstract = {This paper presents Cantag, an open source software toolkit for building marker-based vision (MBV) systems that can identify and accurately locate printed markers in three dimensions. The extensibility of the system makes it ideal for dynamic location and poses determination in pervasive computing systems. Unlike prior MBV systems, Cantag supports multiple fiducial shapes, payload types, data sizes and image processing algorithms in one framework. It allows the application writer to generate a custom tag design and associated optimised executable for any given application. The system includes a test harness which can be used to quantify, compare and contrast the performance of different designs. This paper explores the design space of tags within the Cantag system, and describes the design parameters and performance characteristics which an application writer can use to select the best tag system for any given scenario. It presents quantitative analysis of different markers and processing algorithms, which are compared fairly for the first time},
author = {Rice, Andrew C. and Beresford, Alastair R. and Harle, Robert K.},
booktitle = {Proceedings - Fourth Annual IEEE International Conference on Pervasive Computing and Communications, PerCom 2006},
doi = {10.1109/PERCOM.2006.13},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rice, Beresford, Harle - 2006 - Cantag An open source software toolkit for designing and deploying marker-based vision systems.pdf:pdf},
isbn = {0769525180},
mendeley-groups = {Vision,Vision/Tracking/Fiducial Marker},
pages = {12--21},
title = {{Cantag: An open source software toolkit for designing and deploying marker-based vision systems}},
volume = {2006},
year = {2006}
}
@article{Wang2016,
abstract = {AprilTags and other passive fiducial markers require specialized algorithms to detect markers among other features in a natural scene. The vision processing steps generally dominate the computation time of a tag detection pipeline, so even small improvements in marker detection can translate to a faster tag detection system. We incorporated lessons learned from implementing and supporting the AprilTag system into this improved system. This work describes AprilTag 2, a completely redesigned tag detector that improves robustness and efficiency compared to the original AprilTag system. The tag coding scheme is unchanged, retaining the same robustness to false positives inherent to the coding system. The new detector improves performance with higher detection rates, fewer false positives, and lower computational time. Improved performance on small images allows the use of decimated input images, resulting in dramatic gains in detection speed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wang, John and Olson, Edwin},
doi = {10.1109/IROS.2016.7759617},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wang, Olson - 2016 - AprilTag 2 Efficient and robust fiducial detection.pdf:pdf},
isbn = {9781509037629},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {4193--4198},
pmid = {4358868228737875376},
title = {{AprilTag 2: Efficient and robust fiducial detection}},
volume = {2016-Novem},
year = {2016}
}
@inproceedings{Bergamasco2011,
author = {Bergamasco, F and Albarelli, A and Rodola, E and Torsello, A},
booktitle = {Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on},
doi = {10.1109/CVPR.2011.5995544},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bergamasco et al. - 2011 - RUNE-Tag A high accuracy fiducial marker with strong occlusion resilience(2).pdf:pdf},
issn = {1063-6919},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {113--120},
title = {{RUNE-Tag: A high accuracy fiducial marker with strong occlusion resilience}},
year = {2011}
}
@article{Bergamasco2011b,
abstract = {Over the last decades fiducial markers have provided widely adopted tools to add reliable model-based features into an otherwise general scene. Given their central role in many computer vision tasks, countless different solutions have been proposed in the literature. Some designs are focused on the accuracy of the recovered camera pose with respect to the tag; some other concentrate on reaching high detection speed or on recognizing a large number of distinct markers in the scene. In such a crowded area both the researcher and the practitioner are licensed to wonder if there is any need to introduce yet another approach. Nevertheless, with this paper, we would like to present a general purpose fiducial marker system that can be deemed to add some valuable features to the pack. Specifically, by exploiting the projective properties of a circular set of sizeable dots, we propose a detection algorithm that is highly accurate. Further, applying a dot pattern scheme derived from error-correcting codes, allows for robustness with respect to very large occlusions. In addition, the design of the marker itself is flexible enough to accommodate different requirements in terms of pose accuracy and number of patterns. The overall performance of the marker system is evaluated in an extensive experimental section, where a comparison with a well-known baseline technique is presented.},
author = {Bergamasco, Filippo and Albarelli, Andrea and Rodol{\`{a}}, Emanuele and Torsello, Andrea},
doi = {10.1109/CVPR.2011.5995544},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bergamasco et al. - 2011 - RUNE-Tag Seminar.pdf:pdf},
isbn = {9781457703942},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {113--120},
title = {{RUNE-Tag: Seminar}},
year = {2011}
}
@article{Olson2011,
abstract = {While the use of naturally-occurring features is a central focus of machine perception, artificial features (fiducials) play an important role in creating controllable experiments, ground truthing, and in simplifying the development of systems where perception is not the central objective. We describe a new visual fiducial system that uses a 2D bar code style {\&}{\#}x201C;tag{\&}{\#}x201D;, allowing full 6 DOF localization of features from a single image. Our system improves upon previous systems, incorporating a fast and robust line detection system, a stronger digital coding system, and greater robustness to occlusion, warping, and lens distortion. While similar in concept to the ARTag system, our method is fully open and the algorithms are documented in detail.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Olson, Edwin},
doi = {10.1109/ICRA.2011.5979561},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Olson - 2011 - AprilTag A robust and flexible visual fiducial system.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {3400--3407},
pmid = {15991970},
title = {{AprilTag: A robust and flexible visual fiducial system}},
year = {2011}
}
@article{Greff2017,
abstract = {Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs ({\$}\backslashapprox 15{\$} years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
archivePrefix = {arXiv},
arxivId = {1503.04069},
author = {Greff, Klaus and Srivastava, Rupesh K. and Koutnik, Jan and Steunebrink, Bas R. and Schmidhuber, Jurgen},
doi = {10.1109/TNNLS.2016.2582924},
eprint = {1503.04069},
file = {:home/tkorthals/Documents/Mendeley Desktop/Greff et al. - 2017 - LSTM A Search Space Odyssey.pdf:pdf},
isbn = {9788578110796},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Functional ANalysis Of VAriance (fANOVA),long short-term memory (LSTM),random search,recurrent neural networks,sequence learning},
mendeley-groups = {VAE},
number = {10},
pages = {2222--2232},
pmid = {25246403},
title = {{LSTM: A Search Space Odyssey}},
volume = {28},
year = {2017}
}
@article{Cvpr2014a,
author = {Cvpr, Frank Dellaert and Tutorial, Visual Slam},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cvpr, Tutorial - 2014 - Bundle Adjustment.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{Bundle Adjustment}},
year = {2014}
}
@article{Folkesson2005,
abstract = {In this paper we combine a graphical approach for simultaneous localization and mapping, SLAM, with a feature representation that addresses symmetries and constraints in the feature coordinates, the measurement subspace, M-space. The graphical method has the advantages of delayed linearizations and soft commitment to feature measurement matching. It also allows large maps to be built up as a network of small local patches, star nodes. This local map net is then easier to work with. The formation of the star nodes is explicitly stable and invariant with all the symmetries of the original measurements. All linearization errors are kept small by using a local frame. The construction of this invariant star is made clearer by the M-space feature representation. The M-space allows the symmetries and constraints of the measurements to be explicitly represented. We present results using both vision and laser sensors.},
author = {Folkesson, John and Jensfelt, Patric and Christensen, Henrik I.},
doi = {10.1109/IROS.2005.1545493},
file = {:home/tkorthals/Documents/Mendeley Desktop/Folkesson, Jensfelt, Christensen - 2005 - Graphical SLAM using vision and the measurement subspace.pdf:pdf},
isbn = {0780389123},
journal = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
keywords = {Features,Graph,SLAM,Vision},
mendeley-groups = {Robotics/SLAM/Graph},
pages = {3383--3388},
title = {{Graphical SLAM using vision and the measurement subspace}},
year = {2005}
}
@article{Bergamasco2011a,
abstract = {Over the last decades fiducial markers have provided widely adopted tools to add reliable model-based features into an otherwise general scene. Given their central role in many computer vision tasks, countless different solutions have been proposed in the literature. Some designs are focused on the accuracy of the recovered camera pose with respect to the tag; some other concentrate on reaching high detection speed or on recognizing a large number of distinct markers in the scene. In such a crowded area both the researcher and the practitioner are licensed to wonder if there is any need to introduce yet another approach. Nevertheless, with this paper, we would like to present a general purpose fiducial marker system that can be deemed to add some valuable features to the pack. Specifically, by exploiting the projective properties of a circular set of sizeable dots, we propose a detection algorithm that is highly accurate. Further, applying a dot pattern scheme derived from error-correcting codes, allows for robustness with respect to very large occlusions. In addition, the design of the marker itself is flexible enough to accommodate different requirements in terms of pose accuracy and number of patterns. The overall performance of the marker system is evaluated in an extensive experimental section, where a comparison with a well-known baseline technique is presented.},
author = {Bergamasco, Filippo and Albarelli, Andrea and Rodol{\`{a}}, Emanuele and Torsello, Andrea},
doi = {10.1109/CVPR.2011.5995544},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bergamasco et al. - 2011 - RUNE-Tag A high accuracy fiducial marker with strong occlusion resilience.pdf:pdf},
isbn = {9781457703942},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {113--120},
title = {{RUNE-Tag: A high accuracy fiducial marker with strong occlusion resilience}},
year = {2011}
}
@article{Neuhaus2007,
author = {Neuhaus, Frank},
file = {:home/tkorthals/Documents/Mendeley Desktop/Neuhaus - 2007 - A Full 2D3D GraphSLAM System for Globally Consistent Mapping based on Manifolds.pdf:pdf},
keywords = {3d graphslam,a full 2d,hbereich 4,informatik,mapping based on manifolds,system for globally consistent},
mendeley-groups = {Robotics/SLAM/Graph},
number = {September 2011},
title = {{A Full 2D/3D GraphSLAM System for Globally Consistent Mapping based on Manifolds}},
url = {http://kola.opus.hbz-nrw.de/volltexte/2012/737/},
year = {2007}
}
@article{Weiss2013,
author = {Weiss, Stephan and Group, Computer Vision},
file = {:home/tkorthals/Documents/Mendeley Desktop/Weiss, Group - 2013 - Dealing with.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
number = {c},
title = {{Dealing with}},
year = {2013}
}
@article{Kaess2014,
author = {Kaess, Michael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kaess - 2014 - CVPR 2014 Visual SLAM Tutorial Efficient Inference.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{CVPR 2014 Visual SLAM Tutorial Efficient Inference}},
year = {2014}
}
@article{Cvpr2014,
author = {Cvpr, Frank Dellaert and Slam, Visual and With, Tutorial and Sattler, Torsten and Lee, Gim Hee and Pollefeys, Marc},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cvpr et al. - 2014 - VSLAM on Phones Closing Loops.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{VSLAM on Phones Closing Loops}},
year = {2014}
}
@article{Kaess2014b,
author = {Kaess, Michael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kaess - 2014 - CVPR 2014 Tutorial on Visual SLAM Large Scale – Reducing Computational Cost.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{CVPR 2014 Tutorial on Visual SLAM Large Scale – Reducing Computational Cost}},
year = {2014}
}
@article{Burgard,
author = {Burgard, Wolfram},
file = {:home/tkorthals/Documents/Mendeley Desktop/Burgard - Unknown - Deep Learning for Robot Perception and Navigation.pdf:pdf},
mendeley-groups = {VAE},
title = {{Deep Learning for Robot Perception and Navigation}}
}
@article{Newcombe2014a,
author = {Newcombe, Richard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Newcombe - 2014 - Introduction to Dense Visual Camera Tracking.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{Introduction to Dense Visual Camera Tracking}},
year = {2014}
}
@article{Weiss2013a,
author = {Weiss, Stephan and Group, Computer Vision},
file = {:home/tkorthals/Documents/Mendeley Desktop/Weiss, Group - 2013 - Hybrids Mixed Approaches.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
number = {c},
title = {{Hybrids Mixed Approaches}},
year = {2013}
}
@article{Mao,
archivePrefix = {arXiv},
arxivId = {arXiv:1606.08921v3},
author = {Mao, Xiao-jiao and Shen, Chunhua and Yang, Yu-bin},
eprint = {arXiv:1606.08921v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mao, Shen, Yang - Unknown - Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections.pdf:pdf},
mendeley-groups = {VAE},
pages = {1--17},
title = {{Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections}}
}
@article{Bound2017,
author = {Bound, Variational Lower},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bound - 2017 - Understanding the Variational Lower Bound.pdf:pdf},
mendeley-groups = {VAE},
pages = {1--4},
title = {{Understanding the Variational Lower Bound}},
year = {2017}
}
@article{Newcombe2014,
author = {Newcombe, Richard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Newcombe - 2014 - Dense Visual SLAM Greedy Algorithms.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{Dense Visual SLAM: Greedy Algorithms}},
year = {2014}
}
@article{Wikipedia,
author = {Wikipedia},
mendeley-groups = {Vision/Registration {\&} Calibration},
title = {{Levenberg–Marquardt algorithm}},
url = {https://en.wikipedia.org/wiki/Levenberg–Marquardt{\_}algorithm}
}
@article{Kaess2014a,
author = {Kaess, Michael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kaess - 2014 - CVPR 2014 Visual SLAM Tutorial Kintinuous.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{CVPR 2014 Visual SLAM Tutorial Kintinuous}},
year = {2014}
}
@article{4104179,
abstract = {There is an increasing interest in employing multiple sensors for surveillance and communications. Some of the motivating factors are reliability, survivability, increase in the number of targets under consideration, and increase in required coverage. Tenney and Sandell have recently treated the Bayesian detection problem with distributed sensors. They did not consider the design of data fusion algorithms. We present an optimum data fusion structure given the detectors. Individual decisions are weighted according to the reliability of the detector and then a threshold comparison is performed to obtain the global decision.},
author = {Chair, Z and Varshney, P K},
doi = {10.1109/TAES.1986.310699},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chair, Varshney - 1986 - Optimal Data Fusion in Multiple Sensor Detection Systems.pdf:pdf},
issn = {0018-9251},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
keywords = {Autocorrelation,Delay effects,Detectors,Frequency,Matched filters,Propagation delay,Radar detection,Sensor fusion,Sensor systems,Surveillance},
mendeley-groups = {VAE},
month = {jan},
number = {1},
pages = {98--101},
title = {{Optimal Data Fusion in Multiple Sensor Detection Systems}},
volume = {AES-22},
year = {1986}
}
@article{Salas-moreno2014,
author = {Salas-moreno, Renato F and Newcombe, Richard A and Kelly, Paul H J and Davison, Andrew J},
file = {:home/tkorthals/Documents/Mendeley Desktop/Salas-moreno et al. - 2014 - SLAM Simultaneous Localisation and Mapping at the Level of Objects.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{SLAM++: Simultaneous Localisation and Mapping at the Level of Objects}},
year = {2014}
}
@article{Systems1986,
author = {Systems, Detection},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chair, Varshney - 1986 - Optimal Data Fusion in Multiple Sensor Detection Systems.pdf:pdf},
number = {1},
pages = {98--101},
title = {{Optimal Data Fusion in Multiple Sensor Detection Systems}},
year = {1986}
}
@inproceedings{Cadena,
address = {Cambridge},
author = {Cadena, Cesar and Dick, Anthony and Reid, Ian D},
booktitle = {Robotics: Science and System XIII},
doi = {10.15607/RSS.2016.XII.041},
editor = {Amato, Nancy and Srinivasa, Siddhartha and Ayanian, Nora and Kiundersma, Scott},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cadena, Dick, Reid - 2016 - Multi-modal Auto-Encoders as Joint Estimators for Robotics Scene Understanding.pdf:pdf},
mendeley-groups = {VAE,VAE/Multi-Modal},
publisher = {MIT Press},
title = {{Multi-modal Auto-Encoders as Joint Estimators for Robotics Scene Understanding}},
year = {2016}
}
@article{Liu2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1705.10422v2},
author = {Liu, Guan-horng and Siravuru, Avinash and Prabhakar, Sai and Veloso, Manuela and Kantor, George},
eprint = {arXiv:1705.10422v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Liu et al. - 2017 - Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation.pdf:pdf},
mendeley-groups = {VAE},
number = {CoRL},
pages = {1--13},
title = {{Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation}},
year = {2017}
}
@article{Liu,
author = {Liu, Guan-horng and Siravuru, Avinash and Prabhakar, Sai and Veloso, Manuela and Kantor, George},
file = {:home/tkorthals/Documents/Mendeley Desktop/Liu et al. - Unknown - Multi-modal Deep Reinforcement Learning with a Novel Sensor-based Dropout.pdf:pdf},
keywords = {deep reinforcement learning,multi-modal learning,stochastic regu-},
mendeley-groups = {VAE},
title = {{Multi-modal Deep Reinforcement Learning with a Novel Sensor-based Dropout}},
url = {http://saiprabhakar.github.io/files/rldm.pdf}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2018 - UCL Course on RL.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
pages = {2018},
title = {{UCL Course on RL}},
url = {http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html},
year = {2018}
}
@article{Silvera,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 9 Exploration and Exploitation.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 9: Exploration and Exploitation}}
}
@article{Silverc,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 10 Classic Games.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 10: Classic Games}}
}
@article{Egorov,
author = {Egorov, Maxim},
file = {:home/tkorthals/Documents/Mendeley Desktop/Egorov - Unknown - Multi-Agent Deep Reinforcement Learning.pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
title = {{Multi-Agent Deep Reinforcement Learning}}
}
@article{Lau2018,
author = {Lau, Ben},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lau - 2018 - Using Keras and Deep Deterministic Policy Gradient to play TORCS.pdf:pdf},
mendeley-groups = {VAE},
pages = {1--27},
title = {{Using Keras and Deep Deterministic Policy Gradient to play TORCS}},
url = {https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html},
year = {2018}
}
@article{Kurin2018,
author = {Kurin, Vitaly},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kurin - 2018 - Introduction to Imitation Learning.pdf:pdf},
mendeley-groups = {VAE},
pages = {1--11},
title = {{Introduction to Imitation Learning}},
url = {https://blog.statsbot.co/introduction-to-imitation-learning-32334c3b1e7a},
year = {2018}
}
@article{Yeguas-bolivar2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1606.00151v1},
author = {Yeguas-Bolivar, Enrique and Medina-Carnicer, Rafael},
doi = {10.1016/j.patcog.2017.08.010},
eprint = {arXiv:1606.00151v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yeguas-Bolivar, Medina-Carnicer - 2017 - Mapping and Localization from Planar Markers.pdf:pdf},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
number = {October},
title = {{Mapping and Localization from Planar Markers}},
year = {2017}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2018 - Documentation ArUco.pdf:pdf},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {1--16},
title = {{Documentation: ArUco}},
url = {https://docs.google.com/document/d/1QU9KoBtjSM2kF6ITOjQ76xqL7H0TEtXriJX5kwi9Kgc/mobilebasic},
year = {2018}
}
@article{Magnusson2012,
author = {Magnusson, Martin},
file = {:home/tkorthals/Documents/Mendeley Desktop/Magnusson - 2012 - SLAM with pose graphs.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Graph},
title = {{SLAM with pose graphs}},
url = {http://aass.oru.se/Research/mro/courses/probrob/2012/handouts{\_}08.pdf},
year = {2012}
}
@article{Amplianitis2014,
author = {Amplianitis, Konstantinos},
file = {:home/tkorthals/Documents/Mendeley Desktop/Amplianitis - 2014 - Seminar on Bundle Adjustment.pdf:pdf},
mendeley-groups = {Vision/Registration {\&} Calibration},
title = {{Seminar on Bundle Adjustment}},
url = {https://www2.informatik.hu-berlin.de/cv/vorlesungen/WS1415/material/WS{\_}14{\_}05{\_}Bundle.pdf},
year = {2014}
}
@article{Hansen,
author = {Hansen, P C and Pereyra, V and Scherer, G},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hansen, Pereyra, Scherer - Unknown - Tutorial Nonlinear least squares problems.pdf:pdf},
mendeley-groups = {Vision/Registration {\&} Calibration},
pages = {1--20},
title = {{Tutorial: Nonlinear least squares problems}},
url = {http://www2.compute.dtu.dk/{~}pcha/LSDF/NonlinDataFit.pdf}
}
@article{Stachniss,
author = {Stachniss, Cyrill},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stachniss - Unknown - Least Squares Approach to SLAM.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Graph},
title = {{Least Squares Approach to SLAM}},
url = {http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/pdf/slam15-ls-slam.pdf}
}
@misc{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2018 - INTRO.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
pages = {2018},
title = {{INTRO}},
url = {http://frc.ri.cmu.edu/{~}kaess/vslam{\_}cvpr14/},
volume = {28},
year = {2018}
}
@article{Matrix2013,
author = {Matrix, Essential},
file = {:home/tkorthals/Documents/Mendeley Desktop/Matrix - 2013 - Visual Odometry.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
number = {c},
title = {{Visual Odometry}},
year = {2013}
}
@article{Beall2014,
author = {Beall, Chris},
file = {:home/tkorthals/Documents/Mendeley Desktop/Beall - 2014 - Stereo Visual Odometry.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14},
title = {{Stereo Visual Odometry}},
year = {2014}
}
@article{Ozog,
author = {Ozog, Paul and Eustice, Ryan M},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ozog, Eustice - Unknown - On the Importance of Modeling Camera Calibration Uncertainty in Visual SLAM.pdf:pdf},
mendeley-groups = {Vision/Registration {\&} Calibration},
title = {{On the Importance of Modeling Camera Calibration Uncertainty in Visual SLAM}}
}
@article{Dellaert2014,
author = {Dellaert, Frank},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dellaert - 2014 - Visual SLAM Tutorial Bundle Adjustment.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Visual SLAM CVPR14,Vision/Registration {\&} Calibration},
number = {3},
pages = {1--7},
title = {{Visual SLAM Tutorial: Bundle Adjustment}},
volume = {2},
year = {2014}
}
@article{Bus,
author = {Bus, Lucian and Schutter, Bart De},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bus, Schutter - Unknown - Multi-Agent Reinforcement Learning An Overview.pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
number = {2},
pages = {156--172},
title = {{Multi-Agent Reinforcement Learning: An Overview}},
volume = {38}
}
@article{Schulman2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05477v5},
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael and Abbeel, Pieter and Sciences, Computer},
eprint = {arXiv:1502.05477v5},
file = {:home/tkorthals/Documents/Mendeley Desktop/Schulman et al. - 2015 - Trust Region Policy Optimization.pdf:pdf},
mendeley-groups = {VAE},
title = {{Trust Region Policy Optimization}},
year = {2015}
}
@article{Bus2008,
author = {Bus, L and Schutter, B De},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bus, Schutter - 2008 - A comprehensive survey of multi-agent reinforcement learning ∗.pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
title = {{A comprehensive survey of multi-agent reinforcement learning ∗}},
volume = {19},
year = {2008}
}
@article{Yu2018,
author = {Yu, Lantao},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yu - 2018 - Paper Collection of Multi-Agent Reinforcement Learning (MARL).pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
pages = {1--5},
title = {{Paper Collection of Multi-Agent Reinforcement Learning (MARL)}},
url = {https://github.com/LantaoYu/MARL-Papers/blob/master/README.md},
year = {2018}
}
@article{Gupta,
author = {Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gupta, Egorov, Kochenderfer - Unknown - Cooperative Multi-Agent Control Using Deep Reinforcement Learning.pdf:pdf},
mendeley-groups = {Machine Learning/RL/Multi Agent},
title = {{Cooperative Multi-Agent Control Using Deep Reinforcement Learning}}
}
@article{Arulkumaran,
archivePrefix = {arXiv},
arxivId = {arXiv:1708.05866v2},
author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
eprint = {arXiv:1708.05866v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Arulkumaran et al. - Unknown - A Brief Survey of Deep Reinforcement Learning.pdf:pdf},
mendeley-groups = {Machine Learning/RL},
pages = {1--16},
title = {{A Brief Survey of Deep Reinforcement Learning}}
}
@article{Deeplearning4j2018,
author = {Deeplearning4j},
file = {:home/tkorthals/Documents/Mendeley Desktop/Deeplearning4j - 2018 - A Beginner's Guide to Deep Reinforcement Learning.pdf:pdf},
isbn = {1491914254},
mendeley-groups = {Machine Learning/RL},
pages = {1--12},
title = {{A Beginner's Guide to Deep Reinforcement Learning}},
url = {https://deeplearning4j.org/deepreinforcementlearning},
year = {2018}
}
@article{Silverh,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 2 Markov Decision Processes.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 2: Markov Decision Processes}}
}
@article{Silveri,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 3 Planning by Dynamic Programming.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 3: Planning by Dynamic Programming}}
}
@article{Silverb,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 1 Introduction to Reinforcement Learning.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 1: Introduction to Reinforcement Learning}}
}
@article{Silverf,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 5 Model-Free Control.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 5: Model-Free Control}}
}
@article{Silvere,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 4 Model-Free Prediction.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 4: Model-Free Prediction}}
}
@article{Silverd,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 7 Policy Gradient.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 7: Policy Gradient}}
}
@article{Silverg,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 6 Value Function Approximation.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 6: Value Function Approximation}}
}
@article{Triggs,
author = {Triggs, Bill and Mclauchlan, Philip and Hartley, Richard and Fitzgibbon, Andrew and Technology, Information},
file = {:home/tkorthals/Documents/Mendeley Desktop/Triggs et al. - Unknown - Bundle Adjustment — A Modern Synthesis.pdf:pdf},
keywords = {bundle adjustment,gauge freedom,opti-,scene reconstruction,sparse matrices},
mendeley-groups = {Vision,Vision/Registration {\&} Calibration},
pages = {1--71},
title = {{Bundle Adjustment — A Modern Synthesis}},
volume = {34099}
}
@article{Silver,
author = {Silver, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Silver - Unknown - Lecture 8 Integrating Learning and Planning.pdf:pdf},
mendeley-groups = {Machine Learning/UCL Course on RL},
title = {{Lecture 8: Integrating Learning and Planning}}
}
@article{Suzuki2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.01891v1},
author = {Suzuki, Masahiro and Nakayama, Kotaro and Matsuo, Yutaka},
eprint = {arXiv:1611.01891v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Suzuki, Nakayama, Matsuo - 2017 - Joint multimodal learning with deep generative models.pdf:pdf},
mendeley-groups = {VAE,VAE/Multi-Modal},
pages = {1--12},
title = {{Joint multimodal learning with deep generative models}},
year = {2017}
}
@misc{Abel2018,
abstract = {It's that time again — SpaceNet raised the bar in their third challenge to detect road-networks in overhead imagery around the world. Today, map features such as roads, building footprints, and points of interest are primarily created through manual techniques. In the third SpaceNet challenge, competitors were tasked with finding automated methods for extracting map-ready road networks from high-resolution satellite imagery. This move towards automated extraction of road networks will help bring innovation to computer vision methodologies applied to high-resolution satellite imagery and ultimately help create better maps where they are needed most such as humanitarian efforts, disaster response, and operations. For more details, check out the SpaceNet data repository on AWS and see our previous NVIDIA Developer Blog post on past SpaceNet challenges to extract building footprints. In this post, we approach the current SpaceNet challenge from distinct perspectives. The first part of this blog describes how to directly leverage the full 8-band imagery and manipulate ground truth labels to obtain excellent road networks with relative ease and excellent performance. We next look at how we might exploit the material properties of the road surface itself by using the spectral aspect of the data to create a deep learning solution tailored for a specific spectral signature. Finally, we take creative liberties to think about how we might apply these types of deep learning solutions in a broader operational sense using conditional random fields, percolation theory, and reinforcement learning. Think of this like Bohemian Rhapsody for deep learning (minus the Grammy Hall of Fame).},
author = {Abel, Brown},
file = {:home/tkorthals/Documents/Mendeley Desktop/Abel - 2018 - Solving SpaceNet Road Detection Challenge With Deep Learning.pdf:pdf},
mendeley-groups = {Machine Learning/RL},
title = {{Solving SpaceNet Road Detection Challenge With Deep Learning}},
url = {https://devblogs.nvidia.com/solving-spacenet-road-detection-challenge-deep-learning/},
year = {2018}
}
@article{Drozdzal,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.09326v3},
author = {Drozdzal, Michal and Vazquez, David and Romero, Adriana and Bengio, Yoshua},
eprint = {arXiv:1611.09326v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Drozdzal et al. - Unknown - The One Hundred Layers Tiramisu Fully Convolutional DenseNets for Semantic Segmentation.pdf:pdf},
mendeley-groups = {Machine Learning},
title = {{The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation}}
}
@misc{Teichmann,
author = {Teichmann, Marvin},
mendeley-groups = {Machine Learning},
title = {{KitiSeg (GitHub)}},
url = {https://github.com/MarvinTeichmann/KittiSeg}
}
@article{Long2018,
author = {Long, Jon and Shelhamer, Evan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Long, Shelhamer - 2018 - Fully Convolutional Networks Workshop.pdf:pdf},
mendeley-groups = {Machine Learning},
number = {1},
pages = {62--75},
title = {{Fully Convolutional Networks Workshop}},
url = {http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf},
volume = {28},
year = {2018}
}
@article{Shelhamer,
author = {Shelhamer, Evan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shelhamer, Long, Darrell - 2017 - Fully Convolutional Networks for Semantic Segmentation.pdf:pdf},
mendeley-groups = {Machine Learning},
title = {{Fully Convolutional Networks for Semantic Segmentation (GitHub)}},
url = {https://github.com/shelhamer/fcn.berkeleyvision.org}
}
@article{Teichmann2016,
abstract = {While most approaches to semantic reasoning have focused on improving performance, in this paper we argue that computational times are very important in order to enable real time applications such as autonomous driving. Towards this goal, we present an approach to joint classification, detection and semantic segmentation via a unified architecture where the encoder is shared amongst the three tasks. Our approach is very simple, can be trained end-to-end and performs extremely well in the challenging KITTI dataset, outperforming the state-of-the-art in the road segmentation task. Our approach is also very efficient, taking less than 100 ms to perform all tasks.},
archivePrefix = {arXiv},
arxivId = {1612.07695},
author = {Teichmann, Marvin and Weber, Michael and Zoellner, Marius and Cipolla, Roberto and Urtasun, Raquel},
doi = {10.1109/CVPR.2012.6248074},
eprint = {1612.07695},
file = {:home/tkorthals/Documents/Mendeley Desktop/Teichmann et al. - 2016 - MultiNet Real-time Joint Semantic Reasoning for Autonomous Driving.pdf:pdf},
isbn = {9781467312264},
issn = {10636919},
mendeley-groups = {Machine Learning/RL},
title = {{MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving}},
url = {http://arxiv.org/abs/1612.07695},
year = {2016}
}
@article{He2017,
abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
archivePrefix = {arXiv},
arxivId = {1703.06870},
author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
doi = {10.1109/ICCV.2017.322},
eprint = {1703.06870},
file = {:home/tkorthals/Documents/Mendeley Desktop/He et al. - 2017 - Mask R-CNN.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
mendeley-groups = {Machine Learning/RL,Machine Learning},
pages = {2980--2988},
pmid = {303902},
title = {{Mask R-CNN}},
volume = {2017-Octob},
year = {2017}
}
@article{Gross2012,
author = {Gross, Herbert},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gross - 2012 - Design and Correction of optical Systems Part 13 Correction of aberrations 2 Summer term 2012.pdf:pdf},
mendeley-groups = {Vision,Vision/Registration {\&} Calibration},
pages = {1--51},
title = {{Design and Correction of optical Systems Part 13 : Correction of aberrations 2 Summer term 2012}},
year = {2012}
}
@article{Eggert1997,
abstract = {A common need in machine vision is to com-pute the 3-D rigid body transformation that aligns two sets of points for which correspondence is known. A compara-tive analysis is presented here of four popular and efficient algorithms, each of which computes the translational and ro-tational components of the transform in closed form, as the solution to a least squares formulation of the problem. They differ in terms of the transformation representation used and the mathematical derivation of the solution, using respec-tively singular value decomposition or eigensystem compu-tation based on the standard [R, T] representation, and the eigensystem analysis of matrices derived from unit and dual quaternion forms of the transform. This comparison presents both qualitative and quantitative results of several experi-ments designed to determine (1) the accuracy and robust-ness of each algorithm in the presence of different levels of noise, (2) the stability with respect to degenerate data sets, and (3) relative computation time of each approach under different conditions. The results indicate that under " ideal " data conditions (no noise) certain distinctions in accuracy and stability can be seen. But for " typical, real-world " noise levels, there is no difference in the robustness of the final solutions (contrary to certain previously published results). Efficiency, in terms of execution time, is found to be highly dependent on the computer system setup.},
author = {Eggert, D. W. and Lorusso, A. and Fisher, R. B.},
doi = {10.1007/s001380050048},
file = {:home/tkorthals/Documents/Mendeley Desktop/Eggert, Lorusso, Fisher - 1997 - Estimating 3-D rigid body transformations A comparison of four major algorithms.pdf:pdf},
isbn = {0952189828},
issn = {09328092},
journal = {Machine Vision and Applications},
keywords = {3-D rigid transformations,Motion analysis,Pose estimation},
mendeley-groups = {Vision},
number = {5-6},
pages = {272--290},
pmid = {21736739},
title = {{Estimating 3-D rigid body transformations: A comparison of four major algorithms}},
volume = {9},
year = {1997}
}
@article{ZZhang2002,
abstract = {We propose a flexible new technique to easily calibrate a camera. It is well suited for use without specialized knowledge of 3D geometry or computer vision. The technique only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique, and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthog- onal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one step from laboratory environments to real world use.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zhang, Zhengyou},
doi = {10.1109/34.888718},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhang - 2002 - A Flexible New Technique for Camera Calibration (Technical Report).pdf:pdf},
isbn = {MSR-TR-98-71},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
mendeley-groups = {Vision},
number = {11},
pages = {1330--1334},
pmid = {131},
title = {{A Flexible New Technique for Camera Calibration (Technical Report)}},
volume = {22},
year = {2002}
}
@misc{Wikipedia2017,
author = {Wikipedia},
mendeley-groups = {Vision,Vision/Registration {\&} Calibration},
title = {{Petzval field curvature}},
url = {https://en.wikipedia.org/wiki/Petzval{\_}field{\_}curvature http://www.telescope-optics.net/curvature.htm},
year = {2017}
}
@article{Stachniss2016,
author = {Stachniss, Cyrill},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stachniss - 2016 - Graph-Based SLAM and Sparsity ICRA 2016 Tutorial on SLAM.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Graph},
title = {{Graph-Based SLAM and Sparsity ICRA 2016 Tutorial on SLAM}},
url = {http://www.dis.uniroma1.it/{~}labrococo/tutorial{\_}icra{\_}2016/icra16{\_}slam{\_}tutorial{\_}stachniss.pdf},
year = {2016}
}
@article{Divossen,
author = {Divossen, R.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Divossen - Unknown - Vorlesung Kameratracking.pdf:pdf},
mendeley-groups = {Vision/Tracking},
title = {{Vorlesung Kameratracking}},
url = {http://docplayer.org/4115527-4-kameratracking-vorlesung-virtuelle-realitaet-und-augmented-reality-dank-an-rene-divossen-u-n-i-v-e-r-s-i-t-ae-t-koblenz-landau.html}
}
@article{Abawi2004,
abstract = {Optical tracking with fiducial markers is commonly used in augmented reality (AR) systems - AR systems that rely on the ARToolKit (Kato and Billinghurst, 1999) are prominent examples. The information obtained by the tracking subsystem are widely used in AR, e.g. in order to calculate how virtual objects should be located and oriented. The results of extensive accuracy experiments with single markers are reported and made operational by the definition of an accuracy function. The results show a specific distribution of tracking accuracy dependent on distance as well as angle between camera and marker. This insight is applicable for designing the set-up of AR applications in general that rely on optical tracking.},
author = {Abawi, Daniel F. and Bienwald, Joachim and D{\"{o}}rner, Ralf},
doi = {10.1109/ISMAR.2004.8},
file = {:home/tkorthals/Documents/Mendeley Desktop/Abawi, Bienwald, D{\"{o}}rner - 2004 - Accuracy in optical tracking with fiducial markers An accuracy function for ARToolKit.pdf:pdf},
isbn = {0769521916},
journal = {ISMAR 2004: Proceedings of the Third IEEE and ACM International Symposium on Mixed and Augmented Reality},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
number = {Ismar},
pages = {260--261},
title = {{Accuracy in optical tracking with fiducial markers: An accuracy function for ARToolKit}},
year = {2004}
}
@article{Khan2018,
abstract = {OAPA Fiducial markers are images or landmarks placed in real environment, typically used for pose estimation and camera tracking. Reliable fiducials are strongly desired for many Augmented Reality (AR) applications, but currently there is no systematic method to design highly reliable fiducials. In this paper, we present Fiducial Marker Optimizer (FMO), a tool to optimize the design attributes of ARToolKit markers, including black to white (B:W) ratio, edge sharpness and information complexity, and to reduce inter-marker confusion. For these operations the FMO provides a user friendly interface at the front-end and specialized image processing algorithms at the back-end. We tested manually designed markers and FMO optimized markers in ARToolKit and found that the latter were more robust. The FMO will be used for designing highly reliable fiducials in easy to use fashion. It will improve the application {\&} {\#}x2019;s performance where it is used.},
author = {Khan, D. and Ullah, S. and Yan, D. and Rabbi, I. and Richard, P. and Hoang, T. and Billinghurst, M. and Zhang, X.},
doi = {10.1109/ACCESS.2018.2801028},
file = {:home/tkorthals/Documents/Mendeley Desktop/Khan et al. - 2018 - Robust tracking through the design of high quality fiducial markers An optimization tool for ARToolKit.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {ARToolKit,Augmented Reality,Cameras,Complexity theory,Fiducial markers,Libraries,Marker tracking,Robust recognition,Robustness,Tools},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
number = {c},
title = {{Robust tracking through the design of high quality fiducial markers: An optimization tool for ARToolKit}},
volume = {4},
year = {2018}
}
@article{EPSCStrategicNotes-TheAgeofArtificialIntelligence2016,
annote = {- wir brauchen mehr Nachwuchskr{\"{a}}fte welche das Thema verstehen
- Der Mensch soll durch KI unterst{\"{u}}tzt werden},
author = {{EPSC Strategic Notes - The Age of Artificial Intelligence}},
file = {:home/tkorthals/Documents/Mendeley Desktop/EPSC Strategic Notes - The Age of Artificial Intelligence - 2016 - The Age of Artificial Intelligence - Towards a European Strategy for.pdf:pdf},
journal = {Forbes},
mendeley-groups = {CLAAS SeMAV/2018-04-25{\_}Vortragsprobe},
number = {29},
pages = {1--17},
title = {{The Age of Artificial Intelligence - Towards a European Strategy for Human-Centric Machines}},
year = {2016}
}
@article{BundesministeriumfurErnahrungundLandwirtschaft2018,
author = {{Bundesministerium f{\"{u}}r Ern{\"{a}}hrung und Landwirtschaft}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bundesministerium f{\"{u}}r Ern{\"{a}}hrung und Landwirtschaft - 2018 - Digitalpolitik Landwirtschaft.pdf:pdf},
mendeley-groups = {CLAAS SeMAV/2018-04-25{\_}Vortragsprobe},
number = {April},
title = {{Digitalpolitik Landwirtschaft}},
url = {http://www.bmel.de/SharedDocs/Downloads/Broschueren/DigitalpolitikLandwirtschaft.pdf?{\_}{\_}blob=publicationFile},
year = {2018}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2018 - A Probabilistic Framework for Indoor Mobile Robot Localization in Dynamic and Cluttered Environments.pdf:pdf},
mendeley-groups = {Review},
title = {{A Probabilistic Framework for Indoor Mobile Robot Localization in Dynamic and Cluttered Environments}},
year = {2018}
}
@article{Graves2014,
abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
archivePrefix = {arXiv},
arxivId = {1410.5401},
author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
doi = {10.3389/neuro.12.006.2007},
eprint = {1410.5401},
file = {:home/tkorthals/Documents/Mendeley Desktop/Graves, Wayne, Danihelka - 2014 - Neural Turing Machines.pdf:pdf},
isbn = {0028-0836},
issn = {2041-1723},
mendeley-groups = {Machine Learning/DQN},
pages = {1--26},
pmid = {18958277},
title = {{Neural Turing Machines}},
url = {http://arxiv.org/abs/1410.5401},
year = {2014}
}
@inproceedings{Sundram2018,
annote = {SUMMARY:
This paper describes the design and evaluate the performance of a self developed mini-robot plattform.
Further, the authors present a custom build, two dimensional, laser based ranging module and an algorithm for occupancy grid map construction.
Last, the robot's mapping capabilities are evaluated qualitatively in a closed environment.
The extension to Multi-Agent mapping might be missleading, since it seems that only single-agent mapping with multiple robots is performed.

RATING:
I unfortunately do not endorse the paper to be accepted since it lacks in inovation and evaluation.
However, the literature recherche is not fully in the scope of the presented.
Many common issues, like a diff. kinematic, are addressed in detail while potentially interesting and novel parts of mapping and sensor modelling via the VL53L0X TOF ranging sensor are not elaborated in depth.
The evaluation is very poor and only qualitative exampels are given.
The term "multi-agent" is very missleading and the authors should consider to remove all "multi-agent" reference for the sake of quantitative evaluation of mapping via the VL53L0X.
Even the qualitative evaluation might be tainted due to the BNO55.
Furthermore, many questions are unanswered which I have listed as
issues in the "Comments to authors" section.
I highly recommend the authors to address the issues before
presenting the work.


COMMENTS TO THE AUTHORS (ISSUES BY CHAPTERS):


Title:
- The title might be a bit missleading, since it looks like that you do not really do "multi-agent mapping", but single-agent mapping with multiple robots.
- Why does the author "Gim Song Soh" has an asterics, I connot find any reference to that.
If he is the corresponding author, please say that explicitly.

Abstract:
- Do not write 10x10 as equation

Introduction:
- Robotc systems which are are comparable to the authors work are not cited.
Consider citing the following systems [Herbrechtsmeier 2016] (also look into the work for comparable robots) or mapping scenario [Korthals 2016]
- Rename GPS with GNSS
- You cite already Efles for OGM in [7], so please the very generic citation of Thrun's book regarding OGM in [14]

Korthals, T., Barther, M., Sch{\"{o}}pping, T., Herbrechtsmeier, S., {\&} R{\"{u}}ckert, U. (2016). Occupancy grid mapping with highly uncertain range sensors based on inverse particle filters. In ICINCO 2016 - Proceedings of the 13th International Conference on Informatics in Control, Automation and Robotics (Vol. 2).
Herbrechtsmeier, S., Korthals, T., Sch{\"{o}}pping, T., {\&} R{\"{u}}ckert, U. (2016). AMiRo: A Modular {\&} Customizable Open-Source Mini Robot Platform. In ICSTCC.

II. THE MINIATURE ROBOT: ORION
- I think that "9-axis" is kind of an advertisement phrase. It's still 3 axis but measured by three sensors.
- You are inconsistent regarding pose and heading of the variable $\backslash$theta. What is it, and what information is used?
- I've never heard about the "STM43F411". Do you mean the "STM32F411"?
- What do you mean by "The MCU chip assimilates ..."? Does the MCU just bridges the data or does it already do some pre-processing or fusion? Please point that out!
- Don't say "... along the x and y axis". A diff. kinematic can only move along one translatory axis and one rotary axis. If you want to refer to the world frame, use simply the word "plane".
- Fig 1
- Why does the IMU has a bi-directional communication?
- Why does the LIDAR has a uni-directional communication from the MCU to the LIDAR? 
- Eq. 1 might be very naive. Don't you have any overshooting with just a proportional controller?
- Unify your numbers and units: Compare 940nm and 0.8m and all your other values und units

III Mapping appraoch
- So you actually do the "mapping with known poses" and no SLAM, right? Please point that out!
- By "offline mapping module" you mean that you really do the processing on an external device after the recordings using only the presented alorithms? Please point that out, if true.
- oboard -{\textgreater} onboard
- Maybe it is obvious, but it would be nice if you explain that your transformation matrices does only respect 2D, since 3D is not of interest in your setup
- TABLE I
- Put subscript index into text box
- Your angles are wrong, last two angles should be 3/4*pi and pi
- What do you mean by "This value is computed from a sensor model of the ranging sensors but we obtain good results by setting values empirically."
- The sensor model (or more correct the inverse sensor model) might be of very high interest
- What values are set empirically? The values of you sensor model, the values you add/substract from you log-odds ratio when you do a measurement, or just "Algorithm 2"?
- Please double-check if eq. 9 is correct and give a methematical definition for for log-odds
- lprior is broken
- The "Multi-Agent Mapping" chapter might be a bit naive, since you do not talk about coordination which is actually the crucial part

IV. EXPERIMENT
- The "Multi-Agent Run" is actually a multi "Single-Agent Run", since there is no coordination between the robots
- Fig 9
- Why aren't there walls on the left and down side of the maze? Are they deleted by the OGM?
- Explain the artefacts of occupied cells where no wall exists. Are these faulty measurements?
- You really do need a better inverse sensor model to produce a better map.
- Multiple runs would be of interest, to see the drift of the robot during mapping
- No comparision to ground truth map given
- Fig 12
- No comparision to ground truth map given
- Evaluation and overlay of ground truth is missing
- No evaluation on drift during mapping
- Do you have any image of the robot itselfe?},
author = {Sundram, Jugesh and Nguyen, Van Duong and Soh, Gim Song and Bouffanais, Roland and Wood, Kristin},
booktitle = {ICARM},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sundram et al. - 2018 - Development of a Minimal System Architecture for Multi-Agent Occupancy Grid Mapping.pdf:pdf},
mendeley-groups = {Review},
title = {{Development of a Minimal System Architecture for Multi-Agent Occupancy Grid Mapping}},
year = {2018}
}
@article{Bojarski2016,
abstract = {We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads. Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn't automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps. We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 frames per second (FPS).},
archivePrefix = {arXiv},
arxivId = {1604.07316},
author = {Bojarski, Mariusz and {Del Testa}, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
eprint = {1604.07316},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bojarski et al. - 2016 - End to End Learning for Self-Driving Cars.pdf:pdf},
isbn = {9781450351867},
mendeley-groups = {Machine Learning/DQN},
pages = {1--9},
title = {{End to End Learning for Self-Driving Cars}},
url = {http://arxiv.org/abs/1604.07316},
year = {2016}
}
@inproceedings{Schopping2018,
address = {Suncrest},
author = {Sch{\"{o}}pping, Thomas and Korthals, Timo and Hesse, Marc and R{\"{u}}ckert, Ulrich},
booktitle = {9th International Conference on Robotics in Education},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sch{\"{o}}pping et al. - 2018 - AMiRo A Mini Robot as Versatile Teaching Platform.pdf:pdf},
publisher = {Springer},
title = {{AMiRo: A Mini Robot as Versatile Teaching Platform}},
year = {2018}
}
@inproceedings{Rajalakshmi2016,
abstract = {— Internet Of Things (IoT)is a shared network of objects or things which can interact with each other provided the internet connection. IoT plays an important role in agriculture industry which can feed 9.6 billion people on the Earth by 2050. Smart Agriculture helps to reduce wastage, effective usage of fertilizer and thereby increase the crop yield. In this work, a system is developed to monitor crop-field using sensors (soil moisture, temperature, humidity, Light) and automate the irrigation system. The data from sensors are sent to web server database using wireless transmission. In server database the data are encoded in JSON format. The irrigation is automated if the moisture and temperature of the field falls below the brink. In greenhouses light intensity control can also be automated in addition to irrigation. The notifications are sent to farmers' mobile periodically. The farmers' can able to monitor the field conditions from anywhere. This system will be more useful in areas where water is in scarce. This system is 92{\%} more efficient than the conventional approach.},
author = {Rajalakshmi, P. and {Devi Mahalakshmi}, S.},
booktitle = {Proceedings of the 10th International Conference on Intelligent Systems and Control, ISCO 2016},
doi = {10.1109/ISCO.2016.7726900},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rajalakshmi, Devi Mahalakshmi - 2016 - IOT based crop-field monitoring and irrigation automation.pdf:pdf},
isbn = {9781467378079},
mendeley-groups = {CLAAS SeMAV/Sensorik},
title = {{IOT based crop-field monitoring and irrigation automation}},
year = {2016}
}
@article{Fountas2015,
abstract = {Farm Management Information Systems (FMIS) in agriculture have evolved from simple farm recordkeeping into sophisticated and complex systems to support production management. The purpose of current FMIS is to meet the increased demands to reduce production costs, comply with agricultural standards, and maintain high product quality and safety. This paper presents current advancements in the functionality of academic and commercial FMIS. The study focuses on open-field crop production and centeres on farm managers as the primary users and decision makers. Core system architectures and application domains, adoption and profitability, and FMIS solutions for precision agriculture as the most information-intensive application area were analyzed. Our review of commercial solutions involved the analysis of 141 international software packages, categorized into 11 functions. Cluster analysis was used to group current commercial FMIS as well as examine possible avenues for further development. Academic FMIS involved more sophisticated systems covering compliance to standards applications, automated data capture as well as interoperability between different software packages. Conversely, commercial FMIS applications targeted everyday farm office tasks related to budgeting and finance, such as recordkeeping, machinery management, and documentation, with emerging trends showing new functions related to traceability, quality assurance and sales.},
author = {Fountas, S. and Carli, G. and S{\o}rensen, C.G. and Tsiropoulos, Z. and Cavalaris, C. and Vatsanidou, A. and Liakos, B. and Canavari, M. and Wiebensohn, J. and Tisserye, B.},
doi = {10.1016/J.COMPAG.2015.05.011},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fountas et al. - 2015 - Farm management information systems Current situation and future perspectives.pdf:pdf},
issn = {0168-1699},
journal = {Computers and Electronics in Agriculture},
mendeley-groups = {CLAAS SeMAV/Farm management},
month = {jul},
pages = {40--50},
publisher = {Elsevier},
title = {{Farm management information systems: Current situation and future perspectives}},
url = {https://www.sciencedirect.com/science/article/pii/S0168169915001337},
volume = {115},
year = {2015}
}
@article{Majumdar2017,
abstract = {In agriculture sector where farmers and agribusinesses have to make innumerable decisions every day and intricate complexities involves the various factors influencing them. An essential issue for agricultural planning intention is the accurate yield estimation for the numerous crops involved in the planning. Data mining techniques are necessary approach for accomplishing practical and effective solutions for this problem. Agriculture has been an obvious target for big data. Environmental conditions, variability in soil, input levels, combinations and commodity prices have made it all the more relevant for farmers to use information and get help to make critical farming decisions. This paper focuses on the analysis of the agriculture data and finding optimal parameters to maximize the crop production using data mining techniques like PAM, CLARA, DBSCAN and Multiple Linear Regression. Mining the large amount of existing crop, soil and climatic data, and analysing new, non-experimental data optimizes the production and makes agriculture more resilient to climatic change.},
author = {Majumdar, Jharna and Naraseeyappa, Sneha and Ankalaki, Shilpa},
doi = {10.1186/s40537-017-0077-4},
issn = {21961115},
journal = {Journal of Big Data},
mendeley-groups = {CLAAS SeMAV/Entschiedungsfindung},
number = {1},
title = {{Analysis of agriculture data using data mining techniques: application of big data}},
volume = {4},
year = {2017}
}
@article{Lundstrom2018,
abstract = {Precision agriculture is an important part of the sustainable intensification of agriculture, where information and communications technology and other technologies are necessary, but not sufficient for sustainable farming systems. The technology must fit into farmers' practice and be handled by their experienced-based, situated knowledge in order to contribute to increased sustainability in their farming. This study analysed the relationship between farmers' experience-based situated knowledge and the use of agricultural decision support systems in order to develop care by farmers in their practice. The theoretical framework of distributed cognition was used as a lens when investigating and analysing farmers' use of an agricultural decision support system called CropSAT developed for calculation of variable rate application files for nitrogen fertilisation from satellite images. In the case study, the unit of analysis was broadened to the whole socio-technical system of farmers' decision-making and learning, including other people and different kinds of tools and artefacts. The results revealed that social contexts could support farmers' development of cognitive strategies for use of agricultural decision support systems, e.g. CropSAT, and could thus facilitate decision-making and learning through development of enhanced professional vision that hopefully may increase farmers' situated knowledge and care in PA.},
author = {Lundstr{\"{o}}m, Christina and Lindblom, Jessica},
doi = {10.1016/j.agsy.2017.10.004},
issn = {0308521X},
journal = {Agricultural Systems},
mendeley-groups = {CLAAS SeMAV/Entschiedungsfindung},
title = {{Considering farmers' situated knowledge of using agricultural decision support systems (AgriDSS) to Foster farming practices: The case of CropSAT}},
volume = {159},
year = {2018}
}
@inproceedings{Schopping2018b,
author = {Sch{\"{o}}pping, Thomas and Rothmann, Marc and Korthals, Timo and Hesse, Marc and R{\"{u}}ckert, Ulrich},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sch{\"{o}}pping et al. - 2018 - µRTWare a Lightweight Real-Time Middleware with Built-In System Failure Detection.pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Sch{\"{o}}pping et al. - 2018 - µRTWare a Lightweight Real-Time Middleware with Built-In System Failure Detection(2).pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Sch{\"{o}}pping et al. - 2018 - µRTWare a Lightweight Real-Time Middleware with Built-In System Failure Detection(3).pdf:pdf},
number = {1},
title = {{µRTWare: a Lightweight Real-Time Middleware with Built-In System Failure Detection}},
year = {2018}
}
@article{Korthals2018,
author = {Korthals, Timo and Kragh, Mikkel and Christiansen, Peter and Karstoft, Henrik and J{\o}rgensen, Rasmus N. and R{\"{u}}ckert, Ulrich},
journal = {Frontiers in Robotics and AI Robotic Control Systems},
number = {1},
title = {{Obstacle Detection and Mapping in Agriculture for Process Evaluation}},
url = {https://www.frontiersin.org/research-topics/5597/multi-modal-sensor-fusion},
volume = {1},
year = {2018}
}
@article{Mohanraj2016,
abstract = {Agriculture sector in India is diminishing day by day which affects the production capacity of ecosystem. There is an exigent need to solve the problem in the domain to restore vibrancy and put it back on higher growth. The paper proposes an e-Agriculture Application based on the framework consisting of KM-Knowledge base and Monitoring modules. To make profitable decisions, farmers need information throughout the entire farming cycle. The required information is scattered in various places which includes real time information such as market prices and current production level stats along with the available primary crop knowledge. A knowledge dataflow model is constructed connecting various scattered sources to the crop structures. The world around is getting automated replacing manual procedures with the advancement of technology, since it is energy efficient and engross minimal man power. The paper proposes the advantages of having ICT in Indian agricultural sector, which shows the path for rural farmers to replace some of the conventional techniques. Monitoring modules are demonstrated using various sensors for which the inputs are fed from Knowledge base. A prototype of the mechanism is carried out using TI CC3200 Launchpad interconnected sensors modules with other necessary electronic devices. A comparative study is made between the developed system and the existing systems. The system overcomes limitations of traditional agricultural procedures by utilizing water resource efficiently and also reducing labour cost.},
author = {Mohanraj, I. and Ashokumar, Kirthika and Naren, J.},
doi = {10.1016/j.procs.2016.07.275},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mohanraj, Ashokumar, Naren - 2016 - Field Monitoring and Automation Using IOT in Agriculture Domain.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Knowledge Base,Monitoring,Ontology,e-Agriculture},
mendeley-groups = {CLAAS SeMAV/Sensorik},
number = {September},
pages = {931--939},
publisher = {The Author(s)},
title = {{Field Monitoring and Automation Using IOT in Agriculture Domain}},
url = {http://dx.doi.org/10.1016/j.procs.2016.07.275},
volume = {93},
year = {2016}
}
@article{Kumar2017,
abstract = {Precision agriculture (PA) is an interdisciplinary concept of integrating information technology in agriculture to increase the production and quality of the crops. One of the most important and interesting information of technology is Wireless Sensor Network (WSN). This technology is used to collect, monitor and analyse the data from the field of agriculture. This interdisciplinary technology will boost the crop productivity and maintain quality for example, monitoring the pest and disease control, animal tracking and strength of the crop. In this paper, we have surveyed the importance of sensor in PA and the importance of WSN technologies for remote monitoring in the various applications of the agriculture field.},
author = {Kumar, Subramania Ananda and Ilango, Paramasivam},
doi = {10.1007/s11277-017-4890-z},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kumar, Ilango - 2017 - The Impact of Wireless Sensor Network in the Field of Precision Agriculture A Review.pdf:pdf},
issn = {0929-6212},
journal = {Wireless Personal Communications},
keywords = {Precision agriculture (PA),Wireless sensor network,pa,precision agriculture,{\'{a}} sensors {\'{a}} remote,{\'{a}} wireless sensor network},
mendeley-groups = {CLAAS SeMAV/Sensorik},
number = {1},
pages = {685--698},
publisher = {Springer US},
title = {{The Impact of Wireless Sensor Network in the Field of Precision Agriculture: A Review}},
url = {http://link.springer.com/10.1007/s11277-017-4890-z},
volume = {98},
year = {2017}
}
@article{La2017,
author = {La, Woong Gyu and Yoo, Seungho and Kim, Hwangnam},
file = {:home/tkorthals/Documents/Mendeley Desktop/La, Yoo, Kim - 2017 - DROCS Distributed multi-Robot On-demand Control System.pdf:pdf},
mendeley-groups = {Review},
title = {{DROCS: Distributed multi-Robot On-demand Control System}},
year = {2017}
}
@article{Sabatini2018,
annote = {Confidential comments to the editorial staff:

I endorse the paper to be accepted since it is
within the scope of the conference and presents a
quantitative improvement.
However, the quality of the paper is questionable,
literature recherche is not within the scope of the
approach (SLAM vs. uncertain sensors) and the evaluation
might be tainted due to odometry and evaluation approach.
Thus, many questions are unanswered which I have listed as
issues in the "Comments to authors" section.
I highly recommend the authors to address the issues before
presenting the work.




Comments to authors:

The authors describe the superimposing of a dithering to a
robots trajectory to circumvent the drawbacks of range
sensors with low angular resolution to improving the
mapping quality along a pre-defined path. A practical
evaluation is given by a robot with differential kinematic
and a LeddarVu8 solid-state range sensor.
While the simple, yet effective, the idea seems to be
novel,
the presentation of the approach lacks in terms of
nomenclature and quality.
Furthermore, the evaluation approach is done using the
robot's odometry which obviously taints the results.
Lastly, on the one hand, literature is given for SLAM which
has nothing to do with the presented approach.
On the other hand, current literature for similar
approaches is missing. 
However, I endorse the paper to be accepted since it is
within the scope of the conference and presents a
quantitative improvement even with odometry.

I highly recommend to address the following issues:


Issues:
- Title: the words "... dynamic dithering ..." are 
misleading since you use a constant dithering.
Thus, remove "dynamic" in the title.

- Fig. 2 seems to be copied form some datasheet of the
LeddarVu8 device, which is not cited. 

- The introduction to OGM is very exhaustively, while the
recap on similar techniques to improve
mapping via highly uncertain sensors is very rare.
Please add more comparable literature to your
work like:
"Korthals, T., et al. (2016). Occupancy grid mapping
with highly uncertain range
sensors based on inverse particle filters. In ICINCO
2016 - Proceedings of the 13th International
Conference on Informatics in Control, Automation and
Robotics (Vol. 2)." (http://bit.ly/2H2Ofme)

- Howie Chosset [14] does not literally introduce
"'inverse' sensor model" in this reference.

- Please cite Figure 3 if copied

- Be alot more expressive of the formulation of the inverse
model of your solid state LiDAR in eq. (4) and (5), since
this is a crucial condition for your ongoing algorithms
-- what are d{\_}1, d{\_}2, d{\_}3, $\backslash$sigma{\_}$\backslash$Theta and how have you
determined these parameters?
-- what are the parameters of the linear function g in (5)?

- Figure 9: the mapping without dithering has a wider
coverage of the wall (from top to bottom) than the map-
ping with dithering: This is counter-intuitive and not
explained in the paper

- This paper has nothing to do with SLAM since you use
plain odometry for your mapping. However, SLAM is
exhaustively explained in the introduction: Please remove
these references and add more references to mapping with
sensors having high uncertainties.

- The graphs in Figure 9 and 11 are somehow broken in the
beginning. What happens there especially with the red
line in Figure 11, which flips oddly?

- Why have you used odometry and not a "mapping with known
poses" approach? This would show the real performance of
your approach and you might get rid of the poor WOE in
the end caused by odometry?

- The WOE metric might be not perfect for two reasons:
-- 1. You compare probabilities (p(m{\_}ij)) with binary
values (m{\_}ij{\_}gt). This might not be optimal in case of
path traversal.
I assume that the overall path with dithering might be
longer and thus, more LiDAR scans can be performed du-
ring path traversal compared to the non dithered one.
Therefore, the convergence of the prob. is naturally
higher which result in an unfair comparison.
Commonly, a binary likelihood map is extracted from all
the cell probabilities (which then can be easily put
into Receiver Operator Characteristics and so on)
-- 2. The WOE evaluates even unseen cells, which might
result in an error bias. Your metric will never reach
100{\%} if not all cells are explorable.

- How have you chosen your wall thickness in the ground
truth map, and how do they correspond to the LiDARs
uncertainty in the evaluation?

- Comparing figure 8 and 9: Choose one representation for
your walls: red vs blue. Btw: Why do the walls have
different thicknesses?

- Make some practical statements regarding ware out of the
motors: how long do they survive such an oscillation?

- It is explained in IV.A, that only the velocity
$\backslash$omage{\_}{\{}dither{\}} is chosen, how about the underlying
frequency and amplitude which is of higher interest in
your later sections?

- Figure 9, Snapshot A: Why do the scans have different
intensities in the beginning (compare dither vs.
non-dither). Do you use different inverse sensor models?

- Give a reference to the robot model


Format issues:
- Use Capitalization in the Title
- Keywords are missing
- Write constants and operator properly.
-- e.g.: equation (6) 
--- "WOE" is half italic, half non-italic
--- "OR" is a function ={\textgreater} non-italic
--- "occ", "emp", "gt" is text ={\textgreater} non-italic
-- e.g. equation (3)
--- "log" is an operator ={\textgreater} non-italic
- The braces "[", "]" for units are non-standard. Use "(",
")" or textual "in": "Time in s" "Time (s)"
- The format of the axis labels, legends, grids, and
annotations differ in almost all figures
-- e.g. Fig. 7.: some have grids, and one not
-- e.g. Fig. 9.: title and axis format varies extremely
- Better use constantly "°" instead of "deg" in the figures
and text 
- Avoid pixelated graphs like in Fig. 11 and Fig. 9
- Use proper spacing between numbers and units: 25° vs 25 °
- Punctuation after equation (2)



Typos:
- Fig.2:
-- functionig -{\textgreater} functioning
-- sensor field ... -{\textgreater} sensor's field ...
- Figure 8: blu -{\textgreater} blue},
author = {Sabatini, Stefano and Corno, Matteo and Fiorenti, Simone and Savaresi, Sergio Matteo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sabatini et al. - 2018 - Improving occupancy grid mapping via dynamical dithering for a mobile robot equipped with solid-state LiDAR sen.pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Sabatini et al. - 2018 - Improving occupancy grid mapping via dynamical dithering for a mobile robot equipped with solid-state LiDAR (2).pdf:pdf},
mendeley-groups = {Review},
title = {{Improving occupancy grid mapping via dynamical dithering for a mobile robot equipped with solid-state LiDAR sensors}},
year = {2018}
}
@inproceedings{Thai2018,
annote = {This work provides an overview between measure and control systems as operating point and set point control.

Format
- it seems the the IARA template was not used
- font type is wrong (verdana (?) vs. Times New Roman)
- editor rules as stated by "http://www.iaria.org/editorialrules.html" are not respected
- mixing fonts
- Equations are included pice-wise as blury images and are hard to read
- "Fig."" should be "Figure"
- Numbering of equations is not aligned

Title and Authors
- capitalize all nouns, pronouns and verbs, and all other words of four or more letters, e.g., "Robots in Space"
- don't capitalize surname
- Follow the format for authors name and affiliation as stated in the template (line 1 - 4)

Comments
- lack of english grammar
- it is very hard to understand the overall goal and contribution
- almost the whole paper consists out of the problem formulation (s.t. Section II) and goes straight to applications afterwards 
- the contribution is not well formulated and thus not clear
- no evaluations are given
- "recent papers ..." and other mentioned work is not referenced

Resumee:
Based on the poor language, format quality, and missing contribution for the topic of this conference I consider the paper to be rejeted.},
author = {Thai, Thanh Nga},
booktitle = {ICAS},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thai - 2018 - Non-linear characterization measurement as an advance control method.pdf:pdf},
keywords = {-non-linear},
mendeley-groups = {Review},
title = {{Non-linear characterization measurement as an advance control method}},
year = {2018}
}
@inbook{Ruckelshausen2015,
abstract = {Manually performed measurements in field phenotyping are labor- and time-consuming, often destructive and not objective. Moreover, the complexity and variability of crop plants under field conditions require high-resolution data and filtering. As a consequence, there is a need for spatially and temporally differentiated data, objective data acquisition, and high-throughput technologies. Image-based systems, selective on morphological and spectral crop characteristics, are adequate sensors for further interpretation of raw data in terms of crop properties. In particular multi-sensor and data fusion has a potential to compensate the varying influences of sunlight, dust, moisture, or uneven land in the field. Due to the high-resolution data of image-based systems -- such as digital color cameras, spectral imaging, laser scanning devices, or 3D cameras -- detailed crop properties have become available, even individual plant phenotyping is an option. Autonomous field robots have a high potential for field phenotyping as well as new sensor technologies and virtual phenotyping. Data management is of relevance for field phenotyping, starting from storing the large amounts of raw data up to artificial intelligence algorithms for trait determination. Interdisciplinary cooperation is crucial for the implementation of digital phenotyping into practice.},
address = {New Delhi},
author = {Ruckelshausen, Arno and Busemeyer, Lucas},
booktitle = {Phenomics in Crop Plants: Trends, Options and Limitations},
doi = {10.1007/978-81-322-2226-2_4},
editor = {Kumar, Jitendra and Pratap, Aditya and Kumar, Shiv},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ruckelshausen, Busemeyer - 2015 - Toward Digital and Image-Based Phenotyping.pdf:pdf},
isbn = {978-81-322-2226-2},
mendeley-groups = {CLAAS SeMAV/Definitionen},
pages = {41--60},
publisher = {Springer India},
title = {{Toward Digital and Image-Based Phenotyping}},
url = {https://doi.org/10.1007/978-81-322-2226-2{\_}4},
year = {2015}
}
@article{Zhao2017,
abstract = {We propose a new family of optimization criteria for variational auto-encoding models, generalizing the standard evidence lower bound. We provide conditions under which they recover the data distribution and learn latent features, and formally show that common issues such as blurry samples and uninformative latent features arise when these conditions are not met. Based on these new insights, we propose a new sequential VAE model that can generate sharp samples on the LSUN image dataset based on pixel-wise reconstruction loss, and propose an optimization criterion that encourages unsupervised learning of informative latent features.},
archivePrefix = {arXiv},
arxivId = {1702.08658},
author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
eprint = {1702.08658},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhao, Song, Ermon - 2017 - Towards Deeper Understanding of Variational Autoencoding Models.pdf:pdf},
mendeley-groups = {Machine Learning/Autoencoder,VAE,VAE/Tutorials},
title = {{Towards Deeper Understanding of Variational Autoencoding Models}},
url = {http://arxiv.org/abs/1702.08658},
year = {2017}
}
@article{Lee2013,
abstract = {A 1.0 mm3 general-purpose sensor node platform with heterogeneous multi-layer structure is proposed. The sensor platform benefits from modularity by allowing the addition/removal of IC layers. A new low power I2C interface is introduced for energy efficient inter-layer communication with compatibility to commercial I2C protocols. A self-adapting power management unit is proposed for efficient battery voltage down conversion for wide range of battery voltages and load current. The power management unit also adapts itself by monitoring energy harvesting conditions and harvesting sources and is capable of harvesting from solar, thermal and microbial fuel cells. An optical wakeup receiver is proposed for sensor node programming and synchronization with 228 pW standby power. The system also includes two processors, timer, temperature sensor, and low-power imager. Standby power of the system is 11 nW.},
author = {Lee, Yoonmyung and Bang, Suyoung and Lee, Inhee and Kim, Yejoong and Kim, Gyouho and Ghaed, Mohammad Hassan and Pannuto, Pat and Dutta, Prabal and Sylvester, Dennis and Blaauw, David},
doi = {10.1109/JSSC.2012.2221233},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lee et al. - 2013 - A Modular 1 mm Die-Stacked Sensing Platform With Low Power I C Inter-Die Communication and Multi-Modal Energy Harves.pdf:pdf},
isbn = {978-1-4673-0376-7 IF - 4597{\_}501{\_}Lee (2012) - modular die-stacked sensing platform.pdf{\_} FG - 0},
issn = {0018-9200},
journal = {IEEE Journal of Solid-State Circuits},
keywords = {Batteries,Digital signal processing,I2C protocols,IC layers,Monitoring,Phasor measurement units,Program processors,Random access memory,Standards,Ultra-low power,battery voltage down conversion,die-stacked sensing platform,energy harvesting,general purpose sensor node platform,heterogeneous multilayer structure,integrated circuit interconnections,interlayer communication,low power I2C inter-die communication,low-power electronics,low-power imager,microbial fuel cells,microsensors,multilayers,multimodal energy harvesting,optical wakeup receiver,power 11 nW,power 228 pW,protocols,self-adapting power management unit,sensor node programming,smart dust,system buses,temperature sensor,wireless sensor node},
mendeley-groups = {CLAAS SeMAV/Sensorik},
number = {1},
pages = {229--243},
title = {{A Modular 1 mm³ Die-Stacked Sensing Platform With Low Power I²C Inter-Die Communication and Multi-Modal Energy Harvesting}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6380562},
volume = {48},
year = {2013}
}
@article{Fox2010,
abstract = {This tutorial describes the mean-field variational Bayesian approximation to inference in graphical models, using modern machine learning terminology rather than statistical physics concepts. It begins by seeking to find an approximate mean- field distribution close to the target joint in the KL-divergence sense. It then derives local node updates and reviews the recent Variational Message Passing framework.},
author = {Fox, C W and Roberts, S J},
doi = {10.1007/s10462-011-9236-8},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fox, Roberts - 2010 - A tutorial on variational Bayesian inference.pdf:pdf},
isbn = {1367-4811 (Electronic) 1367-4803 (Linking)},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {mean-field,tutorial,variational bayes},
mendeley-groups = {Machine Learning/Autoencoder},
pages = {1--11},
pmid = {25123903},
title = {{A tutorial on variational Bayesian inference}},
url = {papers2://publication/uuid/1B6D2DDA-67F6-4EEE-9720-2907FFB14789},
year = {2010}
}
@article{He2015,
abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94{\%} top-5 test error on the ImageNet 2012 classification dataset. This is a 26{\%} relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66{\%}). To our knowledge, our result is the first to surpass human-level performance (5.1{\%}, Russakovsky et al.) on this visual recognition challenge.},
archivePrefix = {arXiv},
arxivId = {1502.01852},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.1109/ICCV.2015.123},
eprint = {1502.01852},
file = {:home/tkorthals/Documents/Mendeley Desktop/He et al. - 2015 - Delving deep into rectifiers Surpassing human-level performance on imagenet classification.pdf:pdf},
isbn = {9781467383912},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
mendeley-groups = {Machine Learning},
pages = {1026--1034},
pmid = {7410480},
title = {{Delving deep into rectifiers: Surpassing human-level performance on imagenet classification}},
volume = {2015 Inter},
year = {2015}
}
@article{Doersch2016,
abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
archivePrefix = {arXiv},
arxivId = {1606.05908},
author = {Doersch, Carl},
doi = {10.3389/fphys.2016.00108},
eprint = {1606.05908},
file = {:home/tkorthals/Documents/Mendeley Desktop/Doersch - 2016 - Tutorial on Variational Autoencoders.pdf:pdf},
isbn = {1532-4435},
issn = {1664042X},
keywords = {neural networks,prediction,structured,unsupervised learning,variational autoencoders},
mendeley-groups = {Machine Learning/Autoencoder,VAE/Tutorials},
pages = {1--23},
pmid = {27148061},
title = {{Tutorial on Variational Autoencoders}},
url = {http://arxiv.org/abs/1606.05908},
year = {2016}
}
@article{Blei2017,
abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
archivePrefix = {arXiv},
arxivId = {1601.00670},
author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
doi = {10.1080/01621459.2017.1285773},
eprint = {1601.00670},
file = {:home/tkorthals/Documents/Mendeley Desktop/Blei, Kucukelbir, McAuliffe - 2017 - Variational Inference A Review for Statisticians.pdf:pdf},
isbn = {1601.00670},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Algorithms,Computationally intensive methods,Statistical computing},
mendeley-groups = {Machine Learning/Autoencoder,VAE},
number = {518},
pages = {859--877},
pmid = {303902},
title = {{Variational Inference: A Review for Statisticians}},
volume = {112},
year = {2017}
}
@article{Buda2017,
abstract = {In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that totally eliminates the imbalance, whereas undersampling can perform better when the imbalance is only removed to some extent; (iv) as opposed to some classical machine learning models, oversampling does not necessarily cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.},
archivePrefix = {arXiv},
arxivId = {1710.05381},
author = {Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
eprint = {1710.05381},
file = {:home/tkorthals/Documents/Mendeley Desktop/Buda, Maki, Mazurowski - 2017 - A systematic study of the class imbalance problem in convolutional neural networks.pdf:pdf},
keywords = {class imbalance,convolutional neural networks,deep learning,image},
mendeley-groups = {Machine Learning},
pages = {1--23},
title = {{A systematic study of the class imbalance problem in convolutional neural networks}},
url = {http://arxiv.org/abs/1710.05381},
year = {2017}
}
@misc{Aqeel-Ur-Rehman2014,
abstract = {Due to advancement in technologies and reduction in size, sensors are becoming involved in almost every field of life. Agriculture is one of such domains where sensors and their networks are successfully used to get numerous benefits. Selection of sensors and their effective utilization to solve agricultural domain problems has been an arduous task for novice users due to unavailability of conglomerated information in literature. The aim of this paper is to review the need of wireless sensors in Agriculture, WSN technology and their applications in different aspects of agriculture and to report existing system frameworks in agriculture domain. {\textcopyright} 2011 Elsevier B.V.},
author = {Aqeel-Ur-Rehman and Abbasi, Abu Zafar and Islam, Noman and Shaikh, Zubair Ahmed},
booktitle = {Computer Standards and Interfaces},
doi = {10.1016/j.csi.2011.03.004},
file = {:home/tkorthals/Documents/Mendeley Desktop/Aqeel-Ur-Rehman et al. - 2014 - A review of wireless sensors and networks' applications in agriculture.pdf:pdf},
isbn = {0920-5489},
issn = {09205489},
keywords = {Agriculture,Framework,Sensor and Actuator Network,Sensors},
mendeley-groups = {CLAAS SeMAV/Sensorik},
number = {2},
pages = {263--270},
title = {{A review of wireless sensors and networks' applications in agriculture}},
volume = {36},
year = {2014}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2016 - A review on wireless sensor network in agriculture.pdf:pdf},
keywords = {applications,precision agriculture,wireless sensor network},
number = {10},
pages = {1126--1134},
title = {{A review on wireless sensor network in agriculture}},
volume = {2},
year = {2016}
}
@misc{Ojha2015,
abstract = {The advent of Wireless Sensor Networks (WSNs) spurred a new direction of research in agricultural and farming domain. In recent times, WSNs are widely applied in various agricultural applications. In this paper, we review the potential WSN applications, and the specific issues and challenges associated with deploying WSNs for improved farming. To focus on the specific requirements, the devices, sensors and communication techniques associated with WSNs in agricultural applications are analyzed comprehensively. We present various case studies to thoroughly explore the existing solutions proposed in the literature in various categories according to their design and implementation related parameters. In this regard, the WSN deployments for various farming applications in the Indian as well as global scenario are surveyed. We highlight the prospects and problems of these solutions, while identifying the factors for improvement and future directions of work using the new age technologies.},
author = {Ojha, Tamoghna and Misra, Sudip and Raghuwanshi, Narendra Singh},
booktitle = {Computers and Electronics in Agriculture},
doi = {10.1016/j.compag.2015.08.011},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ojha, Misra, Raghuwanshi - 2015 - Wireless sensor networks for agriculture The state-of-the-art in practice and future challenges.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
keywords = {Agriculture,Agriculture in india,Automation,Sensors and actuators,Wireless sensor networks},
mendeley-groups = {CLAAS SeMAV/Sensorik},
pages = {66--84},
title = {{Wireless sensor networks for agriculture: The state-of-the-art in practice and future challenges}},
volume = {118},
year = {2015}
}
@article{Huang2014,
abstract = {Biodegradable printed circuit boards based on water-soluble materials are demonstrated. These systems can dissolve in water within 10 mins to yield end-products that are environmentally safe. These and related approaches have the potential to reduce hazardous waste streams associated with electronics disposal.},
author = {Huang, Xian and Liu, Yuhao and Hwang, Suk Won and Kang, Seung Kyun and Patnaik, Dwipayan and Cortes, Jonathan Fajardo and Rogers, John A.},
doi = {10.1002/adma.201403164},
file = {:home/tkorthals/Documents/Mendeley Desktop/Huang et al. - 2014 - Biodegradable materials for multilayer transient printed circuit boards.pdf:pdf},
isbn = {1521-4095},
issn = {15214095},
journal = {Advanced Materials},
mendeley-groups = {CLAAS SeMAV/Sensorik},
number = {43},
pages = {7371--7377},
pmid = {25244671},
title = {{Biodegradable materials for multilayer transient printed circuit boards}},
volume = {26},
year = {2014}
}
@inproceedings{Korthals2017a,
abstract = {{\textcopyright} 2017 IEEE. In recent decades, mapping has been increasingly investigated and applied in unmanned terrain, aerial, sea, and underwater vehicles. While exploiting various mapping techniques to build an inner representation of the environment, one of the most famous remaining is occupancy grid mapping. It has been applied to all domains in a 2D/3D fashion for localization, mapping, navigation, and safe path traversal. Until now generally active range measuring sensors like LiDAR or SONAR are exploited to build those maps. With this work the authors want to overcome these barriers by presenting an occupancy mapping framework offering a generic sensor interface. The interface handles occupancy grids as inverse sensor models, which may represent knowledge on different semantical decision levels and therefore build up a semantic grid map stack. The framework offers buffered memory management for efficient storing and shifting and further services for accessing the 2D map stack in different cell-wise pre-fused and topometric ways. Within the framework, two novel techniques operating especially with occupancy grids are presented: First, a novel odds based interpolation filter is introduced, which scales grid maps in a Bayesian way. Second, a Supercell Extracted via Variance-Driven Sampling (SEVDS) algorithm is presented which, abstracts the semantical occupancy grid stack to a topometric map. While this work focuses on the framework's introduction, it is extended by the evaluation of SEVDS against state-of-the-art superpixel approaches to prove its applicability.},
author = {Korthals, T. and Exner, J. and Schopping, T. and Hesse, M.},
booktitle = {2017 European Conference on Mobile Robots, ECMR 2017},
doi = {10.1109/ECMR.2017.8098673},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals et al. - 2017 - Semantical occupancy grid mapping framework.pdf:pdf},
isbn = {9781538610961},
title = {{Semantical occupancy grid mapping framework}},
year = {2017}
}
@article{Arkin1997,
author = {Arkin, Ronald C and Balch, Tucker},
file = {:tmp/jetai-final.pdf:pdf},
journal = {Journal of Experimental and Theoretical Artificial Intelligence (JTAI)},
mendeley-groups = {Robotics/Architectures},
pages = {175--189},
title = {{AurA: Principles and Practice in Review}},
url = {http://www.tandfonline.com/doi/abs/10.1080/095281397147068},
volume = {9},
year = {1997}
}
@techreport{Amazone2013,
author = {Amazone and Kiefer, Stefan},
file = {:home/tkorthals/Documents/Mendeley Desktop/amazone, Kiefer - 2013 - Weite Reihenabst{\"{a}}nde in Raps und Getreide - Chancen und Grenzen.pdf:pdf},
mendeley-groups = {CLAAS SeMAV},
title = {{Weite Reihenabst{\"{a}}nde in Raps und Getreide - Chancen und Grenzen}},
url = {http://www.amazone.de/files/Vortrag{\_}4{\_}Weite{\_}Reihenabstaende{\_}in{\_}Raps{\_}und{\_}Getreide{\_}Chancen{\_}und{\_}Grenzen{\_}Stefan{\_}Kiefer{\_}AMAZONE.pdf},
year = {2013}
}
@article{VandenBergh2015,
abstract = {Superpixel algorithms aim to over-segment the image by grouping pixels that belong to the same object. Many state-of-the-art superpixel algorithms rely on minimizing objective functions to enforce color ho- mogeneity. The optimization is accomplished by sophis- ticated methods that progressively build the superpix- els, typically by adding cuts or growing superpixels. As a result, they are computationally too expensive for real-time applications. We introduce a new approach based on a simple hill-climbing optimization. Starting from an initial superpixel partitioning, it continuously refines the superpixels by modifying the boundaries. We define a robust and fast to evaluate energy function, based on enforcing color similarity between the bound- aries and the superpixel color histogram. In a series of experiments, we show that we achieve an excellent com- promise between accuracy and efficiency. We are able to achieve a performance comparable to the state-of- the-art, but in real-time on a single Intel i7 CPU at 2.8GHz.},
archivePrefix = {arXiv},
arxivId = {1309.3848},
author = {{Van den Bergh}, Michael and Boix, Xavier and Roig, Gemma and {Van Gool}, Luc},
doi = {10.1007/s11263-014-0744-2},
eprint = {1309.3848},
isbn = {9783642337857},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Segmentation,Superpixels,clustering,hill-climbing,histograms,over-segmentation},
mendeley-groups = {Vision},
number = {3},
pages = {298--314},
title = {{SEEDS: Superpixels Extracted Via Energy-Driven Sampling}},
volume = {111},
year = {2015}
}
@misc{Korthals,
author = {Korthals, Timo},
file = {:opt/repositories/murox/docs/Proximitysensors/VCNL{\_}4010/designingvcnl4010.pdf:pdf;:opt/repositories/murox/docs/Proximitysensors/VCNL{\_}4010/vcnl4010.pdf:pdf},
mendeley-groups = {Robotics/Sensing},
title = {{VCNL4020 Proximity Sensor}}
}
@article{Russell2009,
abstract = {The long-anticipated revision of this {\#}1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Russell, Stuart and Norvig, Peter},
doi = {10.1017/S0269888900007724},
eprint = {9809069v1},
file = {:opt/repositories/murox/docs/Books/Artificial-Intelligence-A-Modern-Approach-3rd-Edition.pdf:pdf},
isbn = {0136042597},
issn = {0269-8889},
journal = {Prentice Hall},
mendeley-groups = {Robotics},
pages = {1 -- 1132},
pmid = {18764587},
primaryClass = {arXiv:gr-qc},
title = {{Artificial Intelligence: A Modern Approach, 3rd edition}},
year = {2009}
}
@book{Fuente2014,
abstract = {In Arabic, as in many languages, the future is “ahead” and the past is “behind.” Yet in the research reported here, we showed that Arabic speakers tend to conceptualize the future as behind and the past as ahead of them, despite using spoken metaphors that suggest the opposite. We propose a new account of how space-time mappings become activated in individuals' minds and entrenched in their cultures, the temporal-focus hypothesis: People should conceptualize either the future or the past as in front of them to the extent that their culture (or subculture) is future oriented or past oriented. Results support the temporal-focus hypothesis, demonstrating that the space-time mappings in people's minds are conditioned by their cultural attitudes toward time, that they depend on attentional focus, and that they can vary independently of the space-time mappings enshrined in language. Keywords},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fuente, Juanma De La and Santiago, Julio and Rom{\'{a}}n, Antonio and Dumitrache, Cristina and Casasanto, Daniel},
booktitle = {Psychological Science},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fuente et al. - 2014 - Handbook on Robotics.pdf:pdf},
isbn = {9780874216561},
issn = {1467-9280},
keywords = {conceptual metaphor,cross-cultural differences,mental models,open data,space,time},
mendeley-groups = {Robotics},
number = {9},
pages = {1682--1690},
pmid = {25052830},
title = {{Handbook on Robotics}},
volume = {25},
year = {2014}
}
@misc{Korthals2013a,
author = {Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals - 2013 - MCMC - Metropolis-Hasting Gibbs-Sampling.pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Korthals - 2013 - MCMC - Metropolis-Hasting Gibbs-Sampling(2).pdf:pdf},
mendeley-groups = {Master},
title = {{MCMC - Metropolis-Hasting Gibbs-Sampling}},
year = {2013}
}
@article{IEEE,
author = {IEEE},
file = {:home/tkorthals/Downloads/RAM{\_}20171201{\_}DEC{\_}2017.PDF:PDF},
journal = {IEEE Robotics {\&} Automation Magazine},
mendeley-groups = {IEEE},
title = {{Robotics {\&} Automation 12.17}}
}
@article{IEEE2017a,
author = {IEEE},
file = {:home/tkorthals/Documents/Mendeley Desktop/IEEE - 2017 - Robotics {\&} Automation 06.17.pdf:pdf},
journal = {IEEE Robotics {\&} Automation Magazine},
mendeley-groups = {IEEE},
title = {{Robotics {\&} Automation 06.17}},
year = {2017}
}
@article{IEEEa,
author = {IEEE},
file = {:home/tkorthals/Documents/Mendeley Desktop/IEEE - Unknown - Robotics {\&} Automation 09.17.pdf:pdf},
journal = {IEEE Robotics {\&} Automation Magazine},
mendeley-groups = {IEEE},
title = {{Robotics {\&} Automation 09.17}}
}
@article{Jayaraman2016,
abstract = {Improving farm productivity is essential for increasing farm profitability and meeting the rapidly growing demand for food that is fuelled by rapid population growth across the world. Farm productivity can be increased by understanding and forecasting crop performance in a variety of environmental conditions. Crop recommendation is currently based on data collected in field-based agricultural studies that capture crop performance under a variety of conditions (e.g., soil quality and environmental conditions). However, crop performance data collection is currently slow, as such crop studies are often undertaken in remote and distributed locations, and such data are typically collected manually. Furthermore, the quality of manually collected crop performance data is very low, because it does not take into account earlier conditions that have not been observed by the human operators but is essential to filter out collected data that will lead to invalid conclusions (e.g., solar radiation readings in the afternoon after even a short rain or overcast in the morning are invalid, and should not be used in assessing crop performance). Emerging Internet of Things (IoT) technologies, such as IoT devices (e.g., wireless sensor networks, network-connected weather stations, cameras, and smart phones) can be used to collate vast amount of environmental and crop performance data, ranging from time series data from sensors, to spatial data from cameras, to human observations collected and recorded via mobile smart phone applications. Such data can then be analysed to filter out invalid data and compute personalised crop recommendations for any specific farm. In this paper, we present the design of SmartFarmNet, an IoT-based platform that can automate the collection of environmental, soil, fertilisation, and irrigation data; automatically correlate such data and filter-out invalid data from the perspective of assessing crop performance; and compute crop forecasts and personalised crop recommendations for any particular farm. SmartFarmNet can integrate virtually any IoT device, including commercially available sensors, cameras, weather stations, etc., and store their data in the cloud for performance analysis and recommendations. An evaluation of the SmartFarmNet platform and our experiences and lessons learnt in developing this system concludes the paper. SmartFarmNet is the first and currently largest system in the world (in terms of the number of sensors attached, crops assessed, and users it supports) that provides crop performance analysis and recommendations.},
author = {Jayaraman, Prem Prakash and Yavari, Ali and Georgakopoulos, Dimitrios and Morshed, Ahsan and Zaslavsky, Arkady},
doi = {10.3390/s16111884},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jayaraman et al. - 2016 - Internet of things platform for smart farming Experiences and lessons learnt.pdf:pdf},
isbn = {6139214858},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Internet of things,Semantic web,Smart agriculture},
mendeley-groups = {CLAAS SeMAV/2030,CLAAS SeMAV/Sensorik},
number = {11},
pages = {1--17},
pmid = {27834862},
title = {{Internet of things platform for smart farming: Experiences and lessons learnt}},
volume = {16},
year = {2016}
}
@article{Kamilaris2017,
abstract = {To tackle the increasing challenges of agricultural production, the complex agricultural ecosystems need to be better understood. This can happen by means of modern digital technologies that monitor continuously the physical environment, producing large quantities of data in an unprecedented pace. The analysis of this (big) data would enable farmers and companies to extract value from it, improving their productivity. Although big data analysis is leading to advances in various industries, it has not yet been widely applied in agriculture. The objective of this paper is to perform a review on current studies and research works in agriculture which employ the recent practice of big data analysis, in order to solve various relevant problems. Thirty-four different studies are presented, examining the problem they address, the proposed solution, tools, algorithms and data used, nature and dimensions of big data employed, scale of use as well as overall impact. Concluding, our review highlights the large opportunities of big data analysis in agriculture towards smarter farming, showing that the availability of hardware and software, techniques and methods for big data analysis, as well as the increasing openness of big data sources, shall encourage more academic research, public sector initiatives and business ventures in the agricultural sector. This practice is still at an early development stage and many barriers need to be overcome.},
author = {Kamilaris, Andreas and Kartakoullis, Andreas and Prenafeta-Bold{\'{u}}, Francesc X.},
doi = {10.1016/j.compag.2017.09.037},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kamilaris, Kartakoullis, Prenafeta-Bold{\'{u}} - 2017 - A review on the practice of big data analysis in agriculture.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Agriculture,Big data analysis,Smart Farming,Survey},
mendeley-groups = {CLAAS SeMAV/2030},
number = {October},
pages = {23--37},
title = {{A review on the practice of big data analysis in agriculture}},
volume = {143},
year = {2017}
}
@techreport{Of2017,
address = {Geneva, CH},
author = {Of, Recipients and Draft, This and Invited, A R E and Comments, With Their and Any, O F and Patent, Relevant and Of, Rights and Aware, They A R E and Addition, I N and Their, T O and As, Evaluation and Acceptable, Being and Industrial, F O R and Purposes, User and International, Draft and May, Standards and Have, Occasion and Be, T O and In, Considered and To, Dards and Reference, Which and Be, M A Y and In, Made},
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2017 - Agricultural machinery and tractors — Safety of highly automated agricultural machines.pdf:pdf},
institution = {International Organization for Standardization},
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Agricultural machinery and tractors — Safety of highly automated agricultural machines}},
year = {2017}
}
@techreport{ISOPDF,
address = {Geneva, Switzerland},
author = {ISO},
institution = {International Organization for Standardization},
number = {32000$\backslash$char"2012 1:2008},
title = {{Document management---{\{}P{\}}ortable document format---{\{}P{\}}art{\~{}}1: {\{}PDF{\}}{\~{}}1.7}},
type = {ISO},
year = {2008}
}
@techreport{ISO11783-10,
address = {Geneva, CH},
file = {:home/tkorthals/Documents/Mendeley Desktop/ISO - 2009 - ISO 11783-10 - Task controller and management information system data interchange.pdf:pdf},
institution = {International Organization for Standardization},
mendeley-groups = {CLAAS SeMAV/Normen},
title = {{Tractors and machinery for agriculture and forestry - Serial control and communications data network - Task controller and management information system data interchange}},
type = {Standard},
volume = {2009},
year = {2009}
}
@techreport{ISO18497,
address = {Geneva, CH},
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2017 - Agricultural machinery and tractors — Safety of highly automated agricultural machines.pdf:pdf},
institution = {International Organization for Standardization},
keywords = {Agricultural,Agricultural Engineering,Autonomous,ISO},
mendeley-groups = {CLAAS SeMAV/Normen},
mendeley-tags = {Agricultural,Agricultural Engineering,Autonomous,ISO},
title = {{Agricultural machinery and tractors — Safety of highly automated agricultural machines}},
type = {Standard},
volume = {2017},
year = {2017}
}
@article{Schikora2010,
author = {Schikora, M. and Bender, D. and Koch, W. and Cremers, D.},
doi = {10.1117/12.868225},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schikora et al. - 2010 - Multi-target multi-sensor localization and tracking using passive antennas and optical sensors on UAVs.pdf:pdf},
isbn = {9780819483515},
issn = {0277786X},
journal = {Proc. SPIE Security + Defence,},
keywords = {a and daniel cremers,a and wolgang koch,b,b and daniel bender,marek schikora a,optical sensors on uavs,ti-target multi-sensor localization and,tracking,using passive antennas and},
mendeley-groups = {Robotics/Localization},
pages = {1--9},
title = {{Multi-target multi-sensor localization and tracking using passive antennas and optical sensors on UAVs}},
url = {http://wwwcremers.in.tum.de/pub/pub/2010{\_}SBKC{\_}spie.pdf},
volume = {7833},
year = {2010}
}
@article{Traktoren,
author = {Traktoren, Smarte and Computerprogramm, Ein and Bauer, Der and Farming, Smart},
file = {:home/tkorthals/Documents/Mendeley Desktop/Traktoren et al. - Unknown - Apps f{\"{u}}r den Acker.pdf:pdf},
title = {{Apps f{\"{u}}r den Acker}}
}
@article{Klawitter2017,
author = {Klawitter, Nils},
file = {:home/tkorthals/Documents/Mendeley Desktop/Klawitter - 2017 - Landwirtschaft 4.0 - Apps f{\"{u}}r den Acker.pdf:pdf},
journal = {SPIEGEL},
mendeley-groups = {CLAAS SeMAV/2030},
pages = {68--70},
title = {{Landwirtschaft 4.0 - Apps f{\"{u}}r den Acker}},
year = {2017}
}
@article{Kim2017,
author = {Kim, Yejin and Baek, Seongmin and Bae, Byung-Chull},
doi = {10.4218/etrij.17.2816.0045},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kim, Baek, Bae - 2017 - Motion Capture of the Human Body Using Multiple Depth Sensors.pdf:pdf},
issn = {1225-6463},
journal = {ETRI Journal},
keywords = {depth sensor,dynamic,human motion,motion capture,movements,multiple kinect sensors},
mendeley-groups = {Vision/Tracking/Bodytracking},
number = {2},
pages = {181--190},
title = {{Motion Capture of the Human Body Using Multiple Depth Sensors}},
url = {http://doi.wiley.com/10.4218/etrij.17.2816.0045},
volume = {39},
year = {2017}
}
@phdthesis{Keil2012,
author = {Keil, Michaela},
file = {:home/tkorthals/Documents/Mendeley Desktop/Keil - 2012 - Body Tracking - Echtzeitbewegung von 3D-Charakteren durch Bewegungssteuerung am Beispiel von Kinect.pdf:pdf},
mendeley-groups = {Vision/Tracking/Bodytracking},
title = {{Body Tracking - Echtzeitbewegung von 3D-Charakteren durch Bewegungssteuerung am Beispiel von Kinect}},
url = {https://monami.hs-mittweida.de/files/2730/Diplomarbeit{\_}BodyTracking.pdf},
year = {2012}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/2030,CLAAS SeMAV/Sensorik},
title = {{Bosch Deepfield Connect{\textregistered}}},
url = {https://www.deepfield-connect.com/de/Deepfield-Connect.html},
urldate = {2017-12-07}
}
@article{Demmel2012,
author = {Demmel, Markus and Brandhuber, Robert and Kirchmeier, Hans and M{\"{u}}ller, Martin and Marx, Marc},
file = {:home/tkorthals/Documents/Mendeley Desktop/Demmel et al. - 2012 - Agro-Klima - Controlled traffic farming – technical and organizational realization.pdf:pdf},
keywords = {capability to infil-,compaction,controlled traffic,farming,fields show a high,guidance,soil,store and deliver precipitation,trate,un-wheeled areas in the,water},
mendeley-groups = {CLAAS SeMAV/Projekte},
pages = {435--440},
title = {{Agro-Klima - Controlled traffic farming – technical and organizational realization}},
year = {2012}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Bodenerosion – jeder Halm ein Damm - YouTube}},
url = {https://www.youtube.com/watch?time{\_}continue=173{\&}v=rASx28YnuPo https://www.lfl.bayern.de/ilt/pflanzenbau/marktfruchtanbau/111649/index.php},
urldate = {2017-12-07}
}
@techreport{Demmel2014,
author = {Demmel, Markus and Kirchmeier, Hans and M{\"{u}}ller, Martin},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Demmel, Kirchmeier, M{\"{u}}ller - 2014 - Agro-Klima - Innovationen im Ackerbau Permanente Fahrwege (Controlled Traffic Farming) {\&} Streifenbo.pdf:pdf},
mendeley-groups = {CLAAS SeMAV/Projekte},
title = {{Agro-Klima - Innovationen im Ackerbau: Permanente Fahrwege (Controlled Traffic Farming) {\&} Streifenbodenbearbeitung (Strip Tillage)}},
year = {2014}
}
@article{Rodriguez2017,
abstract = {African farmers are poorly resourced, highly diverse and aground by poverty traps making them rather impervious to change. As a consequence R4D efforts usually result in benefits but also trade-offs that constraint adoption and change. A typical case is the use of crop residues as mulches or as feedstock. Here we linked a database of household surveys with a dynamic whole farm simulation model, to quantify the diversity of trade-offs from the alternative use of crop residues. Simulating all the households in the survey (n=613) over 99 years of synthetic climate data, showed that benefits and trade-offs from “mulching or munching” differ across agro-ecologies, and within agro-ecologies across typologies of households. Even though trade-offs between household production or income and environmental outcomes could be managed; the magnitude of the simulated benefits from the sustainable intensification of maize-livestock systems were small. Our modelling framework shows the benefits from the integration of socio-economic and biophysical approaches to support the design of development programs. Our results support the argument that a greater focus is required on the development and diversification of farmers' livelihoods within the framework of an improved understanding of the interconnectedness between biophysical, socio-economic and market factors.},
author = {Rodriguez, D and de Voil, P and Rufino, MC and Odendo, M and van Wijk, MT},
doi = {10.1016/j.agsy.2017.01.010},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rodriguez et al. - 2017 - To mulch or to munch Big modelling of big data.pdf:pdf},
issn = {0308521X},
journal = {Agricultural Systems},
mendeley-groups = {CLAAS SeMAV/2030},
pages = {32--42},
title = {{To mulch or to munch? Big modelling of big data}},
volume = {153},
year = {2017}
}
@article{Sabarina2015,
abstract = {Predictive analytics can be used to make smarter decisions in farming by collecting real-time data on weather, soil and air quality, crop maturity and even equipment and labor costs and availability. This is known as precision agriculture. Big data is expected to play an important role in precision agriculture for managing real-time data analysis with massive streaming data. The data analysis efficiency and throughput would be a challenge with the massive increase in size of big data. The unstructured streaming data received from different agricultural sources would contain multiple dimensions and not the entire content is needed for performing analysis. The core data which is small but that alone enough to represent the entire content should be extracted. This paper explains how to systematically reduce the size of big data by applying a tensor based feature reduction model. The data decomposition and core value extraction is done with the help of IHOSVD algorithm. This way it reduces the overall file size by eliminating unwanted data dimensions. The time involved in data analysis and CPU usage will be significantly reduced when dimensionality reduced data is used in place of raw (unprocessed) data.},
author = {Sabarina, K. and Priya, N.},
doi = {10.1016/j.procs.2015.04.134},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sabarina, Priya - 2015 - Lowering Data Dimensionality in Big Data for the Benefit of Precision Agriculture.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
mendeley-groups = {CLAAS SeMAV/2030},
pages = {548--554},
title = {{Lowering Data Dimensionality in Big Data for the Benefit of Precision Agriculture}},
volume = {48},
year = {2015}
}
@article{OGrady2017,
abstract = {Smart farming envisages the harnessing of Information and Communication Technologies as an enabler of more efficient, productive, and profitable farming enterprises. Such technologies do not suffice on their own; rather they must be judiciously combined to deliver meaningful information in near real-time. Decision-support tools incorporating models of disparate farming activities, either on their own or in combination with other models, offer one popular approach; exemplars include GPFARM, APSIM, GRAZPLAN amongst many others. Such models tend to be generic in nature and their adoption by individual farmers is minimal. Smart technologies offer an opportunity to remedy this situation; farm-specific models that can reflect near real-time events become tractable using such technologies. Research on the development, and application of farm-specific models is at a very early stage. This paper thus presents an overview of models within the farming enterprise; it then reviews the state-of the art in smart technologies that promise to enable a new generation of enterprise-specific models that will underpin future smart farming enterprises.},
author = {O'Grady, Michael J. and O'Hare, Gregory M.P.},
doi = {10.1016/j.inpa.2017.05.001},
file = {:home/tkorthals/Documents/Mendeley Desktop/O'Grady, O'Hare - 2017 - Modelling the smart farm.pdf:pdf},
issn = {22143173},
journal = {Information Processing in Agriculture},
mendeley-groups = {CLAAS SeMAV/2030},
number = {3},
pages = {179--187},
title = {{Modelling the smart farm}},
volume = {4},
year = {2017}
}
@article{Wolfert2017,
abstract = {Smart Farming is a development that emphasizes the use of information and communication technology in the cyber-physical farm management cycle. New technologies such as the Internet of Things and Cloud Computing are expected to leverage this development and introduce more robots and artificial intelligence in farming. This is encompassed by the phenomenon of Big Data, massive volumes of data with a wide variety that can be captured, analysed and used for decision-making. This review aims to gain insight into the state-of-the-art of Big Data applications in Smart Farming and identify the related socio-economic challenges to be addressed. Following a structured approach, a conceptual framework for analysis was developed that can also be used for future studies on this topic. The review shows that the scope of Big Data applications in Smart Farming goes beyond primary production; it is influencing the entire food supply chain. Big data are being used to provide predictive insights in farming operations, drive real-time operational decisions, and redesign business processes for game-changing business models. Several authors therefore suggest that Big Data will cause major shifts in roles and power relations among different players in current food supply chain networks. The landscape of stakeholders exhibits an interesting game between powerful tech companies, venture capitalists and often small start-ups and new entrants. At the same time there are several public institutions that publish open data, under the condition that the privacy of persons must be guaranteed. The future of Smart Farming may unravel in a continuum of two extreme scenarios: 1) closed, proprietary systems in which the farmer is part of a highly integrated food supply chain or 2) open, collaborative systems in which the farmer and every other stakeholder in the chain network is flexible in choosing business partners as well for the technology as for the food production side. The further development of data and application infrastructures (platforms and standards) and their institutional embedment will play a crucial role in the battle between these scenarios. From a socio-economic perspective, the authors propose to give research priority to organizational issues concerning governance issues and suitable business models for data sharing in different supply chain scenarios.},
author = {Wolfert, Sjaak and Ge, Lan and Verdouw, Cor and Bogaardt, Marc-Jeroen},
doi = {10.1016/J.AGSY.2017.01.023},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wolfert et al. - 2017 - Big Data in Smart Farming – A review.pdf:pdf},
issn = {0308-521X},
journal = {Agricultural Systems},
mendeley-groups = {CLAAS SeMAV/2030},
month = {may},
pages = {69--80},
publisher = {Elsevier},
title = {{Big Data in Smart Farming – A review}},
url = {http://www.sciencedirect.com/science/article/pii/S0308521X16303754},
volume = {153},
year = {2017}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/2030},
title = {{xarvio Digital Farming Solutions}},
url = {https://www.xarvio.com/en},
urldate = {2017-12-07}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Vorgewende}},
url = {https://www.agrarbetrieb-eiswiesen.de/unsere-regeln/},
urldate = {2017-12-07}
}
@techreport{Moser2017,
author = {Moser, Benedikt and Pier, Marcus and Husmann, Marco},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moser, Pier, Husmann - 2017 - Die digitale Kartoffel – Wie Sensordaten den Ernteprozess von Kartoffeln optimieren Unser.pdf:pdf},
institution = {VDI e.V.},
mendeley-groups = {CLAAS SeMAV/2030},
pages = {1--2},
title = {{Die digitale Kartoffel – Wie Sensordaten den Ernteprozess von Kartoffeln optimieren Unser}},
url = {https://m.vdi.de/fileadmin/vdi{\_}de/redakteur{\_}dateien/gpp{\_}dateien/2017-04{\_}GPP{\_}VDI{\_}Fachnews{\_}Maschinen-{\_}und{\_}Betriebdaten{\_}im{\_}Service{\_}nutzen{\_}-{\_}Die{\_}digitale{\_}Kartoffel.pdf},
year = {2017}
}
@article{SAE2014,
author = {SAE},
doi = {10.4271/2012-01-0107.},
file = {:home/tkorthals/Documents/Mendeley Desktop/SAE - 2014 - Surface Vehicle Recommended Practice.pdf:pdf},
isbn = {1999010892},
mendeley-groups = {CLAAS SeMAV/Definitionen},
pages = {1--30},
title = {{Surface Vehicle Recommended Practice}},
year = {2014}
}
@misc{,
keywords = {3016,SAE},
mendeley-groups = {CLAAS SeMAV/Definitionen},
mendeley-tags = {3016,SAE},
title = {{Definition Autonomes Fahren}},
url = {https://de.wikipedia.org/wiki/SAE{\_}J3016}
}
@techreport{CLAAS2017,
author = {CLAAS},
file = {:home/tkorthals/Documents/Mendeley Desktop/CLAAS - 2017 - Level of Automation.pdf:pdf},
institution = {CLAAS},
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Level of Automation}},
year = {2017}
}
@article{SAEinternational2016,
abstract = {With the goal of providing common terminology for automated driving, SAE International's new standard J3016: Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems, delivers a harmonized classification system and supporting definitions that: • Identify six levels of driving automation from “no automation” to “full automation”. • Base definitions and levels on functional aspects of technology. • Describe categorical distinctions for a step-wise progression through the levels. • Are consistent with current industry practice. • Eliminate confusion and are useful across numerous disciplines (engineering, legal, media, and public discourse). • Educate a wider community by clarifying for each level what role (if any) drivers have in performing the dynamic driving task while a driving automation system is engaged.},
author = {SAE international},
doi = {P141661},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/SAE international - 2016 - AUTOMATED DRIVING - LEVELS OF DRIVING AUTOMATION ARE DEFINED IN NEW SAE INTERNATIONAL STANDARD J3016.pdf:pdf},
journal = {SAE international},
keywords = {Vehicle networking},
mendeley-groups = {CLAAS SeMAV/Definitionen},
pages = {1},
title = {{AUTOMATED DRIVING - LEVELS OF DRIVING AUTOMATION ARE DEFINED IN NEW SAE INTERNATIONAL STANDARD J3016}},
url = {https://www.sae.org/news/3544/},
year = {2016}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/Projekte},
title = {{Bonares - soilassist}},
url = {https://www.bonares.de/soilassist},
urldate = {2017-12-07}
}
@misc{,
keywords = {Zwischenfrucht},
mendeley-groups = {CLAAS SeMAV/Projekte},
mendeley-tags = {Zwischenfrucht},
title = {{Bonares - Catchy}},
url = {https://www.bonares.de/catchy},
urldate = {2017-12-07}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/Projekte,CLAAS SeMAV},
title = {{Bonares - Intelligence for Soil}},
url = {https://www.bonares.de/i4s},
urldate = {2017-12-07}
}
@misc{,
abstract = {“BonaRes” is short for “Soil as a sustainable resource for the bioeconomy”. In this funding initiative of the German Federal Ministry for Education and Research (BMBF) the focus is on the sustainable use of soils as a limited resource. The ultimate goal of BonaRes is to extend the scientific understanding of soil ecosystems and to improve the productivity of soils and other soil functions while developing new strategies for a sustainable use and management of soils. The BonaRes Portal provides information about the BonaRes projects, access to data, knowledge and models, as well as to decision support options for a sustainable soil management.},
mendeley-groups = {CLAAS SeMAV/Projekte,CLAAS SeMAV},
title = {{Bonares}},
url = {https://www.bonares.de/},
urldate = {2017-12-07}
}
@article{Mederle2017,
author = {Mederle, Michael and Bernhardt, Heinz},
doi = {10.3303/CET1758052},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mederle, Bernhardt - 2017 - Influences and Decision Criteria on Infield-logistics in German Agricultural Farms.pdf:pdf},
journal = {CHEMICAL ENGINEERING TRANSACTIONS},
mendeley-groups = {CLAAS SeMAV/Infield-Logistik},
pages = {pp 307--312},
title = {{Influences and Decision Criteria on Infield-logistics in German Agricultural Farms}},
url = {https://mediatum.ub.tum.de/1403160},
volume = {58},
year = {2017}
}
@misc{Pflanzenforschung.de,
author = {Pflanzenforschung.de},
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Mischkultur}},
url = {http://www.pflanzenforschung.de/index.php?cID=8156},
urldate = {2017-12-07}
}
@misc{Pflanzenforschung.dea,
author = {Pflanzenforschung.de},
mendeley-groups = {CLAAS SeMAV/Definitionen},
title = {{Monokultur}},
url = {http://www.pflanzenforschung.de/de/themen/lexikon/monokultur-786},
urldate = {2017-12-07}
}
@misc{peters2017verfahren,
annote = {WO Patent App. PCT/EP2016/073,400},
author = {Peters, O},
file = {:home/tkorthals/Documents/Mendeley Desktop/Peters - 2017 - Verfahren zum betreiben einer erntemaschine mit hilfe eines pflanzenwachstumsmodells.pdf:pdf},
mendeley-groups = {CLAAS SeMAV/Patente},
publisher = {Google Patents},
title = {{Verfahren zum betreiben einer erntemaschine mit hilfe eines pflanzenwachstumsmodells}},
url = {https://encrypted.google.com/patents/WO2017060168A1?cl=pt-PT},
year = {2017}
}
@book{Becker2011,
address = {Witzenhausen},
author = {Becker, Konstantin and Brandhuber, Robert and Bohne, Bj{\"{o}}rn and Bolten, Willi and Braun, Anette and Demmel, Markus and van Elsen, Thomas and Fischer, Daniel and Gimplinger, Daniela and Gobor, Zoltan and Haase, Thorsten and H{\"{a}}nsel, Martin and Hensel, Oliver and He{\ss}, J{\"{u}}rgen and Kielhorn, Arnd and K{\"{o}}ller, Karlheinz and Kolbe, Hartmut and Koller, Martin and K{\"{o}}pke, Ulrich and Laber, Hermann and Landzettel, Christian and Latsch, Roy and Lukashyk, Pavel and Lundkvist, Anneli and M{\"{u}}cke, Markus and Niedermaier, Josef and Puffert, Markus and Rumpler, Johann and Sauermann, Guntram and Sauter, Johann and Schiller, Matthias and SchulzeLammers, Peter and Stumm, Christoph and Total, Ren{\'{e}} and Verschwele, Arnd and Wild, Melanie and Wilhelm, Birgit and Zillger, Christine},
booktitle = {Landtechnische L{\"{o}}sungen zur Beikrautregulierung im {\"{O}}kolandbau},
editor = {Wilhelm, Birgit and Hensel, Oliver},
file = {:home/tkorthals/Documents/Mendeley Desktop/Becker et al. - 2011 - Landtechnische L{\"{o}}sungen zur Beikrautregulierung im {\"{O}}kolandbau.pdf:pdf},
isbn = {9783980168687},
issn = {03408159},
mendeley-groups = {CLAAS SeMAV},
pages = {243--249},
publisher = {Deutsches Institut f{\"{u}}r Tropische und Subtropische Landwirtschaft (DITSL) GmbH},
title = {{Landtechnische L{\"{o}}sungen zur Beikrautregulierung im {\"{O}}kolandbau}},
url = {http://orgprints.org/19829/1/2657{\_}Handbuch Unkraut LR.pdf},
year = {2011}
}
@misc{,
mendeley-groups = {CLAAS SeMAV/Agrochemie},
title = {{Agrochemie}},
url = {https://de.wikipedia.org/wiki/Agrochemie},
urldate = {2017-12-07},
year = {2017}
}
@article{Cooper2007,
author = {Cooper, Jerry and Dobson, Hans},
doi = {10.1016/j.cropro.2007.03.022},
issn = {02612194},
journal = {Crop Protection},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/Agrochemie},
month = {sep},
number = {9},
pages = {1337--1348},
title = {{The benefits of pesticides to mankind and the environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S026121940700097X},
volume = {26},
year = {2007}
}
@book{Luck,
abstract = {Durch Zusammenstellung meiner Erfahrungen mochte ich ver suchen, an dem Prozef.$\backslash$ einer erhohten Verantwortung differentiell mitzuwirken. Das Buch erscheint zum 10jiihrigen Jubiliium der Griin dung der Gesellschaft flir Verantwortung in der Wissenschaft (GVW) und nimmt die Erfahrungen dieser 10 Jahre mit auf. Der Mensch scheint zu Extremen zu neigen. Neben den im Prolog angedeuteten Gefahren wird unsere Gesellschaft yom Wege sinnge miif.$\backslash$en Handelns heute auch von der entgegengesetzten Gefahr be droht: Aus Unkenntnis und Furcht vor der Undurchschaubarkeit der Naturwissenschaft und Technik beide zu verbannen und das Heil wieder im emotionalen Denken zu suchen. Es erscheint mir daher notwendig, die Probleme auf breiterer Basis zu durchleuchten. 1m ersten Kapitel wird versucht, das Selbstverstiindnis der Wissen schaft zu diskutieren. Details mogen einige Leser etwas langweilen. Es wird daher am Ende jedes Kapitels eine Zusammenfassung ge geben, die erlauben sollte, jedes weitere Kapitel auch nach tiberschla gen eines Kapitels volliesen zu konnen. 1m zweiten Kapitel werden Motivierungen fUr das Studium und fUr die wissenschaftliche Arbeit zusammengestellt. Eine Meinungsum frage u{\~{}}ter 8000 amerikanischen Studenten hat ergeben, daf.$\backslash$ ca. 80{\%} studieren, urn einen Sinn ihres Lebens zu finden. Diese Umfrage zeigt die Dringlichkeit der im zweiten Kapitel versuchten Diskussion. 1. Was ist Wissenschaft? -- 1.1. Einleitung -- 1.2. Was ist Wissenschaft? -- 1.3. Was ist Naturwissenschaft? -- 1.4. Das Experiment -- 1.5. Einfachheit in der Physik -- 1.6. Objektivierbarkeit der exakten Naturwissenschaft -- 1.7. Einheit von Theorie und Praxis in den Naturwissenschaften -- 1.8. Der Fächerpluralismus -- 1.9. Zusammenfassung -- 2. Zu welchem Zweck studieren wir? -- 2.1. Brotgelehrte und Philosophen nach Schiller -- 2.2. Der 'soziale Gelehrte' -- 2.3. Die Evolution des Altruismus -- 2.4. Der Positivismus -- 2.5. Grundaxiome der Kooperation -- 2.6. Ziele der Wissenschaftler -- 2.7. Religion und Naturwissenschaft -- 2.8. Der eindimensionale Marcuse -- 2.9. Zusammenfassung -- 3. Das ABC der Zukunft -- 3.1. Einleitung -- 3.2. A. Astronomie, die Grö{\ss}e des Alls und die Kleinheit des Individuums -- 3.3. A. Atommü ll, weltweite Verbreitung des Abfalls physika-lischer Aktivitäten -- 3.3. A.1. Atombombenversuche -- 3.3. A.2. Atomkraftwerke -- 3.4. A. Atomwaffen, das Ende des Prinzips Krieg? -- 3.5. B. Bakterien, die letzten Feinde des Menschen? -- 3.6. B. Bevölkerungszuwachs, die Hauptursache vieler Schwierigkeiten -- 3.7. C. C02-Konlendioxid, verändert der Mensch das Weltklima? -- 3.8. D. DDT, weltweite Verbreitung des Abfalls chemischer Aktivitäten -- 3.9. E. Energiefragen, eine natörliche Grenze des Wachstums? . -- 3.10. F. Fernsehen, Beispiele för einschneidende Wirkungen der Informationstechnik -- 3.11. G. Genetik, die Information der Evolution -- 3.12. H. Homo sapiens, die kulturelle Revolution -- 3.13. I. Industrie, die Grundlage des Wachstums -- 3.14. J. Ja zum Leben -- Wir brauchen Kulturoptimismus -- 3.15. K. Katastrophen, werden sie die Menschen zur Kooperation bringen? -- 3.16. L. Lärm -- Der Mensch nirgends mehr allein? -- 3.17. M. Medizin, Gesundheit und Gesellschaft -- 3.18. N. Nationalismus und Internationalismus -- 3.19. Ü. Ükologie -- Lebewesen aller Arten vereinigt euch! -- 3.20. P. Partnerwahl, wird der Mensch das letzte Stück Natur in sich retten? -- 3.21. Q. Quarantäne oder Verantwortliche Freigabe? -- 3.22. R. Rohstoffreserven, gemeinsamer Besitz aller Menschen -- 3.23. S. Soziale Prägungen, werden wir rechtzeitig daraus lernen? -- 3.24. T. Theologie -- Theologen aller Religionen vereinigt euch!. -- 3.25. U. Umwelthygiene, gemeinsame Verantwortlichkeit -- 3.25. U.1. Müllprobleme -- 3.25. U.2. Abwasserfragen -- 3.25. U.3. Allgemeines -- 3.26. V. Verkehrsprobleme, ein Beispiel für Kooperation -- 3.27. W. Wirtschaftsprobleme, Beginn einer echten Internationale -- 3.28. X. Die gro{\ss}e Unbekannte -- 3.29. Y. Yoga, eine Folge der Internationalisierung. -- 3.30. Z. Zigarettenrauchen, ist der Name homo sapiens falsch? -- 3.31. Zusammenfassung -- 4. Die Verantwortung der Naturwissenschaftler und Techniker -- 4.1. Was ist und warum Verantwortung der Wissenschaftler?. -- 4.2. Ursachen ungenügender Verantwortlichkeit -- 4.3. Historische Beispiele für verantwortliches Handeln -- 4.4. Verantwortliches Handeln -- 4.5. Sozialphilosophische Versuche -- 4.6. Grenzen der Sozialphilosophie -- 4.7. Eine Meinungsumfrage zur Verantwortung -- 4.8. Forschungen mit sozialer Zielrichtung -- 4.9. Verhalten der Wissenschaftler -- 4.10. Neue Gemeinschaftskunde oder Chaos? -- 4.11. Zur Situation und Entwicklung der Welt -- 4.12. Was kann der Einzelne tun? -- 4.13. Ein Symposion des Weizmann-lnstitutes -- 4.14. Verantwortung für die Wissenschaft -- 4.15. Zusammenfassung -- Epilog -- Nachwort -- Literatur.},
author = {Luck, Werner A. P.},
isbn = {9783642852985},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/Agrochemie},
title = {{Homo investigans : Der soziale Wissenschaftler}}
}
@misc{,
abstract = {Targeted seeding featuring swarm technology

They are mobile. They are cloud-controlled. And they are many. They are the field robots of the future from Fendt. As a team, they collaborate in a completely autonomous and efficient way and with high precision. The basic idea is simplification.

How? Fewer sensors, robust control units and a clear hardware structure make each individual Xaver robot extremely reliable and productive. At the same time, the use of a large number of small, identical robots operating in a swarm enables smooth running of the job, even in the event of the failure of a single unit.

Their light weight results in a high level of safety and negligible soil compaction. And Xaver robots are ready for operation, all around the clock. These aspects combine to make field robotic systems a very attractive alternative for the farmer of the future. This is our vision.},
keywords = {Agriculture,Field Robotic,Framing,Multi-Robotic,Precision Farming},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/2030},
mendeley-tags = {Agriculture,Field Robotic,Framing,Multi-Robotic,Precision Farming},
title = {{Project Xaver - AGCO GmbH}},
url = {https://www.fendt.com//int/xaver.html},
urldate = {2017-12-07},
year = {2017}
}
@misc{Schmidt2015,
author = {Schmidt, Max},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/Definitionen},
title = {{Bodenverdichtungen auflockern}},
url = {https://www.landwirt.com/Bodenverdichtungen-auflockern,,16375,,Bericht.html},
urldate = {2017-12-07},
year = {2015}
}
@misc{Inquibidt-Wiki2013,
author = {Inquibidt-Wiki},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/Definitionen},
title = {{Von der Saat zur Ernte: Die Arbeitsschritte im Jahresverlauf am Beispiel des Wintergetreides}},
url = {http://inquibidt.zum.de/wiki/Von{\_}der{\_}Saat{\_}zur{\_}Ernte:{\_}Die{\_}Arbeitsschritte{\_}im{\_}Jahresverlauf{\_}am{\_}Beispiel{\_}des{\_}Wintergetreides},
urldate = {2017-12-07},
year = {2013}
}
@techreport{DLG-Vorstand2017,
abstract = {Im Jahr 2030 steht die globale Landwirtschaft vor der Herausforderung, Lebensmittel f{\"{u}}r 8,5 Mrd. Menschen bereitzustellen. Die globale Nachfrage wird 2030 nach Berechnungen der Weltern{\"{a}}hrungorganisation (FAO) bei 2,7 Mrd. t Getreide, 131 Mio. t Schweinefleisch, 132 Mio. t Gefl{\"{u}}gelfleisch und 884 Mio. t Milch und Milchprodukten liegen. Verglichen mit dem Jahr 2015 sind dies Bedarfssteigerungen in H{\"{o}}he von rund 8 {\%} bei Getreide, 19 {\%} bei Schweinefleisch, 17 {\%} bei Gefl{\"{u}}gelfleisch und 10 {\%} bei Milch- und Milchprodukten. Im gleichen Zeitraum wird global die pro Kopf verf{\"{u}}gbare landwirtschaftliche Nutzfl{\"{a}}che von rund 2.200 m² im Jahr 2015 auf rund 2.000 m² im Jahr 2030 zur{\"{u}}ckgegangen sein. Gr{\"{u}}nde daf{\"{u}}r sind Bev{\"{o}}lkerungswachstum, Urbanisierung, W{\"{u}}stenbildung, Bodendegradation und Versalzung. Im Jahr 2030 sollen zugleich die im Jahr 2015 beschlossenen Millenniumsziele der Vereinten Nationen erreicht sein. Das Kernst{\"{u}}ck der Agenda 2030 bildet ein Katalog mit 17 Zielen f{\"{u}}r eine nachhaltige Entwicklung. Im Zielkanon sind alle 17 Ziele gleichrangig und eng miteinander verkn{\"{u}}pft. So bilden Produktivit{\"{a}}t und der Schutz wichtiger Umweltg{\"{u}}ter, wie Klima, Boden, Wasser und Artenvielfalt, zusammen mit den anderen Zielen eine Einheit. Ziel 2 beschreibt das f{\"{u}}r die Landwirtschaft herausragende Thema: „Hunger beenden, Ern{\"{a}}hrungssicherheit und eine bessere Ern{\"{a}}hrung erreichen sowie eine nachhaltige Landwirtschaft f{\"{o}}rdern.“ Auch wenn sich m{\"{o}}glicherweise nicht alle Ziele erreichen lassen, setzen sie dennoch einen sinnvollen normativen Rahmen f{\"{u}}r die Herausforderungen an eine Landwirtschaft 2030. Gleichzeitig m{\"{u}}ssen die Produktivit{\"{a}}t gesteigert, die mit der Landwirtschaft verbundenen Umweltsch{\"{a}}den reduziert und die Nutztierhaltung so organisiert werden, dass sie von einem breiten gesellschaftlichen Konsens getragen wird. Jede einzelne dieser drei Aufgaben bedarf f{\"{u}}r sich genommen bereits einer gewaltigen Kraftanstrengung. Alle drei Probleme gleichzeitig zu l{\"{o}}sen, Landwirtschaft also nachhaltiger zu machen, erfordert von allen Beteiligten ein hohes Ma{\ss} an Engagement, Innovationskraft, Know-how, Kreativit{\"{a}}t und Ver{\"{a}}nderungsbereitschaft. Diese Herausforderungen betreffen alle Agrarstandorte weltweit, insbesondere jedoch die fruchtbaren europ{\"{a}}ischen Landwirtschaftsfl{\"{a}}chen. Die Landwirtschaft hat immer wieder bewiesen, dass sie in der Lage ist, sich den gro{\ss}en Herausforderungen der Branche erfolgreich zu stellen. Das wird auch in Zukunft so sein. Was dazu notwendig ist, beschreiben die 10 Thesen der DLG. Die 10 Thesen sind Ergebnis der DLG-Klausurtagung „Landwirtschaft 2030“, die am 11. und 12. Oktober 2016 in Frankfurt am Main stattfand.},
address = {Frankfurt am Main},
author = {DLG-Vorstand},
file = {:home/tkorthals/Documents/Mendeley Desktop/DLG-Vorstand - 2017 - DLG e.V. - Landwirtschaft 2030 - 10 Thesen.pdf:pdf},
institution = {DLG e.V. - Fachzentrum Landwirtschaft},
keywords = {Ackerbau,Landwitschaft},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/2030},
mendeley-tags = {Ackerbau,Landwitschaft},
pages = {1 -- 16},
title = {{DLG e.V. - Landwirtschaft 2030 - 10 Thesen}},
url = {http://www.dlg.org/5433.html},
year = {2017}
}
@techreport{DLG-AusschussfurAckerbau2017,
abstract = {Resistenz gegen{\"{u}}ber Pflanzenschutzmitteln, zulassungsbedingter Verlust wichtiger Wirkstoffe, Stagnation im Z{\"{u}}chtungsfortschritt, Verlust an Biodiversit{\"{a}}t, Probleme aufgrund zu enger Fruchtfolgen, Anforderungen aus dem Wasser- und Bodenschutz {\ldots} die Liste, mit der der deutsche Ackerbauer aktuell zu k{\"{a}}mpfen hat, ist lang. Und die Liste liegt l{\"{a}}ngst nicht mehr nur in der Schublade der Branche, sondern hat bereits die {\"{o}}ffentliche Diskussion erreicht, die mit – mehr oder weniger – berechtigter Kritik bis in die Politik wirkt. Dabei leiden nicht alle landwirtschaftlichen Regionen unter den gleichen Problemen. Viel mehr hat die jeweilige regionale Spezialisierung auf Kulturen, Fruchtfolgen und Anbaumethoden zu unterschiedlich stark ausgepr{\"{a}}gten Effekten gef{\"{u}}hrt. Nicht erst seit der Diskussion um die Wiederzulassung von Glyphosat wird {\"{u}}ber die {\"{A}}nderungen g{\"{a}}ngiger Ackerbaupraktiken debattiert. Zus{\"{a}}tzlich zu dem zulassungsbedingten Wegfall von Pflanzenschutzwirkstoffen versch{\"{a}}rfen sich Resistenzprobleme in allen Bereichen, angefangen bei den Herbiziden bis hin zu den Insektiziden. Ist dies das Ende des derzeit praktizierten Ackerbaus, mit dem viele Jahre eine hohe und st{\"{a}}ndig steigende Produktivit{\"{a}}t verbunden war? Die Hoffnung auf L{\"{o}}sungsans{\"{a}}tze aus der Industrie oder Z{\"{u}}chtung br{\"{o}}ckelt. Entwicklungen von z. B. Pflanzenschutzwirkstoffen sind langwierig und in absehbarer Zeit sind keine neuen Wirkstoffgruppen zu erwarten. Die Schuld alleine darin zu suchen, dass Pflanzenschutzmittel zulassungsbedingt immer spezifischer und somit resistenzgef{\"{a}}hrdeter geworden sind, ist dabei sicher zu kurz gegriffen. Oftmals hat gerade die sehr gute Wirkung der Pflanzenschutzmittel dazu gef{\"{u}}hrt, dass die Einhaltung ackerbaulicher Grundprinzipien, wie eine ausgewogene Fruchtfolge oder eine zus{\"{a}}tzliche Bodenbearbeitung, au{\ss}er Acht gelassen wurden. Lange konnte damit auch die Produktivit{\"{a}}t der Landwirtschaft gesteigert werden. Mittlerweile kehrt sich das in vielen Bereichen um. In Einzelf{\"{a}}llen, wie z. B. in einigen Ackerfuchsschwanzregionen, ist bereits der Ausstieg aus der einstigen Hauptkultur, dem Winterweizen, notwendig geworden, da die Ungrasprobleme nicht mehr in den Griff zu bekommen sind. Um die Pflanzenproduktion zukunftstr{\"{a}}chtig zu gestalten, ist eine Richtungs{\"{a}}nderung im Handeln erforderlich. Die von der DLG ver{\"{o}}ffentlichten Thesen zur Landwirtschaft 2030 greifen dieses Thema ebenfalls insofern auf, als sie u. a. fordern, dass klassische ackerbauliche Prinzipien in verschiedenen Bereichen wieder st{\"{a}}rker in die gute landwirtschaftliche Praxis Eingang finden m{\"{u}}ssen. Auch der Z{\"{u}}chtungsfortschritt nimmt aufgrund des bereits hohen Leistungsniveaus unserer Sorten nur in kleinen Schritten zu. Auf eine „Wunderwaffe“, die alle oben genannten Probleme l{\"{o}}st, kann nicht gewartet werden. Jetzt ist es am unternehmerischen Landwirt, sich kritisch mit seinem Produktionssystem auseinander zu setzen und zukunftsf{\"{a}}hige Strategien f{\"{u}}r den Ackerbau zu entwickeln. Dieses DLG-Merkblatt nimmt die aktuelle Situation im Ackerbau auf, beleuchtet spezifische Probleme und versucht mit der Darstellung von pflanzenbaulichen aber auch {\"{o}}konomischen Zusammenh{\"{a}}ngen auf m{\"{o}}gliche L{\"{o}}sungswege aufmerksam zu machen, damit auch zuk{\"{u}}nftig noch produktiver und gleichzeitig nachhaltiger, ressourcenschonender Ackerbau betrieben werden kann.},
address = {Frankfurt am Main},
author = {{DLG-Ausschuss f{\"{u}}r Ackerbau} and {DLG-Ausschuss f{\"{u}}r Pflanzenschutz} and Stemann, G{\"{u}}nter and Sch{\"{a}}fer, Bernhard C. and von Kr{\"{o}}cher, Carolin and Ahlers, Doris and Erdle, Klaus},
file = {:home/tkorthals/Documents/Mendeley Desktop/DLG-Ausschuss f{\"{u}}r Ackerbau et al. - 2017 - Ackerbau zukunftsf{\"{a}}hig gestalten.pdf:pdf},
institution = {DLG e.V. - Fachzentrum Landwirtschaft},
keywords = {Ackerbau,Landwirtschaft},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/2030},
mendeley-tags = {Ackerbau,Landwirtschaft},
pages = {1 -- 19},
title = {{Ackerbau zukunftsf{\"{a}}hig gestalten}},
url = {http://www.dlg.org/dlg-merkblatt{\_}424.html},
year = {2017}
}
@misc{,
abstract = {Die DLG hat mit der Ver{\"{o}}ffentlichung ihrer zehn Thesen „Landwirtschaft 2030“ Anfang Januar 2017 wichtige Anst{\"{o}}{\ss}e f{\"{u}}r die Weiterentwicklung der Agrarbranche gegeben.

Die Diskussion dar{\"{u}}ber, wie die Produktivit{\"{a}}t gesteigert, die mit der Landwirtschaft verbundenen Umweltbeeintr{\"{a}}chtigungen reduziert und die Nutztierhaltung so organisiert werden k{\"{o}}nnen, dass sie von einem breiten gesellschaftlichen Konsens getragen wird, nimmt einen breiten Raum in der DLG-Facharbeit ein.

Auf dieser Webseite finden Sie eine ausf{\"{u}}hrliche Beschreibung der zehn Thesen sowie weitere Beitr{\"{a}}ge und Ver{\"{o}}ffentlichungen aus der DLG-Facharbeit mit wertvollen Ans{\"{a}}tzen zur Weiterentwicklung der Branche.},
keywords = {Landwirtschaft},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/2030},
mendeley-tags = {Landwirtschaft},
title = {{DLG e.V. - Landwirtschaft 2030}},
url = {http://www.dlg.org/5433.html},
urldate = {2017-12-07}
}
@misc{Baldenhofer2001,
abstract = {Agrarsystem, 1) synonyme Kurzform f{\"{u}}r "landwirtschaftliches Betriebssystem", wobei besonders der Systemcharakter und das Ineinandergreifen verschiedener Kr{\"{a}}fte betont werden. F{\"{u}}r eine konkrete Kennzeichnung von Agrarsystemen sind mindestens die Definitionen der Faktorkombination, des Produktionsprogramms sowie des Diversifizierungsgrades n{\"{o}}tig. 2) Agrosystem, die auf das {\"{u}}bergeordnete Wirtschafts- und Sozialsystem ausgerichteten Auspr{\"{a}}gungen der institutionellen wirtschafts- und sozialorganisatorischen und -ethischen Verh{\"{a}}ltnisse in der Landwirtschaft. In Industriel{\"{a}}ndern umfassen das Agrarsystem und seine Subsysteme neben den Agrarproduzenten auch die T{\"{a}}tigkeitsfelder der vor- und nachgelagerten Wirtschaftsbereiche ( Abb.). In Entwicklungsl{\"{a}}ndern sind Agrarsysteme wegen geringerer gesamtwirtschaftlicher Diversifizierung und Spezialisierung erst in Ans{\"{a}}tzen vorhanden. Funktionen, die in Industriel{\"{a}}ndern nicht (mehr) von der Landwirtschaft wahrgenommen werden, geh{\"{o}}ren hier noch teilweise zum Aufgabenbereich der Bauern (Herstellung von Werkzeug, Vermarktung, Verarbeitung usw.). 3) Bezeichnung f{\"{u}}r die landwirtschaftlichen Funktionseinheiten ("operational units"), die unterschiedlichste Varianten hinsichtlich Gr{\"{o}}{\ss}e und Komplexit{\"{a}}t aufweisen k{\"{o}}nnen und die dann mit den Begriffen Unternehmen, Farm, Plantagenwirtschaft belegt oder auf die Landwirtschaft einer Region oder eines Staates bezogen sein k{\"{o}}nnen. 4) h{\"{a}}ufig synonym zu agrarsoziales System verwendet. },
author = {Baldenhofer, Kurt},
booktitle = {LEXIKON DER GEOGRAPHIE},
keywords = {Agrarsystem},
mendeley-groups = {CLAAS SeMAV,CLAAS SeMAV/Definitionen},
mendeley-tags = {Agrarsystem},
publisher = {Spektrum Akademischer},
title = {{Agrarsystem}},
url = {http://www.spektrum.de/lexikon/geographie/agrarsystem/184},
year = {2001}
}
@inproceedings{Korthals2016b,
abstract = {Copyright {\textcopyright} 2016 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved. A huge number of techniques for detecting and mapping obstacles based on LIDAR and SONAR exist, though not taking approximative sensors with high levels of uncertainty into consideration. The proposed mapping method in this article is undertaken by detecting surfaces and approximating objects by distance using sensors with high localization ambiguity. Detection is based on an Inverse Particle Filter, which uses readings from single or multiple sensors as well as a robot's motion. This contribution describes the extension of the Sequential Importance Resampling filter to detect objects based on an analytical sensor model and embedding into Occupancy Grid Maps. The approach has been applied to the autonomous mini robot AMiRo in a distributed way. There were promising results for its low-power, low-cost proximity sensors in various real life mapping scenarios, which outperform the standard Inverse Sensor Model approach.},
author = {Korthals, T. and Barther, M. and Sch{\"{o}}pping, T. and Herbrechtsmeier, S. and R{\"{u}}ckert, U.},
booktitle = {ICINCO 2016 - Proceedings of the 13th International Conference on Informatics in Control, Automation and Robotics},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korthals, Barther, Herbrechtsmeier - 2016 - Occupancy Grid Mapping with Highly Uncertain Range Sensors based on Inverse Particle Filters.pdf:pdf},
isbn = {9789897581984},
keywords = {Inverse particle filter,Inverse sensor model,Occupancy grid mapping,Uncertain range sensors},
title = {{Occupancy grid mapping with highly uncertain range sensors based on inverse particle filters}},
volume = {2},
year = {2016}
}
@inproceedings{Herbrechtsmeier2016a,
abstract = {{\textcopyright} 2016 IEEE. AMiRo is a novel modular robot platform that can be easily extended and customized in hardware and software. Built up of electronic modules that fully exploit recent technology and open-source software for sensor processing, actuator control, and cognitive processing, the robot facilitates rich autonomous behaviors. Further contribution lies in the completely open-source software habitat: from low-level microcontroller implementations, over high-level applications running on an embedded processor, up to hardware accelerated algorithms using programmable logic. This paper describes in detail the motivation, system architecture, and software design of the AMiRo, which surpasses state-of-the-art competitors.},
author = {Herbrechtsmeier, S. and Korthals, T. and Sch{\"{o}}pping, T. and R{\"{u}}ckert, U.},
booktitle = {2016 20th International Conference on System Theory, Control and Computing, ICSTCC 2016 - Joint Conference of SINTES 20, SACCS 16, SIMSIS 20 - Proceedings},
doi = {10.1109/ICSTCC.2016.7790746},
file = {:home/tkorthals/Documents/Mendeley Desktop/Herbrechtsmeier et al. - 2016 - AMiRo A modular {\&} customizable open-source mini robot platform.pdf:pdf},
isbn = {9781509027200},
keywords = {Educational robots,Mobile robots,Robot programming,Robots},
title = {{AMiRo: A modular {\&} customizable open-source mini robot platform}},
year = {2016}
}
@phdthesis{Exner2017,
author = {Exner, Julian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Exner - 2017 - Informed Path Planning on Multi-Modal Occupancy Grid Maps.pdf:pdf},
mendeley-groups = {{\_}STUDENTEN/Julian Exner},
title = {{Informed Path Planning on Multi-Modal Occupancy Grid Maps}},
year = {2017}
}
@techreport{Durr2016,
abstract = {Variational autoencoders are interesting generative models, which combine ideas from deep learning with statistical inference. They can be used to learn a low dimensional representation Z of high dimensional data X such as images (of e.g. faces). In contrast to standard auto encoders, X and Z are random variables. It's therefore possible to sample X from the distribution P(X| Z), thus creating e.g. images of faces, MNIST Digits, or speech.},
author = {D{\"{u}}rr, Oliver},
file = {:home/tkorthals/Documents/Mendeley Desktop/D{\"{u}}rr - 2016 - Introduction to variational autoencoder.pdf:pdf},
keywords = {VAE},
mendeley-groups = {Machine Learning/Autoencoder,VAE,VAE/Tutorials},
mendeley-tags = {VAE},
title = {{Introduction to variational autoencoder}},
url = {https://home.zhaw.ch/{~}dueo/bbs/files/vae.pdf},
year = {2016}
}
@article{DBLP:journals/corr/KingmaW13,
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes.pdf:pdf},
journal = {CoRR},
mendeley-groups = {Machine Learning/Autoencoder},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
volume = {abs/1312.6},
year = {2013}
}
@incollection{4ac1c67ae5a1439db82bda1c175dea94,
abstract = {Variational autoencoders are a powerful framework for unsupervised learning. However, previous work has been restricted to shallow models with one or two layers of fully factorized stochastic latent variables, limiting the flexibility of the latent representation. We propose three advances in training algorithms of variational autoencoders, for the first time allowing to train deep models of up to five stochastic layers, (1) using a structure similar to the Ladder network as the inference model, (2) warm-up period to support stochastic units staying active in early training, and (3) use of batch normalization. Using these improvements we show state-of-the-art log-likelihood results for generative modeling on several benchmark datasets.},
author = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
booktitle = {Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)},
file = {:home/tkorthals/Documents/Mendeley Desktop/S{\o}nderby et al. - 2016 - How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks.pdf:pdf},
mendeley-groups = {VAE,VAE/Tutorials},
title = {{How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks}},
year = {2016}
}
@article{Kulkarni2016,
abstract = {Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete stochastic decision process, and (2) the classic ATARI game `Montezuma's Revenge'.},
archivePrefix = {arXiv},
arxivId = {1604.06057},
author = {Kulkarni, Tejas D. and Narasimhan, Karthik R. and Saeedi, Ardavan and Tenenbaum, Joshua B.},
doi = {10.1023/A:1025696116075},
eprint = {1604.06057},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kulkarni et al. - 2016 - Hierarchical Deep Reinforcement Learning Integrating Temporal Abstraction and Intrinsic Motivation.pdf:pdf},
isbn = {0924-6703},
issn = {1573-7594},
mendeley-groups = {Machine Learning/DQN},
pages = {1--13},
title = {{Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation}},
url = {http://arxiv.org/abs/1604.06057},
year = {2016}
}
@inproceedings{6386052,
abstract = {Visual markers are useful assistive tool for service robots. Existing planar visual markers have poor accuracy in pose estimation, especially in frontal direction. We solved this problem by a novel principle using a microlens array. The marker displays a changing moiré pattern according to the visual-line direction. We can extract the pose information from the pattern by image processing using a single camera. The developed marker and the processing algorithm enable high-accuracy pose estimation even by observation from frontal direction. We verified its superiority to the conventional method by some validation tests. The marker is an extension of a marker we previously developed, and is more easily fabricated.},
author = {Tanaka, H and Sumi, Y and Matsumoto, Y},
booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2012.6386052},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanaka, Sumi, Matsumoto - 2012 - A high-accuracy visual marker based on a microlens array.pdf:pdf},
issn = {2153-0858},
keywords = {Accuracy,Arrays,Estimation,Fabrication,Lenses,Microoptics,Visualization,assistive tool,frontal direction,high-accuracy pose estimation,high-accuracy visual marker,microlens array,microlenses,moire pattern,planar visual markers,pose estimation,robot vision,service robots,visual-line direction},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {4192--4197},
title = {{A high-accuracy visual marker based on a microlens array}},
year = {2012}
}
@inproceedings{Korthals2017,
address = {Vancouver},
author = {Korthals, Timo and Kragh, Mikkel and Christiansen, Peter and R{\"{u}}ckert, Ulrich},
booktitle = {IROS 2017 Workshop on Agricultural Robotics: learning from Industry 4.0 and moving into the future},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals et al. - 2017 - Towards Inverse Sensor Mapping in Agriculture.pdf:pdf},
title = {{Towards Inverse Sensor Mapping in Agriculture}},
year = {2017}
}
@book{Press,
author = {Aghajan, Hamid and Cavallaro, Andrea},
file = {:home/tkorthals/Documents/Mendeley Desktop/Aghajan, Cavallaro - 2009 - Multi-Camera Networks principles and applications.pdf:pdf},
isbn = {9780123746337},
title = {{Multi-Camera Networks - Principles and Applications}},
year = {2009}
}
@book{citeulike:5731413,
abstract = {Technological advances in sensor design, communication, and computing are stimulatingthe development of new applications that will transform traditional vision systems intopervasive intelligent camera networks. Applications enabled by multi-camera networksinclude smart homes, office automation through occupancy sensing, security and surveillance,mobile and robotic networks, human–computer interfaces, interactive kiosks, andvirtual reality systems.Image sensors extract valuable event and context information from the environment.By acquiring an information-rich data type, they enable vision-based interpretive applications.Such applications range from real-time event interpretation in smart environmentsto adaptation to user behavior models based on long-term observations in ambientintelligence. Multi-camera networks represent a multi-disciplinary field that defines richconceptual and algorithmic opportunities for computer vision, signal processing, andembedded computing, as well as for wired and wireless sensor networks.New algorithm and system design challenges have been identified across the differentcommunities involved in multi-camera networks research. In signal processing, thesubjects of much recent work involves effective methods for multi-layered or hybrid dataexchange among cameras for collaborative deduction regarding events of interest andexploitation of the spatial and temporal redundancies in the data.The field of sensor networksfinds opportunities for novel research when hybrid types and amounts of data areproduced by image sensors. Embedded computing methods that allow cameras to workcollaboratively over a network to solve a vision problem have been under study. Froma computer vision design standpoint, multi-view methods based on partial processingof video locally provide researchers with new opportunities in considering system-levelconstraints that may influence algorithm design. In this way, multi-camera networks createopportunities for design paradigm shifts in distributed and collaborative fusion ofvisual information, enabling the creation of novel methods and applications that areinterpretive, context aware, and user-centric.},
author = {Aghajan, Hamid and Cavallaro, Andrea},
doi = {10.1016/B978-0-12-374633-7.00011-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Aghajan, Cavallaro - 2009 - Multi-Camera Networks principles and applications.pdf:pdf},
isbn = {13: 9780123746337},
keywords = {cameras,coding,communication,compression,detection,distributed,multisensor,surveillance},
mendeley-groups = {Vision,Vision/Registration {\&} Calibration},
publisher = {Elsevier Inc.},
title = {{Multi-Camera Networks principles and applications}},
url = {http://dx.doi.org/10.1016/B978-0-12-374633-7.00011-2},
year = {2009}
}
@inproceedings{Korthals2017ogmf,
author = {Korthals, Timo and Exner, Julian and Sch{\"{o}}pping, Thomas and Hesse, Marc},
booktitle = {European Conference on Mobile Robotics},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals et al. - 2017 - Semantical Occupancy Grid Mapping Framework.pdf:pdf},
publisher = {IEEE},
title = {{Semantical Occupancy Grid Mapping Framework}},
year = {2017}
}
@article{Simond2003,
abstract = {In this paper, we address the problem of computing the egomotion of a vehicle in an urban environment using dynamic vision. We assume a planar piecewise world where the planes are mainly distributed along three principal directions corresponding to the axes of a reference frame linked to the ground plane with a vertical z-axis. We aim to estimate both the motion of the car and the principal planes in the scene corresponding to the road and the frontages of the building from a sequence of images provided by an on-board uncalibrated camera. In this paper, we present preliminary results concerning the robust segmentation of the road using projective properties of the scene. We develop a two-stage algorithm in order to increase robustness. The first stage detects the borders of the road using a contour-based approach and primarily allows us to estimate the dominant vanishing point (DVP). The DVP and the borders of the road are then used to constrain the region where the points of interest, corresponding to the road lane markers, can be extracted. The second stage uses a robust technique based on projective invariant to match the lines and points between two consecutive images in the sequence. Finally, we compute the homography relating the points and lines lying on the road into the two images.},
author = {Simond, Nicolas and Rives, Patrick},
doi = {10.1109/IROS.2003.1250759},
isbn = {0780378601},
journal = {International Conference on Intelligent Robots and Systems},
keywords = {ban areas vary according,cross-ratio,dominant vanishing point,from,ho-,mography,road plane,shadow conditions and to,the,the type of scenes,to the brightness and,urban environment},
mendeley-groups = {CLAAS itsowl},
pages = {1005--1010},
title = {{Homography from a vanishing point in urban scenes}},
year = {2003}
}
@article{Shelhamer2017,
abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20{\%} relative improvement to 62.2{\%} mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
archivePrefix = {arXiv},
arxivId = {1411.4038},
author = {Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
doi = {10.1109/TPAMI.2016.2572683},
eprint = {1411.4038},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shelhamer, Long, Darrell - 2017 - Fully Convolutional Networks for Semantic Segmentation.pdf:pdf},
isbn = {9781467369640},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Convolutional Networks,Deep Learning,Semantic Segmentation,Transfer Learning},
mendeley-groups = {CLAAS itsowl,Vision/Registration {\&} Calibration,VAE},
number = {4},
pages = {640--651},
pmid = {16190471},
title = {{Fully Convolutional Networks for Semantic Segmentation}},
volume = {39},
year = {2017}
}
@article{Redmon2016,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.$\backslash$r$\backslash$n},
archivePrefix = {arXiv},
arxivId = {1506.02640v1},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
doi = {10.1016/j.nima.2015.05.028},
eprint = {1506.02640v1},
isbn = {9781467388511},
issn = {10636919},
journal = {Cvpr 2016},
mendeley-groups = {CLAAS itsowl},
pages = {779--788},
pmid = {27295650},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
year = {2016}
}
@article{Pickem2016,
abstract = {This paper describes the development of the Robotarium -- a remotely accessible, multi-robot research facility. The impetus behind the Robotarium is that multi-robot testbeds constitute an integral and essential part of the multi-agent research cycle, yet they are expensive, complex, and time-consuming to develop, operate, and maintain. These resource constraints, in turn, limit access for large groups of researchers and students, which is what the Robotarium is remedying by providing users with remote access to a state-of-the-art multi-robot test facility. This paper details the design and operation of the Robotarium as well as connects these to the particular considerations one must take when making complex hardware remotely accessible. In particular, safety must be built in already at the design phase without overly constraining which coordinated control programs the users can upload and execute, which calls for minimally invasive safety routines with provable performance guarantees.},
archivePrefix = {arXiv},
arxivId = {1604.00640},
author = {Pickem, Daniel and Wang, Li and Glotfelter, Paul and Diaz-Mercado, Yancy and Mote, Mark and Ames, Aaron and Feron, Eric and Egerstedt, Magnus},
eprint = {1604.00640},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pickem et al. - 2016 - Safe, Remote-Access Swarm Robotics Research on the Robotarium.pdf:pdf},
journal = {Manuscript},
mendeley-groups = {Robotics/TeleWerkBank,Vision/Tracking/Fiducial Marker,Robotics/TeleWerkBank/Tracking Benches},
number = {April},
pages = {1--13},
title = {{Safe, Remote-Access Swarm Robotics Research on the Robotarium}},
url = {http://arxiv.org/abs/1604.00640},
year = {2016}
}
@inproceedings{Rublee2011,
abstract = {Feature matching is at the base of many computer vi-sion problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for de-tection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magni-tude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world ap-plications, including object detection and patch-tracking on a smart phone.},
author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126544},
isbn = {9781457711015},
issn = {1550-5499},
mendeley-groups = {Robotics/TeleWerkBank},
pages = {2564--2571},
pmid = {20033598},
title = {{ORB: An efficient alternative to SIFT or SURF}},
year = {2011}
}
@techreport{ISO2009,
author = {ISO},
file = {:home/tkorthals/Documents/Mendeley Desktop/ISO - 2009 - ISO 11783-10 - Task controller and management information system data interchange.pdf:pdf},
mendeley-groups = {CLAAS itsowl},
title = {{ISO 11783-10 - Task controller and management information system data interchange}},
volume = {2009},
year = {2009}
}
@inproceedings{Bakker2006,
abstract = {This paper describes quasi-online reinforcement learning: while a robot is exploring its environment, in the background a probabilistic model of the environment is built on the fly as new experiences arrive; the policy is trained concurrently based on this model using an anytime algorithm. Prioritized sweeping, directed exploration, and transformed reward functions provide additional speed-ups. The robot quickly learns goal-directed policies from scratch, requiring few interactions with the environment and making efficient use of available computation time. From an outside perspective it learns the behavior online and in real time. We describe comparisons with standard methods and show the individual utility of each of the proposed techniques},
author = {Bakker, Bram and Zhumatiy, Viktor and Gruener, Gabriel and Schmidhuber, J??rgen},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2006.1642157},
isbn = {0780395069},
issn = {10504729},
mendeley-groups = {Machine Learning/DQN},
pages = {2997--3002},
title = {{Quasi-online reinforcement learning for robots}},
volume = {2006},
year = {2006}
}
@inproceedings{Martinez-Marin2005,
abstract = {This paper presents a new reinforcement learning algorithm for accelerating acquisition of new skills by real mobile robots, without requiring simulation. It speeds up Q-learning by applying memory-based sweeping and enforcing the {\&}{\#}8220;adjoining property{\&}{\#}8221;, a technique that exploits the natural ordering of sensory state spaces in many robotic applications by only allowing transitions between neighbouring states. The algorithm is tested within an image-based visual servoing framework on a docking task, in which the robot has to position its gripper at a desired configuration relative to an object on a table. In experiments, we compare the performance of the new algorithm with a hand-designed linear controller and a scheme using the linear controller as a bias to further accelerate the learning. By analysis of the controllability and docking time, we show that the biased learner could improve on the performance of the linear controller, while requiring substantially lower training time than unbiased learning (less than 1 hour on the real robot).},
author = {Mart{\'{i}}nez-Mar{\'{i}}n, Tom{\'{a}}s and Duckett, Tom},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2005.1570760},
isbn = {078038914X},
issn = {10504729},
mendeley-groups = {Machine Learning/DQN},
pages = {4170--4175},
title = {{Fast reinforcement learning for vision-guided mobile robots}},
volume = {2005},
year = {2005}
}
@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
mendeley-groups = {Machine Learning/DQN},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}
@article{Birdwell2007,
author = {Birdwell, Nicole and Livingston, Scott C},
file = {:home/tkorthals/Documents/Mendeley Desktop/Birdwell, Livingston - 2007 - Reinforcement Learning in Sensor-Guided AIBO Robots.pdf:pdf},
mendeley-groups = {Machine Learning/DQN},
pages = {1--7},
title = {{Reinforcement Learning in Sensor-Guided AIBO Robots}},
year = {2007}
}
@article{Krose1995,
abstract = {In behavioural ecology, stochastic dynamic programming may be used as a general method for calculating animals' optimal behavioural policies. But how might the animals themselves learn optimal policies from their experience? The aim of the thesis is to give a systematic analysis of possible computational methods of learning efficient behaviour. First, it is argued that it does follow from the optimality assumption that animals should learn optimal policies, even though they may' not always follow them. Next, it is argued that Markov decision processes are a general formal model of an animal's behavioural choices in its environment The conventional methods of determining optimal policies by dynamic programming are then described. It is not plausible that animals carry out calculations of this type. However, there is a range of alternative methods of organising the dynamic programming calculation, in ways that are plausible computational models of animal learning. In particular, there is an incremental Monte-Carlo method that enables the optimal values or 'canonical costs') of actions to be learned directly, without any requirement for the animal to model its environ- ment, or to remember situations and actions for more than a short period of time. A proof is given that this learning method works. Learning methods of this type are also possible for hierarchical policies. Previously suggested learn- ing methods are reviewed, and some even simpler learning methods are presented without proof. Demonstration implementations of some of the learn- ing methods are described.},
author = {Kr{\"{o}}se, Ben J.A.},
doi = {10.1016/0921-8890(95)00026-C},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
mendeley-groups = {Machine Learning/DQN},
number = {4},
pages = {233--235},
title = {{Learning from delayed rewards}},
url = {http://linkinghub.elsevier.com/retrieve/pii/092188909500026C},
volume = {15},
year = {1995}
}
@article{Sutton1998,
abstract = {From the Publisher:In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.},
author = {Sutton, Richard S and Barto, Andrew G},
doi = {10.1.1.32.7692},
isbn = {0262193981},
issn = {10743529},
journal = {Learning},
keywords = {intro to dynamic programming,ro to reinforcement learning},
mendeley-groups = {Machine Learning/DQN},
number = {1996},
pages = {1--5},
title = {{Introduction to Reinforcement Learning}},
url = {http://dl.acm.org/citation.cfm?id=551283},
volume = {4},
year = {1998}
}
@misc{schoepping2016,
abstract = {[AMiRo-OS](https://opensource.cit-ec.de/projects/amiro-os) is the operating system for the base version of the Autonomous Mini Robot (AMiRo). It utilizes [ChibiOS](http://chibios.org) (a real-time operating system for embedded devices developed by Giovanni di Sirio) as system kernel and extends it with platform specific functionalities. It also comprises a bootloader and flashing toolchain, based on [OpenBLT](http://feaser.com/en/openblt.php).},
author = {Sch{\"{o}}pping, Thomas and Korthals, Timo and Herbrechtsmeier, Stefan and Chinapirom, Teerapat and Abel, Robert and Barther, Marvin and Kenneweg, Tristan and Braun, Claas and R{\"{u}}ckert, Ulrich},
doi = {10.4119/unibi/2902276},
publisher = {Bielefeld University},
title = {{AMiRo-OS}},
year = {2016}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
eprint = {1312.5602},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
mendeley-groups = {Machine Learning/DQN},
number = {7540},
pages = {529--533},
pmid = {25719670},
title = {{Human-level control through deep reinforcement learning}},
url = {http://www.nature.com/doifinder/10.1038/nature14236},
volume = {518},
year = {2015}
}
@techreport{Lunenburg2016,
abstract = {This paper provides an overview of the main developments of the Tech United Eindhoven RoboCup@Home team. Our main research efforts this year have focused on i) fitting furniture objects to update our object-oriented world model, thereby improving localization, navigation and object segmentation ii) developing a WebGUI to provide the user with a platform-independent way to interact with the robot and iii) natural language interpretation to ease the specification of written commands for the robot and to make speech recognition more robust.},
author = {Lunenburg, J.J.M. and van den Dries, S. and Appeldoorn, R.P.W. and Wijnands, R.W.J. and Clephas, T.T.G. and Baeten, M.J.J. and van Beek, L. and Ottervanger, R.A. and Ferreira, L.F. Bento and van de Molengraft, M.J.G.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lunenburg et al. - 2016 - Tech United Eindhoven @Home 2016 Team Description Paper.pdf:pdf},
institution = {Eindhoven University of Technology},
mendeley-groups = {Robotics/RoboCup},
pages = {1--8},
title = {{Tech United Eindhoven @Home 2016 Team Description Paper}},
url = {http://www.robocup2016.org/media/symposium/Team-Description-Papers/AtHome/RoboCup{\_}2016{\_}AtHome{\_}TDP{\_}Tech{\_}United{\_}At{\_}Home.pdf},
year = {2016}
}
@article{wisspeintner2009robocup,
author = {Wisspeintner, Thomas and {Van Der Zant}, Tijn and Iocchi, Luca and Schiffer, Stefan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wisspeintner et al. - 2009 - RoboCup@ Home Scientific competition and benchmarking for domestic service robots.pdf:pdf},
journal = {Interaction Studies},
mendeley-groups = {Robotics/RoboCup},
number = {3},
pages = {392--426},
publisher = {John Benjamins Publishing Company},
title = {{RoboCup@ Home: Scientific competition and benchmarking for domestic service robots}},
volume = {10},
year = {2009}
}
@misc{Marder-Eppstein,
author = {Marder-Eppstein, Eitan and Lu, D. V. and Hershberg, D.},
mendeley-groups = {Robotics/Maps/OGM},
title = {costmap{\_}2d},
url = {http://wiki.ros.org/costmap{\_}2d},
urldate = {2005-07-20}
}
@misc{Marder-Eppsteina,
author = {Marder-Eppstein, Eitan and Lu, D. V.},
mendeley-groups = {Robotics/Navigation},
title = {navigation},
url = {http://wiki.ros.org/navigation},
urldate = {2017-05-01}
}
@article{Morris2014,
abstract = {This paper presents a method to enable a mobile robot working in non-stationary environments to plan its path and localize within multiple map hypotheses simultaneously. The maps are generated using a long-term and short-term memory mechanism that ensures only persistent configurations in the environment are selected to create the maps. In order to evaluate the proposed method, experimentation is conducted in an office environment. Compared to navigation systems that use only one map, our system produces superior path planning and navigation in a non-stationary environment where paths can be blocked periodically, a common scenario which poses significant challenges for typical planners.},
author = {Morris, Timothy and Dayoub, Feras and Corke, Peter and Wyeth, Gordon and Upcroft, Ben},
doi = {10.1109/ICRA.2014.6907255},
file = {:home/tkorthals/Documents/Mendeley Desktop/Morris et al. - 2014 - Multiple map hypotheses for planning and navigating in non-stationary environments.pdf:pdf},
isbn = {978-1-4799-3685-4},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Robotics/Maps/OGM},
pages = {2765--2770},
title = {{Multiple map hypotheses for planning and navigating in non-stationary environments}},
year = {2014}
}
@article{Grisetti2007,
abstract = {Recently, Rao-Blackwellized particle filters (RBPF) have been introduced as an effective means to solve the simultaneous localization and mapping problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles. In this paper, we present adaptive techniques for reducing this number in a RBPF for learning grid maps. We propose an approach to compute an accurate proposal distribution, taking into account not only the movement of the robot, but also the most recent observation. This drastically decreases the uncertainty about the robot's pose in the prediction step of the filter. Furthermore, we present an approach to selectively carry out resampling operations, which seriously reduces the problem of particle depletion. Experimental results carried out with real mobile robots in large-scale indoor, as well as outdoor, environments illustrate the advantages of our methods over previous approaches},
author = {Grisetti, Giorgio and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1109/TRO.2006.889486},
file = {:home/tkorthals/Documents/Mendeley Desktop/Grisetti, Stachniss, Burgard - 2007 - Improved techniques for grid mapping with Rao-Blackwellized particle filters.pdf:pdf},
isbn = {1552-3098 VO - 23},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Adaptive resampling,Improved proposal,Motion model,Rao-Blackwellized particle filter (RBPF),Simultaneous localization and mapping (SLAM),gmapping},
mendeley-groups = {Robotics/SLAM},
mendeley-tags = {gmapping},
number = {1},
pages = {34--46},
title = {{Improved techniques for grid mapping with Rao-Blackwellized particle filters}},
volume = {23},
year = {2007}
}
@misc{KARTO2017,
author = {KARTO},
mendeley-groups = {Robotics/SLAM},
title = {{KARTO}},
url = {https://www.kartorobotics.com/},
year = {2017}
}
@article{Hornung2013,
abstract = {3D mapping, lack of efficient implmentations this one is? Robocup uses octomap.},
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hornung et al. - 2013 - OctoMap An efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
isbn = {0929-5593},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {3D,Mapping,Navigation,Probabilistic},
mendeley-groups = {Robotics/Maps/OGM},
number = {3},
pages = {189--206},
title = {{OctoMap: An efficient probabilistic 3D mapping framework based on octrees}},
volume = {34},
year = {2013}
}
@article{Droeschel2016,
abstract = {Micro aerial vehicles, such as multirotors, are particularly well suited for the autonomous monitoring, inspection, and surveillance of buildings, e.g., for maintenance or disaster management. Key prerequisites for the fully autonomous operation of micro aerial vehicles are real-time obstacle detection and planning of collision-free trajectories. In this article, we propose a complete system with a multimodal sensor setup for omnidirectional obstacle perception consisting of a three-dimensional (3D) laser scanner, two stereo camera pairs, and ultrasonic distance sensors. Detected obstacles are aggregated in egocentric local multiresolution grid maps. Local maps are efficiently merged in order to simultaneously build global maps of the environment and localize in these. For autonomous navigation, we generate trajectories in a multilayered approach: from mission planning over global and local trajectory planning to reactive obstacle avoidance. We evaluate our approach and the involved components in simulation and with the real autonomous micro aerial vehicle. Finally, we present the results of a complete mission for autonomously mapping a building and its surroundings.},
archivePrefix = {arXiv},
arxivId = {10.1.1.91.5767},
author = {Droeschel, David and Nieuwenhuisen, Matthias and Beul, Marius and Holz, Dirk and St??ckler, J??rg and Behnke, Sven},
doi = {10.1002/rob.21603},
eprint = {10.1.1.91.5767},
file = {:home/tkorthals/Documents/Mendeley Desktop/Droeschel et al. - 2016 - Multilayered Mapping and Navigation for Autonomous Micro Aerial Vehicles.pdf:pdf},
isbn = {9783902661623},
issn = {15564967},
journal = {Journal of Field Robotics},
mendeley-groups = {Robotics/Maps/OGM},
number = {4},
pages = {451--475},
pmid = {22164016},
title = {{Multilayered Mapping and Navigation for Autonomous Micro Aerial Vehicles}},
volume = {33},
year = {2016}
}
@article{IEEE2017,
author = {IEEE},
file = {:home/tkorthals/Documents/Mendeley Desktop/IEEE - 2017 - Robotics {\&} Automation 03.17.pdf:pdf},
journal = {IEEE Robotics {\&} Automation Magazine},
mendeley-groups = {IEEE},
title = {{Robotics {\&} Automation 03.17}},
year = {2017}
}
@article{Meuleau2010,
author = {Meuleau, Nicolas and Plaunt, Christian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Meuleau, Plaunt - 2010 - A pomdp for optimal motion planning with uncertain dynamics.pdf:pdf},
journal = {Icaps-10: Pomdp {\ldots}},
mendeley-groups = {Robotics/POMDP/Policy Optimization},
title = {{A pomdp for optimal motion planning with uncertain dynamics}},
url = {http://de2smith.xs.com/publications/ICAPS10-POMPUD.pdf},
year = {2010}
}
@article{Coenen2012,
author = {Coenen, S A M},
file = {:home/tkorthals/Documents/Mendeley Desktop/Coenen - 2012 - Motion Planning for Mobile Robots - A Guide.pdf:pdf},
journal = {Bobbierobotics.Nl},
mendeley-groups = {Robotics/Control},
pages = {85},
title = {{Motion Planning for Mobile Robots - A Guide}},
url = {http://www.bobbierobotics.nl/media/files/motion{\_}planning{\_}for{\_}mobile{\_}robots{\_}-{\_}a{\_}guide.pdf},
year = {2012}
}
@article{Kollar2008,
abstract = {Automatically building maps from sensor data is a necessary and fundamental skill for mobile robots; as a result, considerable research attention has focused on the technical challenges inherent in the mapping problem. While statistical inference techniques have led to computationally efficient mapping algorithms, the next major challenge in robotic mapping is to automate the data collection process. In this paper, we address the problem of how a robot should plan to explore an unknown environment and collect data in order to maximize the accuracy of the resulting map. We formulate exploration as a constrained optimization problem and use reinforcement learning to find trajectories that lead to accurate maps. We demonstrate this process in simulation and show that the learned policy not only results in improved map building, but that the learned policy also transfers successfully to a real robot exploring on MIT campus.},
author = {Kollar, T. and Roy, N.},
doi = {10.1177/0278364907087426},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kollar, Roy - 2008 - Trajectory Optimization using Reinforcement Learning for Map Exploration.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {reinforcement learning,trajectory optimiza-},
mendeley-groups = {Robotics/POMDP/Policy Optimization},
number = {2},
pages = {175--196},
title = {{Trajectory Optimization using Reinforcement Learning for Map Exploration}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364907087426},
volume = {27},
year = {2008}
}
@article{Li2017,
abstract = {We give an overview of recent exciting achievements of deep reinforcement learning (RL). We start with background of deep learning and reinforcement learning, as well as introduction of testbeds. Next we discuss Deep Q-Network (DQN) and its extensions, asynchronous methods, policy optimization, reward, and planning. After that, we talk about attention and memory, unsupervised learning, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, spoken dialogue systems (a.k.a. chatbot), machine translation, text sequence prediction, neural architecture design, personalized web services, healthcare, finance, and music generation. We mention topics/papers not reviewed yet. After listing a collection of RL resources, we close with discussions.},
archivePrefix = {arXiv},
arxivId = {1701.07274},
author = {Li, Yuxi},
eprint = {1701.07274},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li - 2017 - Deep Reinforcement Learning An Overview.pdf:pdf},
mendeley-groups = {Machine Learning/DQN},
pages = {1--30},
title = {{Deep Reinforcement Learning: An Overview}},
url = {http://arxiv.org/abs/1701.07274},
year = {2017}
}
@article{Dosovitskiy2016,
abstract = {We present an approach to sensorimotor control in immersive environments. Our approach utilizes a high-dimensional sensory stream and a lower-dimensional measurement stream. The cotemporal structure of these streams provides a rich supervisory signal, which enables training a sensorimotor control model by interacting with the environment. The model is trained using supervised learning techniques, but without extraneous supervision. It learns to act based on raw sensory input from a complex three-dimensional environment. The presented formulation enables learning without a fixed goal at training time, and pursuing dynamically changing goals at test time. We conduct extensive experiments in three-dimensional simulations based on the classical first-person game Doom. The results demonstrate that the presented approach outperforms sophisticated prior formulations, particularly on challenging tasks. The results also show that trained models successfully generalize across environments and goals. A model trained using the presented approach won the Full Deathmatch track of the Visual Doom AI Competition, which was held in previously unseen environments.},
author = {Dosovitskiy, Alexey and Koltun, Vladlen},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dosovitskiy, Koltun - 2016 - Learning to Act by Predicting the Future.pdf:pdf},
journal = {CoRR},
mendeley-groups = {Machine Learning/DQN},
pages = {1--14},
title = {{Learning to Act by Predicting the Future}},
url = {http://arxiv.org/abs/1611.01779},
volume = {abs/1611.0},
year = {2016}
}
@article{Theodorou2010,
abstract = {With the goal to generate more scalable algorithms with higher efficiency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parametrized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-Jacobi-Bellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open parameters other than the exploration noise. The resulting algorithm can be conceived of as modelbased, semi-model-based, or even model free, depending on how the learning problem is structured. Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. We believe that Policy Improvement with Path Integrals (PI 2) offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs. Copyright 2010 by the authors.},
author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Theodorou, Buchli, Schaal - 2010 - Learning policy improvements with path integrals.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
mendeley-groups = {Robotics/POMDP/Policy Optimization},
pages = {828--835},
title = {{Learning policy improvements with path integrals}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862297667{\&}partnerID=tZOtx3y1},
volume = {9},
year = {2010}
}
@article{Hof,
author = {Hof, W D Van Den},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hof - Unknown - Thesis Robot Search in Unknown Environments Using POMDPs.pdf:pdf},
mendeley-groups = {Robotics/POMDP/Policy Optimization},
title = {{Thesis: Robot Search in Unknown Environments Using POMDPs}}
}
@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
doi = {10.1038/nature14236},
eprint = {1312.5602},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
mendeley-groups = {Machine Learning/DQN},
pages = {1--9},
pmid = {25719670},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@article{Gerlach2017,
author = {Gerlach, Jonas},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerlach - 2017 - SVM-Basierte Fusion und Klassifikation von Kamera und LiDAR Daten zur Umfelderkennung in Getreidefeldern.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{SVM-Basierte Fusion und Klassifikation von Kamera und LiDAR Daten zur Umfelderkennung in Getreidefeldern}},
year = {2017}
}
@inproceedings{Santana2014,
abstract = {In this paper a complete framework is proposed, to deal with trajectory tracking and positioning with an AR.Drone Parrot quadrotor flying in indoor environments. The system runs in a centralized way, in a computer installed in a ground station, and is based on two main structures, namely a Kalman Filter (KF) to track the 3D position of the vehicle and a nonlinear controller to guide it in the accomplishment of its flight missions. The KF is designed aiming at estimating the states of the vehicle, fusing inertial and visual data. The nonlinear controller is designed with basis on a dynamic model of the AR.Drone, with the closed-loop stability proven using the theory of Lyapunov. Finally, experimental results are presented, which demonstrate the effectiveness of the proposed framework.},
author = {Santana, Lucas Vago and Brandao, Alexandre Santos and Sarcinelli-Filho, Mario and Carelli, Ricardo},
booktitle = {2014 International Conference on Unmanned Aircraft Systems, ICUAS 2014 - Conference Proceedings},
doi = {10.1109/ICUAS.2014.6842321},
file = {:home/tkorthals/Documents/Mendeley Desktop/Santana et al. - 2014 - A trajectory tracking and 3D positioning controller for the AR.Drone quadrotor.pdf:pdf},
isbn = {9781479923762},
mendeley-groups = {{\_}STUDENTEN/Philipp{\_}Juenemann},
pages = {756--767},
title = {{A trajectory tracking and 3D positioning controller for the AR.Drone quadrotor}},
year = {2014}
}
@article{Fankhauser2016,
abstract = {In this research chapter, we present our work on a universal grid map library for use as mapping framework for mobile robotics. It is designed for a wide range of applications such as online surface reconstruction and terrain interpretation for rough terrain navigation. Our software features multi-layered maps, computationally efficient repositioning of the map boundaries, and compatibility with existing ROS map message types. Data storage is based on the linear algebra library Eigen, offering a wide range of data processing algorithms. This chapter outlines how to integrate the grid map library into the reader's own applications. We explain the concepts and provide code samples to discuss various features of the software. As a use case, we present an application of the library for online elevation mapping with a legged robot. The grid map library and the robot-centric elevation mapping framework are available open-source at http://github.com/ethz-asl/grid{\_}map and http://github.com/ethz-asl/elevation{\_}mapping.},
author = {Fankhauser, P{\'{e}}ter and Hutter, Marco},
doi = {10.1007/978-3-319-26054-9_5},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fankhauser, Hutter - 2016 - A universal grid map library Implementation and use case for rough terrain navigation.pdf:pdf},
isbn = {978-3-319-26052-5},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
keywords = {Elevation mapping,Grid map,ROS},
mendeley-groups = {Robotics/Maps/OGM},
pages = {99--120},
title = {{A universal grid map library: Implementation and use case for rough terrain navigation}},
volume = {625},
year = {2016}
}
@inproceedings{Zickler2010,
abstract = {Synaptophysin (protein p38) immunoreactivity has been detected immunohistochemically in neuroendocrine cells of the human adrenal medulla, carotid body, skin, pituitary, thyroid, lung, pancreas and gastrointestinal mucosa as well as in 87 out of 93 neuroendocrine tumours investigated, including pheochromocytomas, chromaffin and non-chromaffin paragangliomas, ganglioneuromas, pituitary adenomas, thyroid medullary carcinomas, parathyroid adenomas, lung carcinoids and neuroendocrine carcinomas, pancreatic and gut endocrine tumours and cutaneous merkelomas. Parallel ultrastructural investigation of synaptophysin-reactive cells and tumours revealed the presence, in addition to dense-cored, secretory granules, of a population of pleomorphic, small, clear vesicles resembling synaptic vesicles of nerve terminals as well as the synaptophysin immunoreactive vesicles already described in rat adrenal medullary and pituitary cells. Synaptophysin immunoreactivity showed several differences in its distribution among tumour and non-tumour endocrine cells when compared to chromogranin A immunoreactivity, a well known marker of the core of endocrine granules. Synaptophysin represents a reliable general marker of neuroendocrine cells and tumours, which may be useful in diagnostic histopathology.},
author = {Zickler, Stefan and Laue, Tim and Birbach, Oliver and Wongphati, Mahisorn and Veloso, Manuela},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-11876-0_37},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zickler et al. - 2010 - SSL-Vision The shared vision system for the RoboCup Small Size League.pdf:pdf},
isbn = {3642118755},
issn = {03029743},
mendeley-groups = {Robotics/TeleWerkBank/Tracking Benches},
pages = {425--436},
title = {{SSL-Vision: The shared vision system for the RoboCup Small Size League}},
volume = {5949 LNAI},
year = {2010}
}
@article{Steinmeyer2014,
author = {Steinmeyer, Simon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Steinmeyer - 2014 - Probabilistische Fahrzeugumfeldsch{\"{a}}tzung f{\"{u}}r Fahrerassistenzsysteme.pdf:pdf},
mendeley-groups = {{\_}STUDENTEN/Julian Exner},
title = {{Probabilistische Fahrzeugumfeldsch{\"{a}}tzung f{\"{u}}r Fahrerassistenzsysteme}},
url = {http://rzbl04.biblio.etc.tu-bs.de:8080/docportal/servlets/MCRFileNodeServlet/DocPortal{\_}derivate{\_}00034752/steinmeyer2014.pdf},
year = {2014}
}
@article{StutzHermansLeibe:2016,
author = {Stutz, David and Hermans, Alexander and Leibe, Bastian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stutz, Hermans, Leibe - 2016 - Superpixels An Evaluation of the State-of-the-Art.pdf:pdf},
journal = {CoRR},
mendeley-groups = {{\_}STUDENTEN/Julian Exner},
title = {{Superpixels: An Evaluation of the State-of-the-Art}},
url = {https://arxiv.org/abs/1612.01601 http://davidstutz.de/projects/superpixel-benchmark/},
volume = {abs/1612.0},
year = {2016}
}
@inproceedings{Elbrechter2011,
abstract = {The ability to manipulate deformable objects, such as textiles or paper, is a major prerequisite to bringing the capabilities of articulated robot hands closer to the level of manual intelligence exhibited by humans. We concentrate on the manipulation of paper, which affords us a rich interaction domain and that has not yet been solved for anthropomorphic robot hands. A key ability needed for this is the robust tracking and modelling of paper under conditions of occlusion and strong deformation. We present a marker based framework that realizes these properties robustly and in real-time. We compare a purely mathematical representation of the paper manifold with a soft-body-physics model and demonstrate the use of our visual tracking method to facilitate the coordination of two anthropomorphic 20 DOF Shadow Dexterous Hands while they grasp a flat-lying piece of paper, using a combination of visually guided bulging and pinching.},
author = {Elbrechter, Christof and Haschke, Robert and Ritter, Helge},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6048348},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elbrechter, Haschke, Ritter - 2011 - Bi-manual robotic paper manipulation based on real-time marker tracking and physical modelling.pdf:pdf},
isbn = {9781612844541},
issn = {2153-0858},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
pages = {1427--1432},
title = {{Bi-manual robotic paper manipulation based on real-time marker tracking and physical modelling}},
year = {2011}
}
@article{Kaltenbrunner2007,
abstract = {This article provides an introductory overview to first-time users of the reacTIVision framework -- an open-source cross-platform computer-vision framework primarily designed for the construction of table-based tangible user interfaces. The central component of the framework is a standalone application for fast and robust tracking of fiducial markers in a real-time video stream. The framework also defines a transport protocol for efficient and reliable transmission of object states via a local or wide area network. In addition, the distribution includes a collection of client example projects for various programming environments that allow the rapid development of unique tangible user interfaces. This article also provides a discussion of key points relevant to the construction of the necessary table hardware and surveys some projects that have been based on this technology.},
author = {Kaltenbrunner, Martin and Bencina, Ross},
doi = {10.1145/1226969.1226983},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kaltenbrunner, Bencina - 2007 - reacTIVision A Computer-Vision Framework for Table-Based Tangible Interaction.pdf:pdf},
isbn = {978-1-59593-619-6},
journal = {Proceedings of the 1st international conference on Tangible and embedded interaction},
keywords = {application development framework,computer vision,tangible user interface},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {69--74},
title = {{reacTIVision: A Computer-Vision Framework for Table-Based Tangible Interaction}},
url = {http://doi.acm.org/10.1145/1226969.1226983},
year = {2007}
}
@article{Aruco2014,
author = {Garrido-Jurado, S and Mu{\~{n}}oz-Salinas, R and Madrid-Cuevas, F J and Mar{\'{i}}n-Jim{\'{e}}nez, M J},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.01.005},
file = {:home/tkorthals/Documents/Mendeley Desktop/Garrido-Jurado et al. - 2014 - Automatic generation and detection of highly reliable fiducial markers under occlusion.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
number = {6},
pages = {2280--2292},
title = {{Automatic generation and detection of highly reliable fiducial markers under occlusion}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320314000235},
volume = {47},
year = {2014}
}
@article{GarridoJurado2015,
author = {Garrido-Jurado, S and Mu{\~{n}}oz-Salinas, R and Madrid-Cuevas, F J and Medina-Carnicer, R},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.09.023},
file = {:home/tkorthals/Documents/Mendeley Desktop/Garrido-Jurado et al. - 2016 - Generation of fiducial marker dictionaries using mixed integer linear programming.pdf:pdf},
issn = {0031-3203},
journal = {Pattern Recognition},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {481--491},
title = {{Generation of fiducial marker dictionaries using mixed integer linear programming}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315003544},
volume = {51},
year = {2016}
}
@article{Fiala2010,
abstract = {Fiducial markers are artificial landmarks added to a scene to facilitate locating point correspondences between images, or between images and a known model. Reliable fiducials solve the interest point detection and matching problems when adding markers is convenient. The proper design of fiducials and the associated computer vision algorithms to detect them can enable accurate pose detection for applications ranging from augmented reality, input devices for HCI, to robot navigation. Marker systems typically have two stages, hypothesis generation from unique image features and verification/identification. A set of criteria for high robustness and practical use are identified and then optimized to produce the ARTag fiducial marker system. An edge-based method robust to lighting and partial occlusion is used for the hypothesis stage, and a reliable digital coding system is used for the identification and verification stage. Using these design criteria large gains in performance are achieved by ARTag over conventional ad hoc designs.},
author = {Fiala, Mark},
doi = {10.1109/TPAMI.2009.146},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fiala - 2010 - Designing highly reliable fiducial markers.pdf:pdf},
isbn = {2008020118},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Augmented reality,Computer vision,Fiducial marker systems},
mendeley-groups = {Vision/Tracking,Vision/Tracking/Fiducial Marker},
number = {7},
pages = {1317--1324},
pmid = {20489233},
title = {{Designing highly reliable fiducial markers}},
volume = {32},
year = {2010}
}
@article{Fiala2004,
abstract = {ARToolkit is a very successful and robust marker system used for Augmented Reality (AR), its robust performance has spawned many applications in AR and computer vision. ARToolkit consists of several 2D planar fiducial marker patterns and software that recognizes and identifies these markers in images. It functions well in finding markers; however its performance with respect to false positive detections and inter-marker confusion could use improvement. Quite often markers are confused for one another of falsely detected in the background. ARToolkit markers consist of a square black border enclosing a pattern that is compared to several stored patterns by correlation. This paper proposes a method to robustify this marker system by replacing this correlation step with a digital symbol method. The interior greyscale pattern is replaced by a digital pattern of 36 bits with contains a unique ID number protected from false detection with the digital code techniques of checksums and forward error correction (FEC). This proposed new system, ARTag has a very low and numerically quantifiable error rate, has a reduced processing item, and can encode up to 2046 different unique Id's with no need to store patterns. Experimental results are shown validating this method.},
author = {Fiala, Mark},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fiala - 2004 - ARTag, An Improved Marker Based System Based on ARToolkit.pdf:pdf},
isbn = {NRC/ERB-1111 NRC 47166},
journal = {System},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
number = {July},
pages = {36},
title = {{ARTag, An Improved Marker Based System Based on ARToolkit}},
url = {http://www.cs.cmu.edu/afs/cs/project/skinnerbots/Wiki/AprilTags/NRC-47166.pdf},
volume = {47166},
year = {2004}
}
@inproceedings{Fiala2005,
abstract = {Fiducial marker systems are systems of unique patterns and computer vision algorithms that help solve the correspondence problem, automatically finding features in different camera images that belong to the same object point in the world. Fiducial marker systems consist of patterns that are mounted in the environment and automatically detected in digital images using an accompanying detection algorithm, useful for augmented reality (AR), robot navigation, 3D modeling, and other applications. This paper compares the two recently developed systems ARTag and ARToolkit Plus on their reliability, detection rates, and immunity to lighting and occlusion. Processing in fiducial systems are defined as two stages, unique feature detection and verification/identification. The systems are compared considering these stages, experimental results are shown.},
author = {Fiala, Mark},
booktitle = {HAVE 2005: IEEE International Workshop on Haptic Audio Visual Environments and their Applications},
doi = {10.1109/HAVE.2005.1545669},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fiala - 2005 - Comparing ARTag and ARToolkit plus fiducial marker systems.pdf:pdf},
isbn = {0780393775},
keywords = {Fiducial marker self-identifying augmented reality},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {148--153},
title = {{Comparing ARTag and ARToolkit plus fiducial marker systems}},
volume = {2005},
year = {2005}
}
@inproceedings{Zhang2002,
abstract = {Visual markers are widely used in existing augmented reality (AR) applications [7, 12, 11, 19].In most of such applications, the performance of an AR system depends highly on the tracking system for visual marker detection, tracking, and pose estimation.Currently, there are more than one marker based tracking/calibration systems available.It is thus desirable for the user to know which marker tracking system is likely to perform the best for a speciﬁc AR application.To this purpose, we compare several marker systems all using planar square coded visual markers.We present the evaluation results, both qualitatively and quantitatively, for the following properties: the usability, efficiency, accuracy, and reliability.For a particular AR application, there are different marker detection and tracking requirements.Therefore, the purpose of this work is not to rank the existing marker systems; instead, we try to analyze the strength and weakness of various aspects of the marker tracking systems and provide the AR application developers with this information.},
author = {Zhang, Xiang and Fronz, Stephan and Navab, Nassir},
booktitle = {Proceedings - International Symposium on Mixed and Augmented Reality, ISMAR 2002},
doi = {10.1109/ISMAR.2002.1115078},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhang, Fronz, Navab - 2002 - Visual marker detection and decoding in AR systems A comparative study.pdf:pdf},
isbn = {0769517811},
issn = {10477039},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {97--106},
title = {{Visual marker detection and decoding in AR systems: A comparative study}},
year = {2002}
}
@article{Claus2004,
abstract = {Reliable detection of fiducial targets in real-world images is addressed in this paper. We show that even the best existing schemes are fragile when exposed to other than laboratory imaging conditions, and introduce an approach which delivers significant improvements in reliability at moderate computational cost. The key to these improvements is in the use of machine learning techniques, which have recently shown impressive results for the general object detection problem, for example in face detection. Although fiducial detection is an apparently simple special case, this paper shows why robustness to lighting, scale and fore- shortening can be addressed within the machine learning framework with greater reliability than previous, more ad-hoc, fiducial detection schemes.},
author = {Claus, David and Fitzgibbon, Andrew W.},
doi = {10.1007/978-3-540-24673-2_38},
file = {:home/tkorthals/Documents/Mendeley Desktop/Claus, Fitzgibbon - 2004 - Reliable Fiducial Detection in Natural Scenes.pdf:pdf},
isbn = {978-3-540-21981-1},
issn = {03029743},
journal = {Proceedings of the 8th European Conference on Computer Vision},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {469--480},
title = {{Reliable Fiducial Detection in Natural Scenes}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-24673-2{\_}38},
volume = {4},
year = {2004}
}
@article{Hirokazu2002,
abstract = {In this paper, I introduce ARToolKit and describe about the structure and what we can do with ARToolKit. ARToolKit is a library which is useful to make vision-based Augmented Reality applications. It is distributed as an open source library. ARToolKit uses black square markers with unique pattern in it and calculates pose and position of the marker. Then virtual objects can be drawn in the marker coordinates and geometrical consistency between real world and the virtual objects is maintained in spite of user's view point.},
author = {Hirokazu, Kato},
issn = {09135685},
journal = {IEIC Technical Report Institute of Electronics Information and Communication Engineers},
mendeley-groups = {Vision/Tracking/Fiducial Marker},
pages = {79--86},
title = {{ARToolKit: Library for Vision-based Augmented Reality.}},
volume = {101},
year = {2002}
}
@article{Elfes1996,
abstract = {This paper proposes an integrated approach to robot navigation that incorporates task-related information needs, perceptual capabilities, robot knowledge metrics and spatial characteristics of the environment into the motion planning process. Autonomous robots are modelled as discrete-time dynamic systems that implement optimal or suboptimal control policies in their choice of appropriate control actions. A stochastic lattice model, the Inference Grid, is used to represent spatially distributed information. Various information metrics are defined to measure the extent, accuracy and complexity of the robot's world model, and to quantify the information needs of a task. A dual control architecture allows the robot to servo on the information required to solve a given task, and employs multi-objective optimization methods to plan the robot's perceptual and motor actions in an integrated manner.},
author = {Elfes, Alberto},
doi = {10.1007/BFb0013955},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elfes - 1996 - Robot navigation Integrating perception, environmental constraints and task execution within a probabilistic framework.pdf:pdf},
isbn = {3540613765},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {Robotics/Maps},
pages = {93--130},
title = {{Robot navigation: Integrating perception, environmental constraints and task execution within a probabilistic framework}},
volume = {1093},
year = {1996}
}
@article{Irwansyah2016,
author = {Irwansyah, Arif and Ibraheem, Omar W and Hagemeyer, Jens and Porrmann, Mario and Rueckert, Ulrich},
file = {:home/tkorthals/Documents/Mendeley Desktop/Irwansyah et al. - 2016 - FPGA-based Multi-Robot Tracking.pdf:pdf},
journal = {Journal of Parallel and Distributed Computing},
mendeley-groups = {Robotics/TeleWerkBank},
pages = {1--43},
title = {{FPGA-based Multi-Robot Tracking}},
year = {2016}
}
@article{Omidshafiei2016,
abstract = {— This paper introduces a probabilistic algorithm for multi-robot decision-making under uncertainty, which can be posed as a Decentralized Partially Observable Markov Decision Process (Dec-POMDP). Dec-POMDPs are inherently synchronous decision-making frameworks which require sig-nificant computational resources to be solved, making them infeasible for many real-world robotics applications. The De-centralized Partially Observable Semi-Markov Decision Process (Dec-POSMDP) was recently introduced as an extension of the Dec-POMDP that uses high-level macro-actions to allow large-scale, asynchronous decision-making. However, existing Dec-POSMDP solution methods have limited scalability or perform poorly as the problem size grows. This paper proposes a cross-entropy based Dec-POSMDP algorithm motivated by the combinatorial optimization literature. The algorithm is applied to a constrained package delivery domain, where it significantly outperforms existing Dec-POSMDP solution methods.},
author = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali Akbar and Amato, Christopher and Liu, Shih Yuan and How, Jonathan P. and Vian, John},
doi = {10.1109/ICRA.2016.7487751},
isbn = {9781467380263},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
title = {{Graph-based Cross Entropy method for solving multi-robot decentralized POMDPs}},
year = {2016}
}
@article{Yehoshua2014,
abstract = {Coverage is a fundamental problem in robotics, where one or more robots are required to visit each point in a target area at least once. While most previous work concentrated on finding a solution that completes the coverage as quickly as possible, in this paper we consider a new version of the problem: adversarial coverage. Here, the robot operates in an environment that contains threats that might stop the robot. We introduce the problem of finding the safest adversarial coverage path, and present different optimization criteria for the evaluation of these paths. We show that finding an optimal solution to the safest coverage problem is NP-Complete. We therefore suggest two heuristic algorithms: STAC, a spanning-tree based coverage algorithm, and GSAC, which follows a greedy approach. These algorithms produce close to optimal solutions in polynomial time. We establish theoretical bounds on the total risk involved in the coverage paths created by these algorithms and on their lengths. Lastly, we compare the effectiveness of these two algorithms in various types of environments and settings.},
author = {Yehoshua, Roi and Agmon, Noa and Kaminka, Gal A.},
doi = {10.1109/IROS.2014.6942980},
isbn = {9781479969340},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
title = {{Safest path adversarial coverage}},
year = {2014}
}
@article{Brechtel2013,
abstract = {Discrete POMDPs of medium complexity can be approximately solved in reasonable time. However, most applications have a continu-ous and thus uncountably infinite state space. We propose the novel concept of learning a discrete representation of the continuous state space to solve the integrals in con-tinuous POMDPs efficiently and generalize sparse calculations over the continuous space. The representation is iteratively refined as part of a novel Value Iteration step and does not depend on prior knowledge. Consistency for the learned generalization is asserted by a self-correction algorithm. The presented con-cept is implemented for continuous state and observation spaces based on Monte Carlo ap-proximation to allow for arbitrary POMDP models. In an experimental comparison it yields higher values in significantly shorter time than state of the art algorithms and solves higher-dimensional problems.},
author = {Brechtel, Sebastian and Gindele, Tobias and Dillmann, R{\"{u}}diger},
journal = {Proceedings of the 30th International Conference on Machine Learning},
title = {{Solving Continuous POMDPs: Value Iteration with Incremental Learning of an Efficient Space Representation}},
year = {2013}
}
@article{Zhang2013,
abstract = {Key challenges to widespread deployment of mobile robots include collaboration and the ability to tailor sensing and information processing to the task at hand. Partially observable Markov decision processes (POMDPs), which are an instance of probabilistic sequential decision-making, can be used to address these challenges in domains characterized by partial observability and nondeterministic action outcomes. However, such formulations tend to be computationally intractable for domains that have large complex state spaces and require robots to respond to dynamic changes. This paper presents a hierarchical decomposition of POMDPs that incorporates adaptive observation functions, constrained convolutional policies, and automatic belief propagation, enabling robots to retain capabilities for different tasks, direct sensing to relevant locations, and determine the sequence of sensing and processing algorithms best suited to any given task. A communication layer is added to the POMDP hierarchy for belief sharing and collaboration in a team of robots. All algorithms are evaluated in simulation and on physical robots, localizing target objects in dynamic indoor domains.},
author = {Zhang, Shiqi and Sridharan, Mohan and Washington, Christian},
doi = {10.1109/TRO.2013.2252252},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
title = {{Active visual planning for mobile robot teams using hierarchical pomdps}},
year = {2013}
}
@article{Bai2014,
abstract = {The partially observable Markov decision process (POMDP) provides a principled mathematical model for integrating perception and planning, a major challenge in robotics. While there are efficient algorithms for moderately large discrete POMDPs, continuous models are often more natural for robotic tasks, and currently there are no practical algorithms that handle continuous POMDPs at an interesting scale. This paper presents an algorithm for continuous-state, continuous-observation POMDPs. We provide experimental results demonstrating its potential in robot planning and learning under uncertainty and a theoretical analysis of its performance. A direct benefit of the algorithm is to simplify model construction.},
author = {Bai, Haoyu and Hsu, David and Lee, Wee Sun},
doi = {10.1177/0278364914528255},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
title = {{Integrated perception and planning in the continuous space: A POMDP approach}},
year = {2014}
}
@article{Viet2015,
abstract = {Online complete coverage is required in many applications, such as in floor cleaning, lawn mowing, mine hunting, and harvesting, and can be performed by single-or multi-robot systems. Motivated by the efficiency and robustness of multi-robot systems, this study proposes a solution to provide online complete coverage through a boustrophedon and backtracking mechanism called the BoB algorithm. This approach designs robots in the system according to a market-based approach. Without a central supervisor, the robots use only local interactions to coordi-nate and construct simultaneously non-overlapping regions in an incremental manner via boustrophedon motion. To achieve complete coverage, that is, the union of all covered regions in the entire accessible area of the workspace, each robot is equipped with an intelligent backtracking mecha- to the closest unvisited region. The robots complete the cov-erage task when no more backtracking points are detected. Computer simulations show that the BoB approach is effi-cient in terms of the coverage rate, the length of the coverage path, and the balance of the workload distribution of robots.},
author = {Viet, Hoang Huu and Dang, Viet Hung and Choi, Seung Yoon and Chung, Tae Choong},
doi = {10.1007/s10489-014-0571-8},
isbn = {0924-669X},
issn = {0924669X},
journal = {Applied Intelligence},
title = {{BoB: an online coverage approach for multi-robot systems}},
year = {2015}
}
@article{AndrewBagnell2014,
abstract = {Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {{Andrew Bagnell}, J.},
doi = {10.1007/978-3-319-03194-1_2},
eprint = {9605103},
isbn = {9783642276446},
issn = {1610742X},
journal = {Springer Tracts in Advanced Robotics},
pmid = {17255001},
primaryClass = {cs},
title = {{Reinforcement Learning in Robotics: A Survey}},
volume = {97},
year = {2014}
}
@inproceedings{Korthals2016a,
abstract = {Diese Ver{\"{o}}ffentlichung befasst sich mit der Analyse und dem Einsatz eines Event-Basierter Systeme zur Datenfusion in der Landtechnik. Eine Ethernet basierte Verbindung stellt die M{\"{o}}glichkeit zur Anbindung von verteilten Rechnersystemen {\"{u}}ber Maschinengrenzen hinweg da. In Kombination mit einer Middleware wird somit ein einheitliches Umgebungsmodel aufgebaut, welches zur Event-Basierten Regelung verwendet wird.},
author = {Korthals, Timo and Skiba, Andreas and Krause, Thilo},
booktitle = {74. Tagung LAND.TECHNIK},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korthals, Skiba, Krause - 2016 - Einsatz Event-Basierter Systemarchitektur f{\"{u}}r Erntemaschinen zur Elektronischen Umfelderkennung.pdf:pdf},
publisher = {VDI e.V.},
title = {{Einsatz Event-Basierter Systemarchitektur f{\"{u}}r Erntemaschinen zur Elektronischen Umfelderkennung}},
year = {2016}
}
@article{Kaiser2013,
author = {Kaiser, M Sc Lydia},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kaiser - 2013 - Modellierungssprachen , Methoden Und Werkzeuge F{\"{u}}r Das Model-Based Systems Engineering.pdf:pdf},
mendeley-groups = {Systems Engineering},
title = {{Modellierungssprachen , Methoden Und Werkzeuge F{\"{u}}r Das Model-Based Systems Engineering}},
year = {2013}
}
@article{IEEE2016,
author = {IEEE},
file = {:home/tkorthals/Documents/Mendeley Desktop/IEEE - 2016 - Robotics {\&} Automation 12.16.pdf:pdf},
journal = {IEEE Robotics {\&} Automation Magazine},
mendeley-groups = {IEEE},
month = {dec},
title = {{Robotics {\&} Automation 12.16}},
year = {2016}
}
@article{IEEE2016a,
author = {IEEE},
file = {:home/tkorthals/Documents/Mendeley Desktop/IEEE - 2016 - Spectrum 12.16.pdf:pdf},
mendeley-groups = {IEEE},
month = {dec},
title = {{Spectrum 12.16}},
year = {2016}
}
@phdthesis{Merten2012,
author = {Merten, Matthias},
file = {:home/tkorthals/Documents/Mendeley Desktop/Merten - 2012 - Design of Interactive Service Robots applying methods of Systems Engineering and Decision Making.pdf:pdf},
mendeley-groups = {Systems Engineering},
pages = {176},
title = {{Design of Interactive Service Robots applying methods of Systems Engineering and Decision Making}},
url = {http://d-nb.info/1024884716/{\%}5Cnhttp://books.google.de/books?id=v6TKMwEACAAJ},
year = {2012}
}
@article{Borenstein1996,
abstract = {This paper presents a very simple, yet very effec-tive method for combining measurements from a gyro with measurements from wheel encoders (odometry). Sensor-fusion of this kind has been done before, usu-ally by means of a statistical model that describes the behavior of the gyro and the behavior of the odometry component. However, because these systems are based on models, they cannot anticipate the unpredictable and potentially "catastrophic" effect of larger bumps or objects occasionally encountered on the floor. By contrast, our method, called Gyrodometry, has been developed based on a careful study of the physical interaction between the ground and the vehicle. We present experimental evidence that non-systematic odometry error sources (such as bumps) impact the vehicle only during very short periods; typically a fraction of a second for each encounter. During these short instances the readings from the gyro and from odometry differ significantly, while in the absence of large non-systematic errors the readings are very similar. Gyrodometry makes use of this observation by using odometry data only C most of the time, while substituting gyro data only during those brief instances during which gyro and odometry data differ substan-tially. This way the ill-effects of gyro drift are almost completely eliminated, and our method can thus make use of inexpensive gyros with large drift rates. Ex-perimental data is presented that demonstrates the effectiveness of this approach.},
author = {Borenstein, J and Feng, L},
doi = {10.1109/ROBOT.1996.503813},
file = {:home/tkorthals/Documents/Mendeley Desktop/Borenstein, Feng - 1996 - Gyrodometry A New Method for Combining Data from Gyros and Odometry in Mobile Robots.pdf:pdf},
isbn = {0-7803-2988-0},
issn = {10504729},
journal = {IEEE International Conference on Robotics and Automation},
mendeley-groups = {Robotics/Odometry},
pages = {423--428},
title = {{Gyrodometry: A New Method for Combining Data from Gyros and Odometry in Mobile Robots}},
year = {1996}
}
@techreport{ImperxIncorporation2005,
author = {{Imperx Incorporation}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Imperx Incorporation - 2005 - IPX CAMERA SERIES - User's Manual.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/Camera},
pages = {1--137},
title = {{IPX CAMERA SERIES - User's Manual}},
year = {2005}
}
@techreport{ImperxIncorporation2005a,
author = {{Imperx Incorporation}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Imperx Incorporation - 2005 - IPX-1M48-G SpecSheet.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/Camera},
title = {{IPX-1M48-G SpecSheet}},
year = {2005}
}
@techreport{DIN1988c,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1988 - Din 5487.pdf:pdf},
mendeley-groups = {Normen},
number = {0007},
pages = {1--6},
title = {{Din 5487}},
year = {1988}
}
@techreport{DIN2007,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2007 - !{\$}i( 1380528.pdf:pdf},
mendeley-groups = {Normen},
number = {November},
title = {!{\$}i(?" 1380528},
year = {2007}
}
@techreport{DIN2008a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2008 - !{\$}K{\_}e 1406066.pdf:pdf},
mendeley-groups = {Normen},
number = {April},
title = {{!{\$}K{\_}e" 1406066}},
year = {2008}
}
@techreport{DIN2008,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2008 - !{\$}k9p 1402245.pdf:pdf},
mendeley-groups = {Normen},
title = {!{\$}k9p" 1402245},
year = {2008}
}
@techreport{DIN2009,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2009 - !{\$}Y'l 1540473.pdf:pdf},
mendeley-groups = {Normen},
number = {September},
title = {{!{\$}Y'l" 1540473}},
year = {2009}
}
@techreport{DIN1992a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1992 - Din 5473.pdf:pdf},
mendeley-groups = {Normen},
number = {0011},
title = {{Din 5473}},
year = {1992}
}
@techreport{DIN1985a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1985 - Din 66 000.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
pages = {5--7},
title = {{Din 66 000}},
year = {1985}
}
@techreport{DIN1983b,
abstract = {Sinnbilder und ihre Anwendung},
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1983 - DIN 66001, Sinnbilder und ihre Anwendung.pdf:pdf},
mendeley-groups = {Normen},
number = {0012},
pages = {1--20},
title = {{DIN 66001, Sinnbilder und ihre Anwendung}},
volume = {6},
year = {1983}
}
@techreport{DIN2009a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2009 - DIN EN 80000-13 - Gr{\"{o}}{\ss}en und Einheiten - Teil 13 Informationswissenschaft und -technik.pdf:pdf},
mendeley-groups = {Normen},
title = {{DIN EN 80000-13 - Gr{\"{o}}{\ss}en und Einheiten - Teil 13: Informationswissenschaft und -technik}},
year = {2009}
}
@techreport{DIN1985,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1985 - 66 261.pdf:pdf},
mendeley-groups = {Normen},
number = {0007},
title = {66 261},
volume = {6},
year = {1985}
}
@techreport{DIN1983,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1983 - Din 5477 1.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
pages = {3--5},
title = {{Din 5477 1}},
year = {1983}
}
@techreport{DIN2011b,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2011 - !{\$}l{\"{U}}n 1739875.pdf:pdf},
mendeley-groups = {Normen},
number = {April},
title = {{!{\$}l{\"{U}}n" 1739875}},
year = {2011}
}
@techreport{DIN1975,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1975 - Gebrauch der W{\"{o}}rter dual, invers, reziprok, {\"{a}}quivalent, komplement{\"{a}}r.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
title = {{Gebrauch der W{\"{o}}rter dual, invers, reziprok, {\"{a}}quivalent, komplement{\"{a}}r}},
year = {1975}
}
@techreport{DIN1977,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1977 - Din 4895(2).pdf:pdf},
mendeley-groups = {Normen},
number = {0004},
pages = {1--4},
title = {{Din 4895}},
year = {1977}
}
@techreport{DIN1983a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1983 - Din 5483.pdf:pdf},
mendeley-groups = {Normen},
number = {0011},
title = {{Din 5483}},
year = {1983}
}
@techreport{DIN5493,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2011 - DIN 5493 - Logarithmische Gr{\"{o}}{\ss}en und Einheiten.pdf:pdf},
mendeley-groups = {Normen},
number = {September 2011},
pages = {1--20},
title = {{DIN 5493 - Logarithmische Gr{\"{o}}{\ss}en und Einheiten}},
year = {2011}
}
@techreport{DIN1994a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1994 - Logarith mische Gr{\"{o}}{\ss}en und Einheiten.pdf:pdf},
mendeley-groups = {Normen},
number = {0008},
title = {{Logarith mische Gr{\"{o}}{\ss}en und Einheiten}},
year = {1994}
}
@techreport{DIN2011,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2011 - !{\$}lo 1732376.pdf:pdf},
mendeley-groups = {Normen},
title = {!{\$}l:o" 1732376},
year = {2011}
}
@techreport{DIN1994,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1994 - DIN 1304-1, Allgemeine Formelzeichen.pdf:pdf},
mendeley-groups = {Normen},
number = {001},
pages = {1--28},
title = {{DIN 1304-1, Allgemeine Formelzeichen}},
volume = {6},
year = {1994}
}
@techreport{DIN1988,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1988 - Elektromagnetisches Feld(2).pdf:pdf},
mendeley-groups = {Normen},
number = {0007},
pages = {1--6},
title = {{Elektromagnetisches Feld}},
year = {1988}
}
@techreport{DIN1982c,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1982 - Din 5483.pdf:pdf},
mendeley-groups = {Normen},
number = {0007},
title = {{Din 5483}},
year = {1982}
}
@techreport{DIN1993,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1993 - Din 13301.pdf:pdf},
mendeley-groups = {Normen},
number = {0014},
title = {{Din 13301}},
year = {1993}
}
@techreport{DIN2000,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2000 - D 2344.pdf:pdf},
mendeley-groups = {Normen},
number = {0012},
pages = {1--17},
title = {{D 2344}},
year = {2000}
}
@techreport{DIN2010,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2010 - !{\$}i{\c{C}}` 1709461.pdf:pdf},
mendeley-groups = {Normen},
number = {August},
pages = {1--2},
title = {{!{\$}i{\c{C}}`" 1709461}},
year = {2010}
}
@techreport{DIN1992,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1992 - DIN 1333 - Zahlenangaben.pdf:pdf},
mendeley-groups = {Normen},
title = {{DIN 1333 - Zahlenangaben}},
year = {1992}
}
@techreport{DIN1984,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1984 - Din 1306.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
pages = {4--5},
title = {{Din 1306}},
year = {1984}
}
@techreport{DIN1978,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1978 - 13 302.pdf:pdf},
mendeley-groups = {Normen},
number = {0014},
title = {13 302},
year = {1978}
}
@techreport{DIN1982,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1982 - Din 13 303.pdf:pdf},
mendeley-groups = {Normen},
number = {0015},
title = {{Din 13 303}},
year = {1982}
}
@techreport{DIN1999,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1999 - Entwurf mathematische Zeichen und Begriffe.pdf:pdf},
mendeley-groups = {Normen},
number = {0014},
title = {{Entwurf mathematische Zeichen und Begriffe}},
year = {1999}
}
@techreport{DIN2010a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2010 - Din 1301-1.pdf:pdf},
mendeley-groups = {Normen},
pages = {1--14},
title = {{Din 1301-1}},
year = {2010}
}
@techreport{DIN1998,
author = {DIN},
booktitle = {Water},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1998 - Deutsche norm.pdf:pdf},
mendeley-groups = {Normen},
number = {0004},
pages = {1--4},
title = {{Deutsche norm}},
year = {1998}
}
@techreport{DIN2011a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2011 - Din 1338.pdf:pdf},
mendeley-groups = {Normen},
title = {{Din 1338}},
year = {2011}
}
@techreport{DIN1994b,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1994 - DIN 5483-3 - Zeitabh{\"{a}}ngige Gr{\"{o}}{\ss}en Teil 3 Komplexe Darstellung sinusf{\"{o}}rmig zeitabh{\"{a}}ngiger Gr{\"{o}}{\ss}en.pdf:pdf},
mendeley-groups = {Normen},
number = {September},
pages = {10},
title = {{DIN 5483-3 - Zeitabh{\"{a}}ngige Gr{\"{o}}{\ss}en Teil 3: Komplexe Darstellung sinusf{\"{o}}rmig zeitabh{\"{a}}ngiger Gr{\"{o}}{\ss}en}},
year = {1994}
}
@techreport{DIN1987,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1987 - DIN{\_}1303{\_}{\_}1987-03.pdf.pdf:pdf},
mendeley-groups = {Normen},
title = {{DIN{\_}1303{\_}{\_}1987-03.pdf}},
year = {1987}
}
@techreport{DIN1988a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1988 - Din 1324.pdf:pdf},
mendeley-groups = {Normen},
number = {0008},
title = {{Din 1324}},
year = {1988}
}
@techreport{DIN1988b,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1988 - Elektromagnetisches Feld.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
title = {{Elektromagnetisches Feld}},
year = {1988}
}
@techreport{DIN2003,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 2003 - ISO 128-1.pdf:pdf},
mendeley-groups = {Normen},
number = {2211},
pages = {1--16},
title = {{ISO 128-1}},
year = {2003}
}
@techreport{DIN1982a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1982 - 13 303.pdf:pdf},
mendeley-groups = {Normen},
number = {0010},
pages = {1--12},
title = {13 303},
year = {1982}
}
@techreport{DIN1986,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1986 - DIN 1341 W{\"{a}}rme{\"{u}}bertragung - Begriffe, Kenngr{\"{o}}{\ss}en.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
pages = {1--3},
title = {{DIN 1341: W{\"{a}}rme{\"{u}}bertragung - Begriffe, Kenngr{\"{o}}{\ss}en}},
year = {1986}
}
@techreport{DIN1977a,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1977 - Din 4895.pdf:pdf},
mendeley-groups = {Normen},
number = {0004},
pages = {1--4},
title = {{Din 4895}},
year = {1977}
}
@techreport{DIN1982b,
author = {DIN},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1982 - Din 1315.pdf:pdf},
mendeley-groups = {Normen},
number = {0005},
pages = {1--3},
title = {{Din 1315}},
year = {1982}
}
@book{Siegwart2004,
abstract = {Mobile robots range from the Mars Pathfinder mission's teleoperated Sojourner to the cleaning robots in the Paris Metro. This text offers students and other interested readers an introduction to the fundamentals of mobile robotics, spanning the mechanical, motor, sensory, perceptual, and cognitive layers the field comprises. The text focuses on mobility itself, offering an overview of the mechanisms that allow a mobile robot to move through a real world environment to perform its tasks, including locomotion, sensing, localization, and motion planning. It synthesizes material from such fields as kinematics, control theory, signal analysis, computer vision, information theory, artificial intelligence, and probability theory. The book presents the techniques and technology that enable mobility in a series of interacting modules. Each chapter treats a different aspect of mobility, as the book moves from low-level to high-level details. It covers all aspects of mobile robotics, including software and hardware design considerations, related technologies, and algorithmic techniques. This second edition has been revised and updated throughout, with 130 pages of new material on such topics as locomotion, perception, localization, and planning and navigation. Problem sets have been added at the end of each chapter. Bringing together all aspects of mobile robotics into one volume, Introduction to Autonomous Mobile Robots can serve as a textbook or a working tool for beginning practitioners. Curriculum developed by Dr. Robert King, Colorado School of Mines, and Dr. James Conrad, University of North Carolina-Charlotte, to accompany the National Instruments LabVIEW Robotics Starter Kit, are available. Included are 13 (6 by Dr. King and 7 by Dr. Conrad) laboratory exercises for using the LabVIEW Robotics Starter Kit to teach mobile robotics concepts.},
address = {Cambridge, Mass.},
author = {Siegwart, Roland and Nourbakhsh, Illah Reza},
file = {:home/tkorthals/Documents/Mendeley Desktop/Siegwart, Nourbakhsh - 2004 - Introduction to Autonomous Mobile Robots.pdf:pdf},
isbn = {9780262015356},
keywords = {Autonomer Roboter,Autonomous robots,Autonomous robots.,Internet resource (url),Mobile robots,Mobile robots.,Robots,Robots autonomes,Robots mobiles},
mendeley-groups = {Robotics},
pages = {453},
publisher = {MIT Press},
title = {{Introduction to Autonomous Mobile Robots}},
volume = {2nd},
year = {2004}
}
@article{Shin1994,
abstract = {This paper surveys the state of the art in real-time computing. It$\backslash$nintroduces basic concepts and identifies key issues in the design of$\backslash$nreal-time systems. Solutions proposed in literature for tackling these$\backslash$nissues are also briefly discussed},
author = {Shin, Kang G. and Ramanathan, Parameswaran},
doi = {10.1109/5.259423},
issn = {15582256},
journal = {Proceedings of the IEEE},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung},
number = {1},
pages = {6--24},
pmid = {16856666},
title = {{Real-Time Computing: A New Discipline of Computer Science and Engineering}},
volume = {82},
year = {1994}
}
@article{Ross2008a,
abstract = {Partially Observable Markov Decision Processes (POMDPs) provide a rich framework for sequential decision-making under uncertainty in stochastic domains. However, solving a POMDP is often intractable except for small problems due to their complexity. Here, we focus on online approaches that alleviate the computational complexity by computing good local policies at each decision step during the execution. Online algorithms gener-ally consist of a lookahead search to find the best action to execute at each time step in an environment. Our objectives here are to survey the various existing online POMDP methods, analyze their properties and discuss their advantages and disadvantages; and to thoroughly evaluate these online approaches in different environments under various met-rics (return, error bound reduction, lower bound improvement). Our experimental results indicate that state-of-the-art online heuristic search methods can handle large POMDP domains efficiently.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ross, St{\'{e}}phane and Pineau, Jo{\"{e}}lle and Paquet, S{\'{e}}bastien and Chaib-draa, Brahim},
doi = {10.1613/jair.2567},
eprint = {NIHMS150003},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ross et al. - 2008 - Online planning algorithms for POMDPs.pdf:pdf},
isbn = {2122633255},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
mendeley-groups = {Robotics/POMDP},
pages = {663--704},
pmid = {19777080},
title = {{Online planning algorithms for POMDPs}},
volume = {32},
year = {2008}
}
@article{Shani2013,
abstract = {The past decade has seen a significant breakthrough in research on solving partially observable Markov decision processes (POMDPs). Where past solvers could not scale beyond perhaps a dozen states, modern solvers can handle complex domains with many thousands of states. This breakthrough was mainly due to the idea of restricting value function computations to a finite subset of the belief space, permitting only local value updates for this subset. This approach, known as point-based value iteration, avoids the exponential growth of the value function, and is thus applicable for domains with longer horizons, even with relatively large state spaces. Many extensions were suggested to this basic idea, focusing on various aspects of the algorithm—mainly the selection of the belief space subset, and the order of value function updates. In this survey, we walk the reader through the fundamentals of point-based value iteration, explaining the main concepts and ideas. Then, we survey the major extensions to the basic algorithm, discussing theirmerits. Finally, we include an extensive empirical analysis using well known benchmarks, in order to shed light on the strengths and limitations of the various approaches.},
author = {Shani, Guy and Pineau, Joelle and Kaplow, Robert},
doi = {10.1007/s10458-012-9200-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shani, Pineau, Kaplow - 2013 - A survey of point-based POMDP solvers.pdf:pdf},
isbn = {1387-2532},
issn = {13872532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {Decision-theoretic planning,Partially observable Markov decision processes,Reinforcement learning},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {1--51},
title = {{A survey of point-based POMDP solvers}},
volume = {27},
year = {2013}
}
@article{Braziunas2003,
abstract = {This is an overview of partially observable Markov decision processes (POMDPs). We describe POMDP value and policy iteration as well as gradient ascent algorithms. The emphasis is on solution methods that work directly in the space of policies.},
author = {Braziunas, Darius},
file = {:home/tkorthals/Documents/Mendeley Desktop/Braziunas - 2003 - POMDP solution methods.pdf:pdf},
journal = {University of Toronto, Tech. Rep},
mendeley-groups = {Robotics/POMDP},
title = {{POMDP solution methods}},
url = {http://www.cs.toronto.edu/{~}darius/papers/POMDP{\_}survey.pdf https://www.techfak.uni-bielefeld.de/{~}skopp/Lehre/STdKI{\_}SS10/POMDP{\_}solution.pdf},
year = {2003}
}
@article{Spaan2004,
abstract = {We present an approximate POMDP solution method for robot planning in partially observable environments. Our algorithm belongs to the family of point-based value iteration solution techniques for POMDPs, in which planning is performed only on a sampled set of reachable belief points. We describe a simple, randomized procedure that performs value update steps that strictly improve the value of all belief points in each step. We demonstrate our algorithm on a robotic delivery task in an office environment and on several benchmark problems, for which we compute solutions that are very competitive to those of state-of-the-art methods in terms of speed and solution quality.},
author = {Spaan, Matthijs T J and Vlassis, Nikos},
doi = {10.1109/ROBOT.2004.1307420},
isbn = {10504729 (ISSN)},
issn = {1050-4729},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
keywords = {Approximation theory,Complex domains,Computational methods,Iterative methods,Mobile robots,Motion planning,Problem solving,Random processes,Robot motion,Robot planning,Solution quality},
mendeley-groups = {Robotics/POMDP},
pages = {2399--2404},
pmid = {1307420},
title = {{A point-based POMDP algorithm for robot planning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-3042527666{\&}partnerID=40},
volume = {3},
year = {2004}
}
@article{Hsu2007,
abstract = {Point-based algorithms have been surprisingly successful in computing approx- imately optimal solutions for partially observable Markov decision processes (POMDPs) in high dimensional belief spaces. In this work, we seek to understand the belief-space properties that allow some POMDP problems to be approximated efficiently and thus help to explain the point-based algorithms' success often ob- served in the experiments. We show that an approximately optimal POMDP so- lution can be computed in time polynomial in the covering number of a reachable belief space, which is the subset of the belief space reachable from a given belief point. We also show that under the weaker condition of having a small covering number for an optimal reachable space, which is the subset of the belief space reachable under an optimal policy, computing an approximately optimal solution is NP-hard. However, given a suitable set of points that “cover” an optimal reach- able space well, an approximate solution can be computed in polynomial time. The covering number highlights several interesting properties that reduce the com- plexity of POMDP planning in practice, e.g., fully observed state variables, beliefs with sparse support, smooth beliefs, and circulant state-transition matrices.},
author = {Hsu, David and Lee, Wee Sun and Rong, Nan},
isbn = {160560352X},
journal = {Advances in Neural Information Processing Systems (NIPS) 20},
mendeley-groups = {Robotics/POMDP},
pages = {689--696},
title = {{What makes some POMDP problems easy to approximate?}},
year = {2007}
}
@book{LaValle2006,
abstract = {This book presents a unified treatment of many different kinds of planning algorithms. The subject lies at the crossroads between robotics, control theory, artificial intelligence, algorithms, and computer graphics. The particular subjects covered include motion planning, discrete planning, planning under uncertainty, sensor-based planning, visibility, decision-theoretic planning, game theory, information spaces, reinforcement learning, nonlinear systems, trajectory planning, nonholonomic planning, and kinodynamic planning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {LaValle, Steven M},
booktitle = {Cambridge University Press},
doi = {10.1017/CBO9780511546877},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/LaValle - 2006 - Planning Algorithms.pdf:pdf},
isbn = {9780511546877},
issn = {1098-6596},
mendeley-groups = {Robotics/POMDP},
pages = {842},
pmid = {25246403},
title = {{Planning Algorithms}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511546877},
volume = {2006},
year = {2006}
}
@article{Cassandra1997,
abstract = {An increasing number of researchers in many ar- eas are becoming interested in the application of the partially observable Markov decision process (pomdp) model to problems with hidden state. This model can account for both state transition and observation uncertainty. The majority of re- cent research interest in the pomdp model has been in the artificial intelligence community and as such, has been applied in a limited range of domains. The main purpose of this paper is show the wider applicability of the model by way of sur- veying the potential application areas for pomdps.},
author = {Cassandra, Anthony R},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cassandra - 1997 - A Survey of POMDP Applications.pdf:pdf},
journal = {Uncertainty in Artificial Intelligence},
mendeley-groups = {Robotics/POMDP},
pages = {472--480},
title = {{A Survey of POMDP Applications}},
year = {1997}
}
@article{Goerzen2010,
abstract = {A fundamental aspect of autonomous vehicle guidance is planning trajectories. Historically, two fields have contributed to trajectory or motion planning methods: robotics and dynamics and control. The former typically have a stronger focus on computational issues and real-time robot control, while the latter emphasize the dynamic behavior and more specific aspects of trajectory performance. Guidance for Unmanned Aerial Vehicles (UAVs), including fixed- and rotary-wing aircraft, involves significant differences from most traditionally defined mobile and manipulator robots. Qualities characteristic to UAVs include non-trivial dynamics, three-dimensional environments, disturbed operating conditions, and high levels of uncertainty in state knowledge. Otherwise, UAV guidance shares qualities with typical robotic motion planning problems, including partial knowledge of the environment and tasks that can range from basic goal interception, which can be precisely specified, to more general tasks like surveillance and reconnaissance, which are harder to specify. These basic planning problems involve continual interaction with the environment. The purpose of this paper is to provide an overview of existing motion planning algorithms while adding perspectives and practical examples from UAV guidance approaches.},
author = {Goerzen, C. and Kong, Z. and Mettler, B.},
doi = {10.1007/s10846-009-9383-1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Goerzen, Kong, Mettler - 2010 - A survey of motion planning algorithms from the perspective of autonomous UAV guidance.pdf:pdf},
isbn = {0921-0296},
issn = {09210296},
journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
keywords = {Algorithm,Autonomous,Complexity,Guidance,Heuristics,Motion planning,Optimization,Trajectory,UAV},
mendeley-groups = {Robotics/POMDP},
number = {1-4},
pages = {65--100},
title = {{A survey of motion planning algorithms from the perspective of autonomous UAV guidance}},
volume = {57},
year = {2010}
}
@techreport{Otte2009,
abstract = {Parameters in robotic systems have traditionally been hand-tuned by human experts through painstaking trail-and-error. In addition to requiring a sub- stantial number of man-hours, hand-tuning usually results in robotic systems that are brittle. That is, they can easily fail in new environments. In the last decade or two, designers have realized that their systems can be made more robust by incorporating concepts developed in the field of machine learning. This paper presents a survey of how machine learning has been applied to robotic path-planning and path-planning related concepts. This},
author = {Otte, Michael Wilson},
file = {:home/tkorthals/Documents/Mendeley Desktop/Otte - 2009 - A Survey of Machine Learning Approaches to Robotic Path-Planning.pdf:pdf},
mendeley-groups = {Robotics/POMDP},
title = {{A Survey of Machine Learning Approaches to Robotic Path-Planning}},
url = {http://www.cs.colorado.edu/{~}mozer/Teaching/Computational Modeling Prelim/Otte.pdf},
year = {2009}
}
@inproceedings{Ocana2005,
abstract = { In this paper we present the low level navigation system carried out in a partially observable Markov decision process (POMDP) based on WiFi and ultrasound observations. We use an H-shape model for the corridor, obtained from ultrasound range sensor. This system leads the robot to follow a corridor while it's detecting transitions for each door in autonomous mode. We demonstrate that this system is useful as low level navigator in a POMDP for indoor environments with a real robot. Some experimental results are shown. Finally, the conclusions and future works are presented.},
author = {Oca{\~{n}}a, M. and Bergasa, L. M. and Sotelo, M. A. and Flores, R.},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
doi = {10.1109/IROS.2005.1545031},
isbn = {0780389123},
keywords = {Autonomous learning system WSLAM,Indoor navigation,Markov process,POMDP,WiFi observation},
mendeley-groups = {Robotics/POMDP},
pages = {503--508},
pmid = {1545031},
title = {{Indoor robot navigation using a POMDP based on WiFi and ultrasound observations}},
year = {2005}
}
@article{Bauerle2011,
abstract = {The sensitivity-based optimization of Markov systems has become an increasingly important area. From the perspective of performance sensitivity analysis, policy-iteration algorithms and gradient estimation methods can be directly obtained for Markov decision processes (MDPs). In this correspondence, the sensitivity-based optimization is extended to average reward partially observable MDPs (POMDPs). We derive the performance-difference and performance-derivative formulas of POMDPs. On the basis of the performance-derivative formula, we present a new method to estimate the performance gradients. From the performance-difference formula, we obtain a sufficient optimality condition without the discounted reward formulation. We also propose a policy-iteration algorithm to obtain a nearly optimal finite-state-controller policy.},
author = {B{\"{a}}uerle, N and Rieder, U},
doi = {10.1109/TSMCB.2008.927711},
isbn = {978-3-642-10676-7},
issn = {1083-4419},
journal = {Markov Decision Processes with Applications to {\ldots}},
mendeley-groups = {Robotics/POMDP},
number = {6},
pages = {1645--1651},
title = {{Partially Observable Markov Decision Processes}},
url = {http://ieeexplore.ieee.org/ielx5/3477/4669532/04625978.pdf?tp={\&}arnumber=4625978{\&}isnumber=4669532{\%}5Cnhttp://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4625978{\&}tag=1{\%}5Cnhttp://www.springerlink.com/index/Q7438U4225P33884.pdf},
volume = {38},
year = {2011}
}
@article{Kaelbling1998,
abstract = {In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (MDPs) and partially observable MDPs (POMDPs). We then outline a novel algorithm for solving POMDPs off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to POMDPs, and of some possibilities for finding approximate solutions. Consider the problem of a robot navigating in a large office building. The robot can move from hallway intersection to intersection and can make local observations of its world. Its actions are not completely reliable, however. Sometimes, when it intends to move, it stays where it is or goes too far; sometimes, when it intends to turn, it overshoots. It has similar problems with observation. Sometimes a corridor looks like a corner; sometimes a T-junction looks like an L-junction. How can such an error-plagued robot navigate, even given a map of the corridors? PII: S 0 0 0 4 -3 7 0 2 (9 8) 0 0 0 2 3 -X 100 L.P. Kaelbling et al. / Artificial Intelligence 101 (1998) 99–134 In general, the robot will have to remember something about its history of actions and observations and use this information, together with its knowledge of the underlying dynamics of the world (the map and other information), to maintain an estimate of its location. Many engineering applications follow this approach, using methods like the Kalman filter [26] to maintain a running estimate of the robot's spatial uncertainty, expressed as an ellipsoid or normal distribution in Cartesian space. This approach will not do for our robot, though. Its uncertainty may be discrete: it might be almost certain that it is in the north-east corner of either the fourth or the seventh floors, though it admits a chance that it is on the fifth floor, as well. Then, given an uncertain estimate of its location, the robot has to decide what actions to take. In some cases, it might be sufficient to ignore its uncertainty and take actions that would be appropriate for the most likely location. In other cases, it might be better for the robot to take actions for the purpose of gathering information, such as searching for a landmark or reading signs on the wall. In general, it will take actions that fulfill both purposes simultaneously.},
author = {Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
doi = {10.1016/S0004-3702(98)00023-X},
isbn = {00043702 (ISSN)},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Partially observable Markov decision processes,Planning,Uncertainty},
mendeley-groups = {Robotics/POMDP},
pages = {99--134},
pmid = {20552381},
title = {{Planning and acting in partially observable stochastic domains}},
volume = {101},
year = {1998}
}
@article{Shatkay2002,
abstract = {Hidden Markov models (HMMs) and partially observable Markov decision$\backslash$nprocesses (POMDPs) provide useful tools for modeling dynamical systems.$\backslash$nThey are particularly useful for representing the topology of environnements$\backslash$nsuch as road networks and office buildings, which are typical for$\backslash$nrobot navigation and planning. The work presented here describes$\backslash$na formal framework for incorporating readily available odometric$\backslash$ninformation and geometrical constraints into both the models and$\backslash$nthe algorithm that learns them. By taking advantage of such information,$\backslash$nlearning HMMs/POMDPs can be made to generate better solutions and$\backslash$nrequire fewer iterations, while being robust in the face of data$\backslash$nreduction. Experimental results, obtained from both simulated and$\backslash$nreal robot data, demonstrate the effectiveness of the approach.},
author = {Shatkay, Hagit and Kaelbling, Leslie Pack},
doi = {10.1613/jair.874},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
mendeley-groups = {Robotics/POMDP},
pages = {167--207},
title = {{Learning geometrically-constrained Hidden Markov models for robot navigation: Bridging the topological-geometrical gap}},
volume = {16},
year = {2002}
}
@inproceedings{Theocharous2001a,
abstract = {We propose and investigate a general framework for hierarchical modeling of partially observable environments, such as office buildings, using hierarchical hidden Markov models (HHMMs). Our main goal is to explore hierarchical modeling as a basis for designing more efficient methods for model construction and usage. As a case study we focus on indoor robot navigation and show how this framework can be used to learn a hierarchy of models of the environment at different levels of spatial abstraction. We introduce the idea of model reuse that can be used to combine already learned models into a larger model. We describe an extension of the HHMM model to includes actions, which we call hierarchical POMDPs, and describe a modified hierarchical Baum-Welch algorithm to learn these models. We train different families of hierarchical models for a simulated and a real world corridor environment and compare them with the standard "flat" representation of the same environment. We show that the hierarchical POMDP approach, combined with model reuse, allows learning hierarchical models that fit the data better and train faster than flat models.},
author = {Theocharous, G},
booktitle = {Proceedings of the 2001 IEEE International Conference on Robotics and Automation},
isbn = {0780364759},
mendeley-groups = {Robotics/POMDP},
pages = {511--516},
title = {{Learning hierarchical observable Markov decision process models for robot navigation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=932601},
year = {2001}
}
@article{Matignon2012,
abstract = {Recent works on multi-agent sequential decision mak- ing using decentralized partially observable Markov de- cision processes have been concerned with interaction- oriented resolution techniques and provide promising results. These techniques take advantage of local inter- actions and coordination. In this paper, we propose an approach based on an interaction-oriented resolution of decentralized decision makers. To this end, distributed value functions (DVF) have been used by decoupling the multi-agent problem into a set of individual agent problems. However existing DVF techniques assume permanent and free communication between the agents. In this paper, we extend the DVF methodology to ad- dress full local observability, limited share of informa- tion and communication breaks.We apply our newDVF in a real-world application consisting of multi-robot ex- ploration where each robot computes locally a strategy that minimizes the interactions between the robots and maximizes the space coverage of the team even under communication constraints. Our technique has been im- plemented and evaluated in simulation and in real-world scenarios during a robotic challenge for the exploration and mapping of an unknown environment. Experimen- tal results from real-world scenarios and from the chal- lenge are given where our system was vice-champion.},
author = {Matignon, L and Jeanpierre, Laurent and Mouaddib, AI},
isbn = {9781577355687},
journal = {Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence Coordinated},
mendeley-groups = {Robotics/POMDP},
pages = {2017--2023},
title = {{Coordinated Multi-Robot Exploration Under Communication Constraints Using Decentralized Markov Decision Processes.}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/download/5038/5366},
year = {2012}
}
@article{Theocharous2001,
abstract = {We propose and investigate a general framework for hierarchical modeling of partially observable environments, such as office buildings, using Hierarchical Hidden Markov Models (HHMMs). Our main goal is to explore hierarchical modeling as a basis for designing more efficient methods for model construction and useage. As a case study we focus on indoor robot navigation and show how this framework can be used to learn a hierarchy of models of the environment at different levels of spatial abstraction. We introduce the idea of model reuse, that can be used to combine already learned models into a larger model. We describe an extension of the HHMM model to includes actions, which we call hierarchical POMDPs, and describe a modified hierarchical Baum-Welch algorithm to learn these models. We train different families of hierarchical models for a simulated and a real world corridor environment and compare them with the standard "flat" representation of the same environment. We show that the hierarchical POMDP approach, combined with model reuse, allows learning hierarchical models that fit the data better and train faster than flat models.},
author = {Theocharous, G and Rohanimanesh, K and Mahadevan, S},
isbn = {1050-4729},
journal = {2001 Ieee International Conference on Robotics and Automation, Vols I-Iv, Proceedings},
mendeley-groups = {Robotics/POMDP},
pages = {511--516},
title = {{Learning hierarchical partially observable Markov decision process models for robot navigation}},
year = {2001}
}
@article{Theocharous2004,
abstract = {We explore the advantages of representing hier- archical partially observable Markov decision processes (H- POMDPs) as dynamic Bayesian networks (DBNs). In particular, we focus on the special case of using H-POMDPs to represent multi-resolution spatial maps for indoor robot navigation. Our results show that a DBN representation of H-POMDPs can train significantly faster than the original learning algorithm for H- POMDPs or the equivalent flat POMDP, and requires much less data. In addition, the DBN formulation can easily be extended to parameter tying and factoring of variables, which further reduces the time and sample complexity. This enables us to apply H-POMDP methods to much larger problems than previously possible. I.},
author = {Theocharous, Georgios and Murphy, Kevin and Kaelbling, Leslie},
doi = {10.1109/ROBOT.2004.1307288},
isbn = {0-7803-8232-3},
issn = {1050-4729},
journal = {International Conference on Robotics and Automation},
mendeley-groups = {Robotics/POMDP},
pages = {1045--1051},
title = {{Representing hierarchical POMDPs as DBNs for multi-scale robot localization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1307288},
year = {2004}
}
@article{Dai2013,
abstract = {Crowdsourcing, outsourcing of tasks to a crowd of unknown people ("workers") in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers ("requesters") for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost. {\textcopyright} 2013 Elsevier B.V.},
author = {Dai, Peng and Lin, Christopher H. and Mausam and Weld, Daniel S.},
doi = {10.1016/j.artint.2013.06.002},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Crowdsourcing,POMDP,Partially-Observable Markov Decision,Planning under uncertainty,Process},
mendeley-groups = {Robotics/POMDP},
pages = {52--85},
title = {{POMDP-based control of workflows for crowdsourcing}},
volume = {202},
year = {2013}
}
@inproceedings{Cassandra1996,
abstract = {Discrete Bayesian models have been used to model uncertainty for mobile-robot navigation, but the question of how actions should be chosen remains largely unexplored. This paper presents the optimal solution to the problem, formulated as a partially observable Markov decision process. Since solving for the optimal control policy is intractable, in general, it goes on to explore a variety of heuristic control strategies. The control strategies are compared experimentally, both in simulation and in runs on a robot},
author = {Cassandra, A.R. and Kaelbling, L.P. and Kurien, J.a.},
booktitle = {Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96},
doi = {10.1109/IROS.1996.571080},
isbn = {0-7803-3213-X},
issn = {078033213X},
mendeley-groups = {Robotics/POMDP},
pages = {963--972},
title = {{Acting under uncertainty: discrete Bayesian models for mobile-robot navigation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=571080},
volume = {2},
year = {1996}
}
@article{Rao2010a,
abstract = {A fundamental problem faced by animals is learning to select actions based on noisy sensory information and incomplete knowledge of the world. It has been suggested that the brain engages in Bayesian inference during perception but how such probabilistic representations are used to select actions has remained unclear. Here we propose a neural model of action selection and decision making based on the theory of partially observable Markov decision processes (POMDPs). Actions are selected based not on a single "optimal" estimate of state but on the posterior distribution over states (the "belief" state). We show how such a model provides a unified framework for explaining experimental results in decision making that involve both information gathering and overt actions. The model utilizes temporal difference (TD) learning for maximizing expected reward. The resulting neural architecture posits an active role for the neocortex in belief computation while ascribing a role to the basal ganglia in belief representation, value computation, and action selection. When applied to the random dots motion discrimination task, model neurons representing belief exhibit responses similar to those of LIP neurons in primate neocortex. The appropriate threshold for switching from information gathering to overt actions emerges naturally during reward maximization. Additionally, the time course of reward prediction error in the model shares similarities with dopaminergic responses in the basal ganglia during the random dots task. For tasks with a deadline, the model learns a decision making strategy that changes with elapsed time, predicting a collapsing decision threshold consistent with some experimental studies. The model provides a new framework for understanding neural decision making and suggests an important role for interactions between the neocortex and the basal ganglia in learning the mapping between probabilistic sensory representations and actions that maximize rewards.},
author = {Rao, Rajesh P N},
doi = {10.3389/fncom.2010.00146},
isbn = {1662-5188 (Electronic)$\backslash$n1662-5188 (Linking)},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {basal ganglia,bayesian inference,decision theory,dopamine,parietal cortex,probabilistic models,reinforcement learning,temporal difference learning},
mendeley-groups = {Robotics/POMDP},
number = {November},
pages = {146},
pmid = {21152255},
title = {{Decision making under uncertainty: a neural model based on partially observable markov decision processes.}},
volume = {4},
year = {2010}
}
@article{Littman2009,
abstract = {The partially observable Markov decision process (POMDP) model of environments was first explored in the engineering and operations research communities 40??years ago. More recently, the model has been embraced by researchers in artificial intelligence and machine learning, leading to a flurry of solution algorithms that can identify optimal or near-optimal behavior in many environments represented as POMDPs. The purpose of this article is to introduce the POMDP model to behavioral scientists who may wish to apply the framework to the problem of understanding normative behavior in experimental settings. The article includes concrete examples using a publicly-available POMDP solution package. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Littman, Michael L.},
doi = {10.1016/j.jmp.2009.01.005},
isbn = {00222496},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
keywords = {Markov processes,POMDP,Planning under uncertainty},
mendeley-groups = {Robotics/POMDP},
number = {3},
pages = {119--125},
title = {{A tutorial on partially observable Markov decision processes}},
volume = {53},
year = {2009}
}
@article{Zhang2009,
abstract = {This paper presents a novel framework for studying partially observable Markov decision processes ({\{}POMDPs{\}}) with finite state, action, observation sets, and discounted rewards. The new framework is solely based on future-reward vectors associated with future policies, which is more parsimonious than the traditional framework based on belief vectors. It reveals the connection between the {\{}POMDP{\}} problem and two computational geometry problems, i.e., finding the vertices of a convex hull and finding the Minkowski sum of convex polytopes, which can help solve the {\{}POMDP{\}} problem more efficiently. The new framework can clarify some existing algorithms over both finite and infinite horizons and shed new light on them. It also facilitates the comparison of {\{}POMDPs{\}} with respect to their degree of observability, as a useful structural result.},
author = {Zhang, Hao},
doi = {10.1287/opre.1090.0697},
isbn = {0030-364X},
issn = {0030-364X},
journal = {Operations Research},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {214--228},
title = {{Partially Observable Markov Decision Processes: A Geometric Technique and Analysis}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0697},
volume = {58},
year = {2009}
}
@article{Chong2009,
abstract = {Adaptive sensing involves actively managing sensor resources to achieve a sensing task, such as object detection, classification, and tracking, and represents a promising direction for new applications of discrete event system methods. We describe an approach to adaptive sensing based on approximately solving a partially observable Markov decision process (POMDP) formulation of the problem. Such approximations are necessary because of the very large state space involved in practical adaptive sensing problems, precluding exact computation of optimal solutions. We review the theory of POMDPs and show how the theory applies to adaptive sensing problems. We then describe a variety of approximation methods, with examples to illustrate their application in adaptive sensing. The examples also demonstrate the gains that are possible from nonmyopic methods relative to myopic methods, and highlight some insights into the dependence of such gains on the sensing resources and environment.},
author = {Chong, Edwin K. P. and Kreucher, Christopher M. and Hero, Alfred O.},
doi = {10.1007/s10626-009-0071-x},
isbn = {978-1-4244-2592-1},
issn = {0924-6703},
journal = {Discrete Event Dynamic Systems},
keywords = {and by darpa under,and conclusions or recommendations,any opinions,are,award fa8750-05-2-0285,expressed in this publication,findings,force office of scientific,in part upon work,markov decision process,pomdp,research under award fa9550-06-1-0324,scheduling,sensing,supported by the air,this material is based,tracking},
mendeley-groups = {Robotics/POMDP},
number = {3},
pages = {377--422},
title = {{Partially Observable Markov Decision Process Approximations for Adaptive Sensing}},
volume = {19},
year = {2009}
}
@article{Simmons1995,
abstract = {Autonomous mobile robots need very reliable navigation capabilities in order to operate unattended for long periods of time. This paper reports on first results of a research program that uses partially observable Markov models to robustly track a robot's location in office environments and to direct its goal-oriented actions. The approach explicitly maintains a probability distribution over the possible locations of the robot, taking into account various sources of uncertainty, including approximate knowledge of the environment, and actuator and sensor uncertainty. A novel feature of our approach is its integration of topological map information with approximate metric information. We demonstrate the robustness of this approach in controlling an actual indoor mobile robot navigating corridors.},
author = {Simmons, Reid and Koenig, Sven},
doi = {10.1.1.44.2639},
file = {:home/tkorthals/Documents/Mendeley Desktop/Simmons, Koenig - 1995 - Probabilistic Robot Navigation in Partially Observable Environments.pdf:pdf},
isbn = {1045-0823},
issn = {1045-0823},
journal = {Proceedings of the 1995 International Joint Conference on Artificial Intelligence (IJCAI)},
mendeley-groups = {Robotics/POMDP},
pages = {1080--1087},
title = {{Probabilistic Robot Navigation in Partially Observable Environments}},
url = {http://dl.acm.org/citation.cfm?id=1643031.1643040},
year = {1995}
}
@article{Foka2010,
abstract = {This paper considers the problem of autonomous robot navigation in dynamic and congested environments. The predictive navigation paradigm is proposed where probabilistic planning is integrated with obstacle avoidance along with future motion prediction of humans and/or other obstacles. Predictive navigation is performed in a global manner with the use of a hierarchical Partially Observable Markov Decision Process (POMDP) that can be solved online at each time step and provides the actual actions the robot performs. Obstacle avoidance is performed within the predictive navigation model with a novel approach by deciding paths to the goal position that are not obstructed by other moving objects movement with the use of future motion prediction and by enabling the robot to increase or decrease its speed of movement or by performing detours. The robot is able to decide which obstacle avoidance behavior is optimal in each case within the unified navigation model employed. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract).},
author = {Foka, Amalia F. and Trahanias, Panos E.},
doi = {10.1007/s12369-009-0037-z},
isbn = {1875-4791$\backslash$r1875-4805},
issn = {18754791},
journal = {International Journal of Social Robotics},
keywords = {Motion prediction,Navigation,Obstacle avoidance,POMDPS,Path planning},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {79--94},
title = {{Probabilistic Autonomous Robot Navigation in Dynamic Environments with Human Motion Prediction}},
volume = {2},
year = {2010}
}
@article{Doshi2009,
abstract = {The Partially Observable Markov Decision Process (POMDP) framework has proven useful in planning domains where agents must balance actions that provide knowledge and actions that provide reward. Unfortunately, most POMDPs are complex structures with a large number of parameters. In many real-world problems, both the structure and the parameters are difficult to specify from domain knowledge alone. Recent work in Bayesian reinforcement learning has made headway in learning POMDP models; however, this work has largely focused on learning the parameters of the POMDP model. We define an infinite POMDP (iPOMDP) model that does not require knowledge of the size of the state space; instead, it assumes that the number of visited states will grow as the agent explores its world and only models visited states explicitly. We demonstrate the iPOMDP's utility on several standard problems.},
author = {Doshi, Finale},
journal = {ReCALL},
keywords = {learning,statistics {\&} optimisation,theory {\&} algorithms},
mendeley-groups = {Robotics/POMDP},
pages = {1--9},
title = {{The Infinite Partially Observable Markov Decision Process}},
url = {http://eprints.pascal-network.org/archive/00006513/},
volume = {22},
year = {2009}
}
@article{Kurniawati2008,
abstract = {Motion planning in uncertain and dynamic environments is an essential capability for autonomous robots. Partially observable Markov decision processes (POMDPs) provide a principled mathematical framework for solving such problems, but they are often avoided in robotics due to high computational complexity. Our goal is to create practical POMDP algorithms and software for common robotic tasks. To this end, we have developed a new point-based POMDP algorithm that exploits the notion of optimally reachable belief spaces to improve computational efﬁciency. In simulation, we successfully applied the algorithm to a set of common robotic tasks, including instances of coastal navigation, grasping, mobile robot exploration, and target tracking, all modeled as POMDPs with a large number of states. In most of the instances studied, our algorithm substantially outperformed one of the fastest existing point-based algorithms. A software package implementing our algorithm will soon be released at http://motion.comp.nus.edu.sg/ projects/pomdp/pomdp.html.},
author = {Kurniawati, Hanna and Hsu, David and Lee, Wee Sun},
isbn = {9780262513098},
issn = {2330765X},
journal = {Proceedings of Robotics: Science and Systems IV},
mendeley-groups = {Robotics/POMDP},
pages = {w/o page numbers},
title = {{SARSOP : Efficient Point-Based POMDP Planning by Approximating Optimally Reachable Belief Spaces}},
url = {https://www1.comp.nus.edu.sg/{~}leews/publications/rss08.pdf{\%}5Cnhttp://www.roboticsproceedings.org/rss04/p9.html},
year = {2008}
}
@article{Balch1998,
abstract = {New reactive behaviors that implement formations in multirobot$\backslash$nteams are presented and evaluated. The formation behaviors are$\backslash$nintegrated with other navigational behaviors to enable a robotic team to$\backslash$nreach navigational goals, avoid hazards and simultaneously remain in$\backslash$nformation. The behaviors are implemented in simulation, on robots in the$\backslash$nlaboratory and aboard DARPA's HMMWV-based unmanned ground vehicles. The$\backslash$ntechnique has been integrated with the autonomous robot architecture$\backslash$n(AuRA) and the UGV Demo II architecture. The results demonstrate the$\backslash$nvalue of various types of formations in autonomous, human-led and$\backslash$ncommunications-restricted applications, and their appropriateness in$\backslash$ndifferent types of task environments},
author = {Balch, Tucker and Arkin, Ronald C.},
doi = {10.1109/70.736776},
isbn = {1042-296X},
issn = {1042296X},
journal = {IEEE Transactions on Robotics and Automation},
keywords = {Autonomous robots,Behavior-based control,Robot formation},
mendeley-groups = {Robotics/POMDP},
number = {6},
pages = {926--939},
title = {{Behavior-based formation control for multirobot teams}},
volume = {14},
year = {1998}
}
@article{Madani1999,
abstract = {We investigate the computability of problems in probabilistic planning and partially observable infinite-horizon Markov decision processes. The undecidability of the string-existence problem for probabilistic finite automata is adapted to show that the following problem of plan existence in probabilistic planning is undecidable: given a probabilistic planning problem, determine whether there exists a plan with success probability exceeding a desirable threshold. Analogous policy-existence problems for partially observable infinite-horizon Markov decision processes under discounted and undiscounted total reward models, average-reward models, and state-avoidance models are all shown to be undecidable. The results apply to corresponding approximation problems as well.},
author = {Madani, Omid and Hanks, Steve and Condon, Anne},
doi = {10.1.1.31.3526},
isbn = {0262511061 (ISBN)},
journal = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {Approximation theory Automata theory Computability},
mendeley-groups = {Robotics/POMDP},
number = {Littman 1997},
pages = {541--548},
title = {{On the undecidability of probabilistic planning and infinite-horizon partially observable Markov decision problems}},
url = {internal-pdf://madanietal{\_}aaai1999-2434471431/MadaniETAL{\_}AAAI1999.pdf LB  - MadaniETAL.AAAI1999{\%}5Cnhttp://www.scopus.com/inward/record.url?eid=2-s2.0-0032596468{\&}partnerID=40},
year = {1999}
}
@misc{Rao2010,
abstract = {A fundamental problem faced by animals is learning to select actions based on noisy sensory information and incomplete knowledge of the world. It has been suggested that the brain engages in Bayesian inference during perception but how such probabilistic representations are used to select actions has remained unclear. Here we propose a neural model of action selection and decision making based on the theory of partially observable Markov decision processes (POMDPs). Actions are selected based not on a single “optimal” estimate of state but on the posterior distribution over states (the “belief” state). We show how such a model provides a unified framework for explaining experimental results in decision making that involve both information gathering and overt actions. The model utilizes temporal difference (TD) learning for maximizing expected reward. The resulting neural architecture posits an active role for the neocortex in belief computation while ascribing a role to the basal ganglia in belief representation, value computation, and action selection. When applied to the random dots motion discrimination task, model neurons representing belief exhibit responses similar to those of LIP neurons in primate neocortex. The appropriate threshold for switching from information gathering to overt actions emerges naturally during reward maximization. Additionally, the time course of reward prediction error in the model shares similarities with dopaminergic responses in the basal ganglia during the random dots task. For tasks with a deadline, the model learns a decision making strategy that changes with elapsed time, predicting a collapsing decision threshold consistent with some experimental studies. The model provides a new framework for understanding neural decision making and suggests an important role for interactions between the neocortex and the basal ganglia in learning the mapping between probabilistic sensory representations and actions that maximize rewards.},
author = {Rao, Radesh P. N.},
booktitle = {Frontiers in computational neuroscience},
doi = {10.3389/fncom.2010.00146},
isbn = {1662-5188 (Electronic)$\backslash$n1662-5188 (Linking)},
issn = {1662-5188},
keywords = {Bayesian inference,basal ganglia,decision theory,dopamine,parietal cortex,probabilistic models,reinforcement learning,temporal difference learning},
mendeley-groups = {Robotics/POMDP},
pages = {18},
pmid = {21152255},
title = {{Decision making under uncertainty: a neural model based on partially observable Markov decision processes}},
url = {http://www.frontiersin.org/computational{\_}neuroscience/10.3389/fncom.2010.00146/abstract},
year = {2010}
}
@inproceedings{Ross2008,
abstract = {We consider the problem of optimal control in continuous and partially observable environments when the parameters of the model are not known exactly. Partially Observable Markov Decision Processes (POMDPs) provide a rich mathematical model to handle such environments but require a known model to be solved by most approaches. This is a limitation in practice as the exact model parameters are often difficult to specify exactly. We adopt a Bayesian approach where a posterior distribution over the model parameters is maintained and updated through experience with the environment. We propose a particle filter algorithm to maintain the posterior distribution and an online planning algorithm, based on trajectory sampling, to plan the best action to perform under the current posterior. The resulting approach selects control actions which optimally trade-off between 1) exploring the environment to learn the model, 2) identifying the system's state, and 3) exploiting its knowledge in order to maximize long-term rewards. Our preliminary results on a simulated robot navigation problem show that our approach is able to learn good models of the sensors and actuators, and performs as well as if it had the true model. {\textcopyright}2008 IEEE.},
author = {Ross, St{\'{e}}phane and Chaib-draa, Brahim and Pineau, Joelle},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2008.4543641},
isbn = {9781424416479},
issn = {10504729},
mendeley-groups = {Robotics/POMDP},
pages = {2845--2851},
title = {{Bayesian reinforcement learning in continuous POMDPs with application to robot navigation}},
year = {2008}
}
@article{Ragi2013,
abstract = {A path-planning algorithm to guide unmanned aerial vehicles (UAVs) for tracking multiple ground targets based on the theory of partially observable Markov decision processes (POMDPs) is presented. A variety of features of interest are shown to be easy to incorporate into the framework by plugging in the appropriate models, which demonstrates the power and flexibility of the POMDP framework. Specifically, it is shown how to incorporate the following features by appropriately formulating the POMDP action space, transition law, and objective function: 1) control UAVs with both forward acceleration and bank angle subject to constraints; 2) account for the effect of wind disturbance on UAVs; 3) avoid collisions between UAVs and obstacles and among UAVs; 4) track targets while evading threats; 5) track evasive targets; and 6) mitigate track swaps.},
author = {Ragi, Shankarachary and Chong, Edwin K P},
doi = {10.1109/TAES.2013.6621824},
issn = {00189251},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
mendeley-groups = {Robotics/POMDP},
number = {4},
pages = {2397--2412},
title = {{UAV path planning in a dynamic environment via partially observable markov decision process}},
volume = {49},
year = {2013}
}
@article{Monahan1982,
abstract = {Models and algorithms concerning partially observable Markov decision processes (POMDPs), which are generalizations of Markov decision processes that allow for uncertainty regarding the state of a Markov process and for state information acquisition, are surveyed. A general framework is presented for finite state and action POMDPs. The development of POMDPs and their relationship with other decision processes is briefly discussed. A wide variety of models in fields such as quality control, machine maintenance, internal auditing, learning, and optimal stopping are dealt with within the POMDP-framework. Finally, algorithms for calculating optimal solutions to POMDPs are presented. It is concluded that, although a partially observable process is not Markovian (in general), the POMDP can be formulated as a Markov decision process with an enlarged state space, specifically the space of probability distributions over the underlying (partially observable) states.},
author = {Monahan, George E.},
doi = {10.2307/2631070},
isbn = {00251909 (ISSN)},
issn = {0025-1909},
journal = {Management Science},
keywords = {MARKOV DECISION PROCESSES,PARTIALLY OBSERVABLE,SURVEY},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {1--16},
pmid = {7357551},
title = {{A Survey of Partially Observable Markov Decision Processes: Theory, Models, and Algorithms}},
volume = {28},
year = {1982}
}
@misc{Lopez2005,
abstract = {Assistant robots have received special attention from the research community in the last years. One of the main applications of these robots is to perform care tasks in indoor environments such as houses, nursing homes or hospitals, and therefore they need to be able to navigate robustly for long periods of time. This paper focuses on the navigation system of SIRA, a robotic assistant for elderly and/or blind people based on a Partially Observable Markov Decision Process (POMDP) to global localize the robot and to direct its goal-oriented actions. The main novel feature of our approach is that it combines sonar and visual information in a natural way to produce state transitions and observations in the framework of Markov Decision Processes. Besides this multisensorial fusion, a two-level layered planning architecture that combines several planning objectives (such as guiding to a goal room and reducing locational uncertainty) improves the robustness of the navigation system, as its shown in our experiments with SIRA navigating corridors.},
author = {L{\'{o}}pez, Mar{\'{i}}a Elena and Bergasa, Luis Miguel and Barea, Rafael and Escudero, Mar{\'{i}}a Soledad},
booktitle = {Autonomous Robots},
doi = {10.1007/s10514-005-0607-3},
issn = {09295593},
keywords = {Assistant robots,Multisensorial fusion,Partially Observable Markov Decision Processes,Planning under uncertainty,Probabilistic navigation},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {67--87},
title = {{A navigation system for assistant robots using visually augmented POMDPs}},
volume = {19},
year = {2005}
}
@article{Monahan1982a,
abstract = {This paper surveys models and algorithms dealing with partially observable Markov decision processes. A partially observable Markov decision process (POMDP) is a generaliza- tion of a Markov decision process which permits uncertainty regarding the state of a Markov process and allows for state information acquisition. A general framework for finite state and action POMDP's is presented. Next, there is a brief discussion of the development of POMDP's and their relationship with other decision processes. A wide range of models in such areas as quality control, machine maintenance, internal auditing, learning, and optimal stopping are discussed within the POMDP-framework. Lastly, algorithms for computing optimal},
author = {Monahan, George},
journal = {Management Science},
mendeley-groups = {Robotics/POMDP},
number = {1},
pages = {1--16},
title = {{A survey of partially observable markov decision processes: theory, models, and algorithms}},
url = {http://www.jstor.org/stable/2631070},
volume = {28},
year = {1982}
}
@article{Koenig1998,
abstract = {Autonomous mobile robots need very reliable navigation capabilities in order to operate unattended for long periods of time. We present a technique for achieving this goal that uses partially observable Markov decision process models (POMDPs) to explicitly model navigation uncertainty, including actuator and sensor uncertainty and approximate knowledge of the environment. This allows the robot to maintain a probability distribution over its current pose. Thus, while the robot rarely knows exactly where it is, it always has some belief as to what its true pose is, and is never completely lost. We present a navigation architecture based on POMDPs that provides a uniform framework with an established theoretical foundation for pose estimation, path planning, robot control during navigation, and learning. Our experiments show that this architecture indeed leads to robust corridor navigation for an actual indoor mobile robot.},
author = {Koenig, Sven and Simmons, Reid G.},
doi = {10.1.1.130.5088},
file = {:home/tkorthals/Documents/Mendeley Desktop/Koenig, Simmons - 1998 - Xavier A Robot Navigation Architecture Based on Partially Observable Markov Decision Process Models.pdf:pdf},
isbn = {0-262-61137-6},
journal = {Artificial Intelligence Based Mobile Robotics: Case Studies of Successful Robot Systems},
mendeley-groups = {Robotics/POMDP},
pages = {91--122},
title = {{Xavier : A Robot Navigation Architecture Based on Partially Observable Markov Decision Process Models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.130.5088},
year = {1998}
}
@article{Amato2013,
abstract = {Markov decision processes (MDPs) are often used to model sequential decision problems involving uncertainty un- der the assumption of centralized control. However, many large, distributed systems do not permit centralized control due to communication limitations (such as cost, latency or corruption). This paper surveys recent work on decentralized control of MDPs in which control of each agent depends on a partial view of the world.We focus on a general framework where there may be uncertainty about the state of the environment, represented as a decentralized partially observable MDP (Dec-POMDP), but consider a number of subclasses with different assumptions about uncertainty and agent independence. In these models, a shared objective function is used, but plans of action must be based on a partial view of the environment. We describe the frameworks, along with the complexity of optimal control and important properties.We also provide an overview of exact and approximate solution methods as well as relevant applications. This survey provides an introduction to what has become an active area of research on these models and their solutions.},
archivePrefix = {arXiv},
arxivId = {1502.06030},
author = {Amato, Christopher and Chowdhary, Girish and Geramifard, Alborz and Ure, N Kemal and Kochenderfer, Mykel J},
doi = {10.1109/CDC.2013.6760239},
eprint = {1502.06030},
isbn = {9781467357173},
issn = {0743-1546},
journal = {52nd IEEE COnference on Decision and Control},
mendeley-groups = {Robotics/POMDP},
pages = {2398--2405},
title = {{Decentralized Control of Partially Observable Markov Decision Processes}},
year = {2013}
}
@article{Foka2007,
abstract = {This paper proposes a new hierarchical formulation of POMDPs for autonomous robot navigation that can be solved in real-time, and is memory efficient. It will be referred to in this paper as the Robot Navigation-Hierarchical POMDP (RN-HPOMDP). The RN-HPOMDP is utilized as a unified framework for autonomous robot navigation in dynamic environments. As such, it is used for localization, planning and local obstacle avoidance. Hence, the RN-HPOMDP decides at each time step the actions the robot should execute, without the intervention of any other external module for obstacle avoidance or localization. Our approach employs state space and action space hierarchy, and can effectively model large environments at a fine resolution. Finally, the notion of the reference POMDP is introduced. The latter holds all the information regarding motion and sensor uncertainty, which makes the proposed hierarchical structure memory efficient and enables fast learning. The RN-HPOMDP has been experimentally validated in real dynamic environments. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Foka, Amalia and Trahanias, Panos},
doi = {10.1016/j.robot.2007.01.004},
isbn = {0921-8890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Hierarchical POMDP,Partially observable Markov decision processes (PO,Robot navigation},
mendeley-groups = {Robotics/POMDP},
number = {7},
pages = {561--571},
title = {{Real-time hierarchical POMDPs for autonomous robot navigation}},
volume = {55},
year = {2007}
}
@article{Theocharous2002,
abstract = {We propose and investigate a planning framework based on the Hierarchical Partially Observable Markov Decision Process model (HPOMDP), and apply it to robot navigation. We show how this framework can be used to produce more robust plans as compared to flat models such as Partially Observable Markov Decision Processes (POMDPs). In our approach the environment is modeled at different levels of resolution, where abstract states represent both spatial and temporal abstraction. We test our hierarchical POMDP approach using a large simulated and real navigation environment. The results show that the robot is more successful in navigating to goals starting with no positional knowledge (uniform Initial belief state distribution) using the hierarchical POMDP framework as compared to the flat POMDP approach.},
author = {Theocharous, G and Mahadevan, S},
journal = {2002 Ieee International Conference on Robotics and Automation, Vols I-Iv, Proceedings},
mendeley-groups = {Robotics/POMDP},
pages = {1347--1352},
title = {{Approximate planning with hierarchical partially Observable Markov Decision Process models for robot navigation}},
year = {2002}
}
@article{Hoey2014,
abstract = {Abstract This paper presents a general decision theoretic model of interactions between users and cognitive assistive technologies for various tasks of importance to the elderly population. The model is a partially observable Markov decision process ( POMDP ) whose ... $\backslash$n},
author = {Hoey, Jesse and Poupart, Pascal and Boutilier, Craig and Mihailidis, Alex},
doi = {10.4018/978-1-60960-165-2.ch013},
isbn = {9781609601652},
journal = {Proc AAAI Fall Symposium on Assistive Technologies},
mendeley-groups = {Robotics/POMDP},
title = {{POMDP models for assistive technology}},
url = {http://www.aaai.org/Papers/Symposia/Fall/2005/FS-05-02/FS05-02-009.pdf{\%}5Cnpapers3://publication/uuid/CB605201-5DE9-4D84-AF60-403F70A5E8B1},
year = {2014}
}
@inproceedings{Chen2016,
abstract = {The partially observable Markov decision process (POMDP) provides a principled general model for planning under uncertainty. However, solving a general POMDP is computationally intractable in the worst case. This paper introduces POMDP-lite, a subclass of POMDPs in which the hidden state variables are constant or only change deterministically. We show that a POMDP-lite is equivalent to a set of fully observable Markov decision processes indexed by a hidden parameter and is useful for modeling a variety of interesting robotic tasks. We develop a simple model-based Bayesian reinforcement learning algorithm to solve POMDP-lite models. The algorithm performs well on large-scale POMDP-lite models with up to {\$}10{\^{}}{\{}20{\}}{\$} states and outperforms the state-of-the-art general-purpose POMDP algorithms. We further show that the algorithm is near-Bayesian-optimal under suitable conditions.},
archivePrefix = {arXiv},
arxivId = {1602.04875},
author = {Chen, Min and Frazzoli, Emilio and Hsu, David and Lee, Wee Sun},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2016.7487754},
eprint = {1602.04875},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chen et al. - 2016 - POMDP-lite for robust robot planning under uncertainty.pdf:pdf},
isbn = {9781467380263},
issn = {10504729},
mendeley-groups = {Robotics/POMDP},
pages = {5427--5433},
title = {{POMDP-lite for robust robot planning under uncertainty}},
volume = {2016-June},
year = {2016}
}
@inproceedings{Capitan2012,
abstract = {Planning under uncertainty faces a scalability problem when considering multi-robot teams, as the informa- tion space scales exponentially with the number of robots. To address this issue, this paper proposes to decentralize multiagent Partially Observable Markov Decision Process (POMDPs) while maintaining cooperation between robots by using POMDP policy auctions. Furthermore, communication models in the multiagent POMDP literature severely mismatch with real inter-robot communication. We address this issue by applying a decentralized data fusion method in order to efficiently maintain a joint belief state among the robots. The paper focuses on a cooperative tracking application, in which several robots have to jointly track a moving target of interest. The proposed ideas are illustrated in real multi-robot experiments, showcasing the flexible and robust cooperation that our techniques can provide.},
author = {Capitan, Jesus and Spaan, Matthijs T J and Merino, Luis and Ollero, Anibal},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224917},
isbn = {9781467314039},
issn = {10504729},
mendeley-groups = {Robotics/POMDP},
pages = {3323--3328},
title = {{Decentralized multi-robot cooperation with auctioned POMDPs}},
year = {2012}
}
@article{Galceran20131258,
abstract = {Abstract Coverage Path Planning (CPP) is the task of determining a path that passes over all points of an area or volume of interest while avoiding obstacles. This task is integral to many robotic applications, such as vacuum cleaning robots, painter robots, autonomous underwater vehicles creating image mosaics, demining robots, lawn mowers, automated harvesters, window cleaners and inspection of complex structures, just to name a few. A considerable body of research has addressed the {\{}CPP{\}} problem. However, no updated surveys on {\{}CPP{\}} reflecting recent advances in the field have been presented in the past ten years. In this paper, we present a review of the most successful {\{}CPP{\}} methods, focusing on the achievements made in the past decade. Furthermore, we discuss reported field applications of the described {\{}CPP{\}} methods. This work aims to become a starting point for researchers who are initiating their endeavors in CPP. Likewise, this work aims to present a comprehensive review of the recent breakthroughs in the field, providing links to the most interesting and successful works.},
author = {Galceran, Enric and Carreras, Marc},
doi = {http://dx.doi.org/10.1016/j.robot.2013.09.004},
file = {:home/tkorthals/Documents/Mendeley Desktop/Galceran, Carreras - 2013 - A survey on coverage path planning for robotics.pdf:pdf},
issn = {0921-8890},
journal = {Robotics and Autonomous Systems},
keywords = {Coverage path planning,Motion planning,Path planning},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
number = {12},
pages = {1258--1276},
title = {{A survey on coverage path planning for robotics}},
url = {http://www.sciencedirect.com/science/article/pii/S092188901300167X},
volume = {61},
year = {2013}
}
@book{Ct2016,
abstract = {er g{\"{u}}nstigste Multikopter, den wir getestet haben, kostet 30 Euro und taugt sogar was. Kein Wunder also, dass {\"{u}}berall die surrenden Propeller aufsteigen: Der Traum vom selber Fliegen f{\"{u}}r jedermann ist wahr geworden. c't Multikopter hat alle wichtigen Kopter getestet, gibt Aufnahmetipps von oben und berichtet {\"{u}}ber neue und {\"{u}}berraschende Anwendungen der neuen Flugger{\"{a}}te. Doch einfach losfliegen w{\"{a}}re eine doofe und gef{\"{a}}hrliche Idee, mit der Sie sich sehr schaden k{\"{o}}nnen – so sehr die Fernbedienung auch zwischen den Fingern reizt: Die Hausratversicherung zahlt nicht, wenn der Kopter irgendwo oder gar irgendwem dagegenkracht. Und was darf ich eigentlich mit der Actioncam von oben aufnehmen? Wieso gibt es Flugverbotszonen mitten in der Stadt, sodass ich im eigenen Garten den Multikopter nicht ausprobieren darf? Und f{\"{u}}r wen ist eine Aufstiegserlaubnis gedacht? Die Antworten finden Sie hier im Heft, damit Sie wissen, was Sie mit dem Multikopter d{\"{u}}rfen und was nicht. Die Gesetze sind zum Teil kurios, weil sie zu der Zeit gemacht wurden, als es noch keine Multikopter gab. Starten Sie durch mit unserem Flugtraining im Heft und auf der DVD und werden Sie zum versierten Piloten.},
author = {C't},
file = {:home/tkorthals/Documents/Mendeley Desktop/c't - 2016 - c't Multikopter.pdf:pdf},
mendeley-groups = {Robotics/Drone},
publisher = {Heise Medien GmbH},
title = {{c't Multikopter}},
url = {https://shop.heise.de/ct-multikopter-2016},
year = {2016}
}
@article{Prassler2000,
abstract = {The definition of the desired functions and the design of an ultimate versatile personal robot is an ongoing debate. Meanwhile, however, precursors of this yet to evolve species are well on their way to become commercial products. Cleaning robots for public environments as well as for private households seem to be able to provide the breakthrough which the designers of non-industrial robot systems have long awaited. This survey describes a selection of 30 different cleaning robots, with the first developments reaching back more than 15 years. With a few exceptions we have focused on floor cleaning, in particular indoor floor cleaning. We describe a variety of scrubbing and vacuuming robots which were developed for this task. The described systems range from heavy, large, and expensive industrial cleaning vehicles to small-size, light-weight, low-cost household devices. The survey does not include, however, systems for cleaning facades of buildings, or windows, or production tools. Although not all of the 30 cleaning robots abovementioned have yet reached the state of commercial products, their number alone certainly reflects the expectations regarding the economic value associated with the automation of cleaning tasks. In Europe only the estimates for the market for cleaning services range up to the order of US{\$} 100 billion per year. It is therefore not surprising that the cleaning industry and the manufacturers of cleaning devices are rather enthusiastic with respect to the automation of cleaning tasks using (semi-)autonomous mobile robot systems.},
author = {Prassler, Erwin and Ritter, Arno and Schaeffer, Christoph and Fiorini, Paolo},
doi = {10.1023/A:1008974515925},
file = {:home/tkorthals/Documents/Mendeley Desktop/Prassler et al. - 2000 - A Short History of Cleaning Robots.pdf:pdf},
isbn = {0929-5593},
issn = {07436661},
journal = {Autonomous Robots},
keywords = {automatic cleaning,autonomous cleaning devices,autonomous pool cleaner,autonomous vacuum cleaner,cleaning robots,robotic floor scrubber,robotic road sweeper},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
pages = {211--226},
pmid = {16104376},
title = {{A Short History of Cleaning Robots}},
volume = {9},
year = {2000}
}
@misc{kim1995robot,
annote = {US Patent 5,440,216},
author = {{Samsung Electronics Co.}, Ltd. and Kim, T S},
institution = {Samsung Electronics Co., Ltd.},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Robot cleaner}},
url = {https://www.google.com/patents/US5440216},
year = {1995}
}
@misc{yoo1994self,
annote = {US Patent 5,369,347},
author = {{Samsung Electronics Co.}, Ltd. and Yoo, C H},
institution = {Samsung Electronics Co., Ltd.},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Self-driven robotic cleaning apparatus and driving method thereof}},
url = {https://www.google.com/patents/US5369347},
year = {1994}
}
@misc{okumura1987multiple,
annote = {US Patent 4,674,048},
author = {{Automax Kabushiki-Kaisha} and Okumura, K},
institution = {Automax Kabushiki-Kaisha},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Multiple robot control system using grid coordinate system for tracking and completing travel over a mapped region containing obstructions}},
url = {https://www.google.com/patents/US4674048},
year = {1987}
}
@inproceedings{citeulike:2154195,
address = {New York, NY, USA},
author = {Forlizzi, Jodi},
booktitle = {HRI '07: Proceeding of the ACM/IEEE international conference on Human-robot interaction},
doi = {10.1145/1228716.1228734},
file = {:home/tkorthals/Documents/Mendeley Desktop/Forlizzi - 2007 - How robotic products become social products an ethnographic study of cleaning in the home.pdf:pdf},
isbn = {9781595936172},
keywords = {ethnography,interaction design,robotic products,robots},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
pages = {129--136},
publisher = {ACM},
title = {{How robotic products become social products: an ethnographic study of cleaning in the home}},
url = {http://dx.doi.org/10.1145/1228716.1228734},
year = {2007}
}
@misc{clark2003robotic,
abstract = {A robotic floor cleaning device comprises a chassis (10), motor-driven wheels (11) supporting the chassis (10), a motor-driven suction fan (9), a dirty air inlet (2) and a motor-driven rotatable agitator (4) at the dirty air inlet (2) for agitating the surface. A control system navigates the device around a room and distributes power to the motor-driven wheels (11) and to the agitator (4). The control system detects when the agitator (4) has jammed (100, 102) and, in the event of a jam, attempts to clear the jam (104, 106). After successfully clearing the jam the control system turns the agitator (4) off (114, 116, 118) or navigates the cleaning device around the location at which the jam occurred (119). The cleaning device can store the location of the jam for use in preventing further jams when the cleaning device returns to a similar position in the room.},
annote = {US Patent 6,605,156},
author = {{Dyson Limited} and Clark, A G and Bisset, D L and Aldred, M D},
institution = {Dyson Limited},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Robotic floor cleaning device}},
url = {https://www.google.de/patents/US6605156},
year = {2003}
}
@misc{shah2015distance,
abstract = {A distance measuring system and method employing a laser distance sensor may have utility in various applications. In accordance with one aspect of the present invention, a laser distance sensor may acquire accurate distance measurements with a short baseline.},
annote = {US Patent 8,996,172},
author = {{Neato Robotics}, Inc. and Shah, P and Konolige, K and Augenbraun, J and Donaldson, N and Fiebig, C and Liu, Y and Khan, H M and Pinzarrone, J and Salinas, L and Tang, H and Others},
institution = {Neato Robotics, Inc.},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Distance sensor system and method}},
url = {https://www.google.de/patents/US8996172},
year = {2015}
}
@misc{jones2015autonomous,
abstract = {An autonomous floor-cleaning robot comprising a housing infrastructure including a chassis, a power subsystem; for providing the energy to power the autonomous floor-cleaning robot, a motive subsystem operative to propel the autonomous floor-cleaning robot for cleaning operations, a command and control subsystem operative to control the autonomous floor-cleaning robot to effect cleaning operations, and a self-adjusting cleaning head subsystem that includes a deck mounted in pivotal combination with the chassis, a brush assembly mounted in combination with the deck and powered by the motive subsystem to sweep up particulates during cleaning operations, a vacuum assembly disposed in combination with the deck and powered by the motive subsystem to ingest particulates during cleaning operations, and a deck adjusting subassembly mounted in combination with the motive subsystem for the brush assembly, the deck, and the chassis that is automatically operative in response to an increase in brush torque in said brush assembly to pivot the deck with respect to said chassis. The autonomous floor-cleaning robot also includes a side brush assembly mounted in combination with the chassis and powered by the motive subsystem to entrain particulates outside the periphery of the housing infrastructure and to direct such particulates towards the self-adjusting cleaning head subsystem.},
annote = {US Patent 9,167,946},
author = {{Irobot Corporation} and Jones, J L and Mack, N E and Nugent, D M and Sandin, P E},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Autonomous floor cleaning robot}},
url = {https://www.google.com/patents/US9167946},
year = {2015}
}
@misc{sofman2011method,
abstract = {Techniques that optimize performance of simultaneous localization and mapping (SLAM) processes for mobile devices, typically a mobile robot. In one embodiment, erroneous particles are introduced to the particle filtering process of localization. Monitoring the weights of the erroneous particles relative to the particles maintained for SLAM provides a verification that the robot is localized and detection that it is no longer localized. In another embodiment, cell-based grid mapping of a mobile robot's environment also monitors cells for changes in their probability of occupancy. Cells with a changing occupancy probability are marked as dynamic and updating of such cells to the map is suspended or modified until their individual occupancy probabilities have stabilized. In another embodiment, mapping is suspended when it is determined that the device is acquiring data regarding its physical environment in such a way that use of the data for mapping will incorporate distortions into the map, as for example when the robotic device is tilted.},
annote = {US Patent App. 12/873,018},
author = {{Neato Robotics}, Inc. and Sofman, B and Ermakov, V and Emmerich, M and Alexander, S and MONSON, N D},
institution = {Neato Robotics, Inc.},
keywords = {LiDAR,LiDAR-SLAM,SLAM},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {LiDAR,LiDAR-SLAM,SLAM},
publisher = {Google Patents},
title = {{Method and apparatus for simultaneous localization and mapping of mobile robot environment}},
url = {https://www.google.de/patents/US20110082585},
year = {2011}
}
@misc{alexander2016method,
abstract = {A robotic surface treatment apparatus treats corners of rooms more effectively through intricate guidance of the apparatus through inside and outside corners. In one aspect, contact and/or non-contact sensors provide information to one or more on-board processors on the apparatus to enable selective overriding of obstacle avoidance program code and allow the apparatus to get closer to walls to facilitate treatment. In another aspect, the sensors provide information to the on-board processors to control backup motion of the apparatus to cover previously-missed areas when turning corners. In yet another aspect, the apparatus is shaped to have its treatment mechanism positioned more closely to the front of the apparatus to enable treatment more closely to walls near corners. In one embodiment, the robotic surface treatment apparatus is a robotic vacuum. The vacuum may have its cleaning brush positioned near a flat front portion of the apparatus.},
annote = {US Patent 9,408,514},
author = {{Neato Robotics}, Inc. and Alexander, S M and Hexsel, B A},
institution = {Neato Robotics, Inc.},
keywords = {Navigation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {Navigation},
publisher = {Google Patents},
title = {{Method and apparatus for traversing corners of a floored area with a robotic surface treatment apparatus}},
url = {https://www.google.de/patents/US9408514},
year = {2016}
}
@misc{hussey2010autonomous,
abstract = {An autonomous coverage robot includes a body, a drive system disposed on the body, and a cleaning assembly disposed on the body and configured to engage a floor surface while the robot is maneuvered across the floor surface. The cleaning assembly includes a driven cleaning roller, a cleaning bin disposed on the body for receiving debris agitated by the cleaning roller, and an air mover. The cleaning bin includes a cleaning bin body having a cleaning bin entrance disposed adjacent to the cleaning roller and a roller scraper disposed on the cleaning bin body for engaging the cleaning roller. The cleaning bin body has a holding portion in pneumatic communication with the cleaning bin entrance, and the air mover is operable to move air into the cleaning bin entrance.},
annote = {US Patent App. 12/540,884},
author = {{Irobot Corporation} and Hussey, P A and Roy, R P and Neumann, R M and Svendsen, S and Ozick, D N and Casey, C M and Kapoor, D R and Campbell, T L and Won, C and Morse, C J and Others},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Autonomous Coverage Robots}},
url = {https://www.google.de/patents/US20100037418},
year = {2010}
}
@misc{schnittman2008compact,
abstract = {An autonomous coverage robot includes a chassis having forward and rearward portions and a drive system carried by the chassis. The forward portion of the chassis defines a substantially rectangular shape. The robot includes a cleaning assembly mounted on the forward portion of the chassis and a bin disposed adjacent the cleaning assembly and configured to receive debris agitated by the cleaning assembly. A bin cover is pivotally attached to a lower portion of the chassis and configured to rotate between a first, closed position providing closure of an opening defined by the bin and a second, open position providing access to the bin opening. The robot includes a body attached to the chassis and a handle disposed on an upper portion of the body. A bin cover release is actuatable from substantially near the handle.},
annote = {US Patent App. 12/118,117},
author = {{Irobot Corporation} and Schnittman, M and Dubrovsky, Z A and Mammen, J W and Solochek, A},
institution = {Irobot Corporation},
keywords = {Navigation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {Navigation},
publisher = {Google Patents},
title = {{Compact Autonomous Coverage Robot}},
url = {https://www.google.de/patents/US20080276407},
year = {2008}
}
@misc{halloran2013robot,
annote = {US Patent 8,374,721},
author = {{Irobot Corporation} and Halloran, M J and Mammen, J W and Campbell, T L and Walker, J S and Sandin, P E and Billington, J N and Ozick, D N},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Robot system}},
url = {https://www.google.com/patents/US8374721},
year = {2013}
}
@misc{yan2011robotic,
annote = {US Patent 7,937,800},
author = {Yan, J},
institution = {Jason Yan},
keywords = {Spirale,spiral},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {Spirale,spiral},
publisher = {Google Patents},
title = {{Robotic vacuum cleaner}},
url = {https://www.google.com/patents/US7937800},
year = {2011}
}
@misc{hyung2010method,
abstract = {Disclosed herein is a method of building a map of a mobile platform moving in a dynamic environment and detecting an object using a 3D camera sensor, e.g., an IR TOF camera sensor, for localization. A localization technology to separate and map a dynamic object and a static object is applied to a mobile platform, such as an unmanned vehicle or a mobile robot. Consequently, the present method is capable of accurately building map information based on the static object in a dynamic environment having a large number of dynamic objects and achieving a dynamic object avoidance or chasing function using position information acquired to build the map.},
annote = {US Patent App. 12/654,037},
author = {{Samsung Electronics Co.}, Ltd. and Hyung, S Y and Roh, K S and Yoon, S J and Ahn, S H},
institution = {Samsung Electronics Co., Ltd.},
keywords = {SLAM,Visual,Visual-SLAM},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {SLAM,Visual,Visual-SLAM},
publisher = {Google Patents},
title = {{Method of building map of mobile platform in dynamic environment}},
url = {https://www.google.com/patents/US20100161225},
year = {2010}
}
@misc{jung2010cleaning,
annote = {US Patent 7,856,291},
author = {{Lg Electronics Inc.} and JUNG, Y G and JEON, H S},
institution = {Lg Electronics Inc.},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Cleaning robot and method for controlling the same}},
url = {https://www.google.com/patents/US7856291},
year = {2010}
}
@misc{vartanian2015determining,
abstract = {Determining, with utilization of environmental sensor data, a floor in a building that the mobile computer is located is disclosed. The mobile computer may track indoor position on the floor with a combination of Wi-Fi related position data and an estimated distance traveled determined with accelerometer data. The mobile computer may also determine an area on the floor where the mobile computer is located.},
annote = {US Patent 9,116,230},
author = {{HJ Laboratories}, LLC and Vartanian, H and Jurikson-Rhodes, J},
institution = {HJ Laboratories, LLC},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Determining floor location and movement of a mobile computer in a building}},
url = {https://www.google.com/patents/US9116230},
year = {2015}
}
@misc{hyung2016robot,
abstract = {A robot and a method for creating a robot path. The method for planning the robot path includes generating a depth map including a plurality of cells by measuring a distance to an object, dividing a boundary among the plurality of cells into a plurality of partitions according to individual depth values of the cells, and extracting a single closed loop formed by the divided boundary, obtaining a position and shape of the object located at a first time through the extracted single closed loop, calculating a probability that the object is located at a second time after t seconds on the basis of the obtained position and shape of the object located at the first time, and creating a moving path simultaneously while avoiding the object according to the calculated probability, thereby creating an optimum path without colliding with the object.},
annote = {US Patent 9,254,571},
author = {{Samsung Electronics Co.}, Ltd. and Hyung, S Y and Roh, K S and Yoon, S J and Ahn, S H},
institution = {Samsung Electronics Co., Ltd.},
keywords = {Map-building,Navigation,TOF},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {Map-building,Navigation,TOF},
publisher = {Google Patents},
title = {{Robot and method for creating path of the robot}},
url = {https://www.google.com/patents/US9254571},
year = {2016}
}
@misc{friedman2014distributed,
abstract = {A system is provided that includes at least one manager and one or more robots configured to communicate wirelessly. The manager can include certain functions that generate data, instructions, or both used by one or more robots. The manager can also facilitate communications among several robots, or robots could also be configured to communicate directly.},
annote = {US Patent 8,755,936},
author = {{Seegrid Corporation} and Friedman, S J M and Moravec, H P},
institution = {Seegrid Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Distributed multi-robot system}},
url = {https://www.google.com/patents/US8755936},
year = {2014}
}
@misc{park2009method,
abstract = {A method of detecting an object using a structured light and a robot using the same are disclosed. The method of detecting a floor object using a structured light includes measuring a height difference of a position onto which a specified structured light is projected with a reference position, and detecting the floor object using the measured height difference.},
annote = {US Patent 7,507,948},
author = {{Samsung Electronics Co.}, Ltd. and Park, D and Lee, H K and Kim, D J and Bang, S},
institution = {Samsung Electronics Co., Ltd.},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Method of detecting object using structured light and robot using the same}},
url = {https://www.google.com/patents/US7507948},
year = {2009}
}
@misc{casey2008obstacle,
abstract = {A robot obstacle detection system including a robot housing which navigates with respect to a surface and a sensor subsystem aimed at the surface for detecting the surface. The sensor subsystem includes an emitter which emits a signal having a field of emission and a photon detector having a field of view which intersects the field of emission at a region. The subsystem detects the presence of an object proximate the mobile robot and determines a value of a signal corresponding to the object. It compares the value to a predetermined value, moves the mobile robot in response to the comparison, and updates the predetermined value upon the occurrence of an event.},
annote = {US Patent 7,430,455},
author = {{Irobot Corporation} and Casey, C and Cross, M and Ozick, D and Jones, J L},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Obstacle following sensor scheme for a mobile robot}},
url = {https://www.google.com/patents/US7430455},
year = {2008}
}
@misc{vartanian2015determining,
abstract = {A mobile computer may use building information to determine its indoor location or position. The mobile computer determines the dimensions of a room in a building using range determination or a range finder in the mobile computer. The determined dimensions of the room may be compared to the building information to locate, position, or track the mobile computer in the building.},
annote = {US Patent 9,110,159},
author = {{HJ Laboratories}, LLC and Vartanian, H and Jurikson-Rhodes, J},
institution = {HJ Laboratories, LLC},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Determining indoor location or position of a mobile computer using building information}},
url = {https://www.google.com/patents/US9110159},
year = {2015}
}
@misc{friedman2014service,
abstract = {In accordance with aspects of the present invention, a service robot, such as a robotic cleaner, can be configured to more effectively service an environment. The service robot can include one or more sensors that sense its location, the location of objects, or both, and can also include noise reduction elements. The service robot can determine that it is under a “furnishing” and implement a different servicing pattern.},
annote = {US Patent 8,838,268},
author = {{Seegrid Corporation} and Friedman, S J M and Moravec, H P},
institution = {Seegrid Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Service robot and method of operating same}},
url = {https://www.google.com/patents/US8838268},
year = {2014}
}
@misc{jones2003robot,
abstract = {A robot obstacle detection system including a robot housing which navigates with respect to a surface and a sensor subsystem having a defined relationship with respect to the housing and aimed at the surface for detecting the surface. The sensor subsystem includes an optical emitter which emits a directed beam having a defined field of emission and a photon detector having a defined field of view which intersects the field of emission of the emitter at a region. A circuit in communication with a detector redirects the robot when the surface does not occupy the region to avoid obstacles. A similar system is employed to detect walls.},
annote = {US Patent 6,594,844},
author = {{Irobot Corporation} and Jones, J L},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Robot obstacle detection system}},
url = {https://www.google.com/patents/US6594844},
year = {2003}
}
@misc{landry2013navigational,
abstract = {An autonomous cleaning apparatus includes a chassis, a drive system disposed on the chassis and operable to enable movement of the cleaning apparatus, and a controller in communication with the drive system. The controller includes a processor operable to control the drive system to steer movement of the cleaning apparatus. The autonomous cleaning apparatus includes a cleaning head system disposed on the chassis and a sensor system in communication with the controller. The sensor system includes a debris sensor for generating a debris signal, a bump sensor for generating a bump signal, and an obstacle following sensor disposed on a side of the autonomous cleaning apparatus for generating an obstacle signal. The processor executes a prioritized arbitration scheme to identify and implement one or more dominant behavioral modes based upon at least one signal received from the sensor system.},
annote = {US Patent 8,428,778},
author = {{Irobot Corporation} and Landry, G W and Cohen, D A and Ozick, D N and Chiappetta, M J and Jones, J L},
institution = {Irobot Corporation},
keywords = {Navigation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
mendeley-tags = {Navigation},
publisher = {Google Patents},
title = {{Navigational control system for a robotic device}},
url = {https://www.google.com/patents/US8428778},
year = {2013}
}
@misc{jones2005autonomous,
abstract = {An autonomous floor-cleaning robot comprises a self-adjusting cleaning head subsystem that includes a dual-stage brush assembly having counter-rotating, asymmetric brushes and an adjacent, but independent, vacuum assembly such that the cleaning capability and efficiency of the self-adjustable cleaning head subsystem is optimized while concomitantly minimizing the power requirements thereof. The autonomous floor-cleaning robot further includes a side brush assembly for directing particulates outside the envelope of the robot into the self-adjusting cleaning head subsystem.},
annote = {US Patent 6,883,201},
author = {{Irobot Corporation} and Jones, J L and Mack, N E and Nugent, D M and Sandin, P E},
institution = {Irobot Corporation},
mendeley-groups = {Robotics/Vacuum Cleaner/Patente},
publisher = {Google Patents},
title = {{Autonomous floor-cleaning robot}},
url = {https://www.google.com/patents/US6883201},
year = {2005}
}
@misc{Corporation2013,
author = {Corporation, Mamirobot USA},
file = {:home/tkorthals/Documents/Mendeley Desktop/Corporation - 2013 - Mami KF5 User Manual.pdf:pdf},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
title = {{Mami KF5 User Manual}},
url = {http://www.robotshop.com/media/files/pdf/user-manual-kf5-white.pdf},
urldate = {2016-11-01},
year = {2013}
}
@article{Ulrich97autonomousvacuum,
abstract = {This paper presents the results of the development of an autonomous mobile robot, designed according to some new concepts established in this field during the last decade. These principles can be found in other work based on the constructivist approach, artificial life, subsumption architecture and other bottom-up methodologies. These ideas have been applied to the complete robot design, spanning from the shape of the robot to the sensors, from the electronics to the software control structure. By this way we have developed what we call an "Application Specific Mobile Robot" (ASMR). The target application is a domestic autonomous vacuum cleaner. Despite the actual limitations of the final robot, this work shows how this methodology can bring many interesting results. 1 Introduction The domestic autonomous vacuum cleaner that cleans your home while you are outdoors doing some shopping, is an old wish and it may stay so for some time. Many companies and research institutions have tried ...},
author = {Ulrich, Iwan R. and Mondada, Francesco and Nicoud, J.-D.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ulrich, Mondada, Nicoud - 1997 - Autonomous vacuum cleaner.pdf:pdf},
journal = {Robotics and Autonomous Systems},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
pages = {1--16},
title = {{Autonomous vacuum cleaner}},
volume = {19},
year = {1997}
}
@incollection{Al-Wahedi2013,
address = {Berlin, Heidelberg},
annote = {Sehr schlechtes paper, welches von einem verhaltensbasierten Ansatz ausgeht, ohne eine Kartographierung durch zu f{\"{u}}hren. Die Karte wird als Grid angenommen, bei der jede Gridzelle auf Basis einer Kostenabsch{\"{a}}tzung angefahren wird.},
author = {Al-Wahedi, Khaled and Darwish, Aya and Kodiah, Basma},
booktitle = {Robot Intelligence Technology and Applications 2012: An Edition of the Presented Papers from the 1st International Conference on Robot Intelligence Technology and Applications},
doi = {10.1007/978-3-642-37374-9_40},
editor = {Kim, Jong-Hwan and Matson, Eric T and Myung, Hyun and Xu, Peter},
file = {:home/tkorthals/Documents/Mendeley Desktop/Al-Wahedi, Darwish, Kodiah - 2013 - Cost Based Navigation for Autonomous Vacuum Cleaners.pdf:pdf},
isbn = {978-3-642-37374-9},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
pages = {415--422},
publisher = {Springer Berlin Heidelberg},
title = {{Cost Based Navigation for Autonomous Vacuum Cleaners}},
url = {http://dx.doi.org/10.1007/978-3-642-37374-9{\_}40},
year = {2013}
}
@article{moeller2013,
abstract = {The paper describes a visual method for the navigation of autonomous floor-cleaning robots. The method constructs a topological map with metrical information where place nodes are characterized by panoramic images and by particle clouds representing position estimates. Current image and position estimate of the robot are interrelated to landmark images and position estimates stored in the map nodes through a holistic visual homing method which provides bearing and orientation estimates. Based on these estimates, a position estimate of the robot is updated by a particle filter. The robot's position estimates are used to guide the robot along parallel, meandering lanes and are also assigned to newly created map nodes which later serve as landmarks. Computer simulations and robot experiments confirm that the robot position estimate obtained by this method is sufficiently accurate to keep the robot on parallel lanes, even in the presence of large random and systematic odometry errors. This ensures an efficient cleaning behavior with almost complete coverage of a rectangular area and only small repeated coverage. Furthermore, the topological-metrical map can be used to completely cover rooms or apartments by multiple meander parts. ?? 2013 Elsevier B.V. All rights reserved.},
author = {M{\"{o}}ller, Ralf and Krzykawski, Martin and Gerstmayr-Hillen, Lorenz and Horst, Michael and Fleer, David and {De Jong}, Janina},
doi = {10.1016/j.robot.2013.07.011},
file = {:home/tkorthals/Documents/Mendeley Desktop/M{\"{o}}ller et al. - 2013 - Cleaning robot navigation using panoramic views and particle clouds as landmarks.pdf:pdf},
isbn = {0921-8890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Cleaning robot,Particle filter,Topological-metrical map,Visual navigation},
mendeley-groups = {Robotics/Exploration,Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner,Robotics/Vacuum Cleaner/Forschung/M{\"{o}}ller},
number = {12},
pages = {1415--1439},
publisher = {Elsevier BV},
title = {{Cleaning robot navigation using panoramic views and particle clouds as landmarks}},
volume = {61},
year = {2013}
}
@misc{Parkinson2016,
abstract = {The top performers in our review are the Neato Botvac Connected, the Gold Award winner; the iRobot Roomba 980, the Silver Award winner; and Samsung POWERbot, the Bronze Award winner. Here's more on choosing a robot vacuum to meet your needs, along with detail on how we arrived at our ranking of these 10 products.},
author = {Parkinson, Angie},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
title = {{Robot Vacuum Reviews}},
url = {robot-vacuum-review.toptenreviews.com},
urldate = {2016-11-01},
year = {2016}
}
@article{Yamauchi1997,
author = {Yamauchi, Brian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yamauchi - 1997 - A Frontier-Based Approach for Autonomous Exploration.pdf:pdf},
mendeley-groups = {Robotics/Exploration},
title = {{A Frontier-Based Approach for Autonomous Exploration}},
year = {1997}
}
@book{Choset2005,
abstract = {Robot motion planning has become a major focus of robotics. Research findings can be applied not only to robotics but to planning routes on circuit boards, directing digital actors in computer graphics, robot-assisted surgery and medicine, and in novel areas such as drug design and protein folding. This text reflects the great advances that have taken place in the last ten years, including sensor-based planning, probabalistic planning, localization and mapping, and motion planning for dynamic and nonholonomic systems. Its presentation makes the mathematical underpinnings of robot motion accessible to students of computer science and engineering, rleating low-level implementation details to high-level algorithmic concepts.},
address = {Cambridge, Mass.},
author = {Choset, Howie and Lynch, Kevin M. and Hutchinson, Seth and Kantor, George a. and Burgard, Wolfram and Kavraki, Lydia E. and Thrun, Sebastian},
doi = {10.1109/MRA.2005.1511878},
file = {:home/tkorthals/Documents/Mendeley Desktop/Choset et al. - 2005 - Principles of Robot Motion.chm:chm;:home/tkorthals/Documents/Mendeley Desktop/Choset et al. - 2005 - Principles of Robot Motion.pdf:pdf},
isbn = {0262033275},
issn = {1070-9932},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
number = {C},
pages = {1--603},
pmid = {189},
publisher = {MIT Press},
title = {{Principles of Robot Motion}},
volume = {2007},
year = {2005}
}
@article{Waanders2011,
abstract = {In this paper a path planning algorithms for a mobile cleaning robot is developed. An exact cellular decomposition divides an environment in multiple smaller regions called cells. To produce an efficient cleaning path, the order in which these cells are cleaned is important. This paper describes how the optimalization of this path can be formulated as a Traveling Salesman Problem. Furthermore an exact cellular decomposition called the Boustrophedon cellular decomposition is expanded to handle the dynamic, unknown environments a cleaning robots can face in an indoor environment. In particular this is achieved by allowing the robot to change the decomposition during its cleaning activity. A simulation study have been used to validate this approach.},
author = {Waanders, Marten},
file = {:home/tkorthals/Documents/Mendeley Desktop/Waanders - 2011 - Coverage Path Planning for Mobile Cleaning Robots.pdf:pdf},
keywords = {cleaning robots,coverage path planning,exact cellular},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
title = {{Coverage Path Planning for Mobile Cleaning Robots}},
year = {2011}
}
@book{Alonso2011,
abstract = {This book provides the reader with a clear and precise description of robotics and othersystems for home automation currently on the market, and discusses their interoperability and perspectives for the near future. It shows the different standards and the development platforms used by the main service robots inan international environment. This volumeprovides a scientific basis for the user who is looking for the bestoptionto suithis or her needs from the available alternatives to integratemodern technology in thedigital home.},
author = {Alonso, Ignacio Gonz{\'{a}}lez and Fern{\'{a}}ndez, Mercedes and Maestre, Jos{\'{e}} M. and Fuente, Mar{\'{i}}a del Pilar Almudena Garc{\'{i}}a},
booktitle = {Springer},
doi = {10.1007/978-94-007-1491-5},
edition = {1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Alonso et al. - 2011 - Service Robotics within the Digital Home Applications and Future Prospects.pdf:pdf},
isbn = {978-94-007-1490-8},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
number = {Service Robotics within the Digital Home},
pages = {49--88},
publisher = {Springer Netherlands},
title = {{Service Robotics within the Digital Home: Applications and Future Prospects}},
url = {http://link.springer.com/content/pdf/10.1007/978-94-007-1491-5.pdf},
volume = {53},
year = {2011}
}
@article{Fink2013,
abstract = {Little is known about the usage, adoption process and long-term effects of domestic service robots in people's homes. We investigated the usage, acceptance and process of adoption of a vacuum cleaning robot in nine households by means of a six month ethnographic study. Our major goals were to explore how the robot was used and integrated into daily practices, whether it was adopted in a durable way, and how it impacted its environment. We studied people's perception of the robot and how it evolved over time, kept track of daily routines, the usage patterns of cleaning tools, and social activities related to the robot. We integrated our results in an existing framework for domestic robot adoption and outlined similarities and differences to it. Finally, we identified several factors that promote or hinder the process of adopting a domestic service robot and make suggestions to further improve human-robot interactions and the design of functional home robots toward long-term acceptance.},
author = {Fink, Julia and Bauwens, Val{\'{e}}rie and Kaplan, Fr{\'{e}}d{\'{e}}ric and Dillenbourg, Pierre},
doi = {10.1007/s12369-013-0190-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fink et al. - 2013 - Living with a Vacuum Cleaning Robot A 6-month Ethnographic Study.pdf:pdf},
issn = {18754791},
journal = {International Journal of Social Robotics},
keywords = {Adoption of technology,Domestic robots,Ethnographic study,Human-Robot interaction,Long-term interaction,Miele,Social issues in robotics},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
number = {3},
pages = {389--408},
title = {{Living with a Vacuum Cleaning Robot: A 6-month Ethnographic Study}},
volume = {5},
year = {2013}
}
@article{DeAlmeida2011,
abstract = {Domestic service robots are making new inroads into several applications particularly carried out by conventional human-driven appliances such as vacuum cleaners and lawn mowers. The European Commission in the year 2005 issued the ecodesign directive aimed at reducing the environmental impact of energy-using products during their life cycle. The commission established a well-defined approach to the development of implementing measures, 'the Methodology for the Ecodesign of Energy Using Products (MEEuP)'. It sets out a common method to gather information to evaluate whether and to which extent a product fulfills certain criteria that make it eligible for implementing measures under the directive, namely its environmental impact and potential for improvement. The International Organization for Standardization (ISO) has a TC, ISO/TC 184/SC, that is developing standards for robots and, specifically, working group 8 (WG 8) is investigating on the standardization needs for service robots.},
author = {{De Almeida}, Anibal T. and Fong, Joao},
doi = {10.1109/MRA.2011.942484},
file = {:home/tkorthals/Documents/Mendeley Desktop/De Almeida, Fong - 2011 - Domestic service robots.pdf:pdf},
issn = {10709932},
journal = {IEEE Robotics and Automation Magazine},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
number = {3},
pages = {18--20},
title = {{Domestic service robots}},
volume = {18},
year = {2011}
}
@article{Palleja2010,
abstract = {In this paper, floor-cleaning coverage performances of some domestic mobile robots are measured, analyzed and modeled. Results obtained in a reduced scenario show that floor-cleaning coverage is complete in all cases if the path-planning exploration algorithm has some random dependence. Additionally, the evolution of the area cleaned by the mobile robot expressed in a distance domain has an exponential shape that can be modeled with a single exponential where the amplitude defines the maximum cleaning-coverage achieved and the time-constant defines the dynamic evolution of the coverage. Both parameters are robot dependent and can be estimated if the area of the room is known and then floor-cleaning coverage can be predicted and over-cleaning minimized. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Palleja, T. and Tresanchez, M. and Teixido, M. and Palacin, J.},
doi = {10.1016/j.robot.2009.07.030},
file = {:home/tkorthals/Documents/Mendeley Desktop/Palleja et al. - 2010 - Modeling floor-cleaning coverage performances of some domestic mobile robots in a reduced scenario.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Cleaning coverage,Coverage,Domestic robots,Mobile robot},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
number = {1},
pages = {37--45},
publisher = {Elsevier B.V.},
title = {{Modeling floor-cleaning coverage performances of some domestic mobile robots in a reduced scenario}},
url = {http://dx.doi.org/10.1016/j.robot.2009.07.030},
volume = {58},
year = {2010}
}
@article{Choset1997,
abstract = {Coverage path planning is the determination of a path that a robot must take in order to pass over each point in an environment. Applications include vacuuming, floor scrubbing and inspection. We developed the boustrophedon cellular decomposition, which is an exacnt cellular decomposition approach, for the purposes of coverage. Each cell in the boustrophedon is covered with simple back and forth motions. Once each cell is covered, then the entire environment is covered. Therefore, coverage is reduced to finding an exhaustive path through a graph which represents the adjacency relationships of the cells in the boustrophedon decomposition. This approach is provably complete and Experiments on a mobile robot validate this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Choset, Howie and Pignon, Philippe},
doi = {10.1007/978-1-4471-1273-0_32},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Choset, Pignon - 1997 - Coverage Path Planning The Boustrophedon Cellular Decomposition.pdf:pdf},
isbn = {978-1-4471-1275-4},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Miele},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
number = {3},
pages = {247--253},
pmid = {9295593},
title = {{Coverage Path Planning : The Boustrophedon Cellular Decomposition}},
volume = {9},
year = {1997}
}
@article{Vaussard2014,
abstract = {This article considers the suitability of current robots designed to assist humans in accomplishing their daily domestic tasks. With several million units sold worldwide, robotic vacuum cleaners are currently the figurehead in this field. As such, we will use them to investigate the following key question: How does a service cleaning robot perform in a real household? One must consider not just how well a robot accomplishes its task, but also how well it integrates inside the user's space and perception. We took a holistic approach to addressing these topics by combining two studies in order to build a common ground. In the first of these studies, we analyzed a sample of seven robots to identify the influence of key technologies, such as the navigation system, on technical performance. In the second study, we conducted an ethnographic study within nine households to identify users' needs. This innovative approach enables us to recommend a number of concrete improvements aimed at fulfilling users' needs by leveraging current technologies to reach new possibilities. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Vaussard, F. and Fink, J. and Bauwens, V. and R{\'{e}}tornaz, P. and Hamel, D. and Dillenbourg, P. and Mondada, F.},
doi = {10.1016/j.robot.2013.09.014},
file = {:home/tkorthals/Documents/Mendeley Desktop/Vaussard et al. - 2014 - Lessons learned from robotic vacuum cleaners entering the home ecosystem.pdf:pdf},
isbn = {09218890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Cleaning robots,Domestic robotics,Energy efficiency,Human factors in robotics,Human-robot interaction,Miele},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
number = {3},
pages = {376--391},
title = {{Lessons learned from robotic vacuum cleaners entering the home ecosystem}},
volume = {62},
year = {2014}
}
@inproceedings{Ward1994,
author = {Ward, Charles W.},
booktitle = {Conference on Intelligent Robotics in Field, Factory, Service, and Space},
editor = {Erickson, Jon D.},
keywords = {Miele},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
pages = {662--663},
title = {{An end user's whishlist}},
url = {https://ntrs.nasa.gov/search.jsp?R=19950005096},
volume = {2},
year = {1994}
}
@article{Miele,
author = {Salunke, Shanu},
file = {:home/tkorthals/Documents/Mendeley Desktop/Salunke - 2013 - Modified Boundary Fill for Complete Surface Coverage by Robotic Agents.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {Miele,boundary fill,household robots,surface,vacuum cleaner robots},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
number = {13},
title = {{Modified Boundary Fill for Complete Surface Coverage by Robotic Agents}},
volume = {73},
year = {2013}
}
@article{Mazo2008,
abstract = {Abstract. Robust area coverage is the problem of driving the footprint of a mo-bile robot over all the points of a given region in an efficient manner even when noise is present in actuators and sensors. This problem is a common challenge in many applications, including automatic lawn mowing and vacuum cleaning. In this paper a robot with uncertain heading is studied. Five control strategies based on event-triggered position measurements available when the vehicle intersects the boundary of the area to be covered are compared. It is shown that the per-formance depends heavily on the maximum size of the heading error. The results are evaluated through extensive Monte Carlo simulations for the coverage of a square-shaped cell. An experimental implementation is also presented. 1},
author = {Mazo, Manuel and Johansson, Karl Henrik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mazo, Johansson - 2008 - Path-Planning for Robust Area Coverage Evaluation of Five Coordination Strategies.pdf:pdf},
journal = {Online},
keywords = {Miele},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
title = {{Path-Planning for Robust Area Coverage: Evaluation of Five Coordination Strategies}},
year = {2008}
}
@article{Choset2001,
abstract = {This paper surveys recent results in coverage path planning, a new path planning approach that determines a path for a robot to pass over all points in its free space. Unlike conventional point-to-point path planning, coverage path planning enables applications such as robotic de- mining, snow removal, lawn mowing, car-body painting, machine milling, etc. This paper will focus on coverage path planning algorithms for mobile robots constrained to operate in the plane. These algorithms can be classified as either heuristic or complete. It is our con- jecture that most complete algorithms use an exact cellular decomposition, either explicitly or implicitly, to achieve coverage. Therefore, this paper organizes the coverage algorithms into four categories: heuristic, approximate, partial-approximate and exact cellular decompo- sitions. The final section describes some provably complete multi-robot coverage algorithms.},
author = {Choset, Howie},
doi = {10.1023/A:1016639210559},
file = {:home/tkorthals/Documents/Mendeley Desktop/Choset - 2001 - Coverage for robotics – A survey of recent results.pdf:pdf},
isbn = {1012-2443},
issn = {1573-7470},
journal = {Annals of mathematics and artificial intelligence},
keywords = {Miele,cell decompositions,coverage,mobile robots},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
pages = {113--126},
title = {{Coverage for robotics – A survey of recent results}},
url = {http://link.springer.com/article/10.1023/A:1016639210559},
year = {2001}
}
@article{Skrzypczyk2010,
author = {Skrzypczyk, Krzysztof and Pieronczyk, Agnieszka},
file = {:home/tkorthals/Documents/Mendeley Desktop/Skrzypczyk, Pieronczyk - 2010 - Surface Covering Algorithms for Semiautonomous Vacuum Cleaner.pdf:pdf},
isbn = {9789549260014},
journal = {12th WSEAS International Conference on Automatic Control, Modelling {\&} Simulation},
keywords = {Miele},
mendeley-groups = {Robotics/Vacuum Cleaner/Forschung,Robotics/Vacuum Cleaner},
mendeley-tags = {Miele},
pages = {294--298},
title = {{Surface Covering Algorithms for Semiautonomous Vacuum Cleaner}},
year = {2010}
}
@inproceedings{tobi2016,
author = {zu Borgsen, Sebastian and Korthals, Timo and Wachsmuth, Sven},
file = {:home/tkorthals/Documents/Mendeley Desktop/zu Borgsen, Korthals, Wachsmuth - 2016 - ToBI-Team of Bielefeld The Human-Robot Interaction System for RoboCup@Home 2016.pdf:pdf},
title = {{ToBI-Team of Bielefeld The Human-Robot Interaction System for RoboCup@Home 2016}},
year = {2016}
}
@article{Rudolph2016,
author = {Rudolph, Daniel},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rudolph - 2016 - Kalman-basierte Lokalisation f{\"{u}}r Landmaschinen.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{Kalman-basierte Lokalisation f{\"{u}}r Landmaschinen}},
year = {2016}
}
@article{Arkin1998,
author = {Arkin, Ronald},
doi = {10.1016/S0005-1098(02)00169-3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Arkin - 1998 - Behavior-Based Robotics.pdf:pdf},
isbn = {0262011654},
issn = {00051098},
journal = {The MIP Press},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Behavior-Based Robotics}},
year = {1998}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2007 - Local Visual Homing with Differential Flow Methods.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Local Visual Homing with Differential Flow Methods}},
year = {2007}
}
@article{Krzykawski2011,
author = {Krzykawski, M},
file = {:home/tkorthals/Documents/Mendeley Desktop/Krzykawski - 2011 - Parsimonious Loop-Closure Detection based on Global Image Descriptors of Panoramic Images.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Parsimonious Loop-Closure Detection based on Global Image Descriptors of Panoramic Images}},
year = {2011}
}
@article{Gerstmayr,
author = {Gerstmayr, Lorenz and R{\"{o}}ben, Frank and M{\"{o}}ller, Ralf},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerstmayr, R{\"{o}}ben, M{\"{o}}ller - Unknown - From Insect Visual Homing to Autonomous Robot Cleaning.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{From Insect Visual Homing to Autonomous Robot Cleaning}}
}
@article{Dong2009,
author = {Dong, YE},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dong - 2009 - Image-based Visual Servoing.pdf:pdf},
journal = {Vigir.Missouri.Edu},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Image-based Visual Servoing}},
url = {http://vigir.missouri.edu/imagebasedservoing.htm},
year = {2009}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2007 - Performance Measures for Local Visual Homing.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
pages = {1--29},
title = {{Performance Measures for Local Visual Homing}},
year = {2007}
}
@article{Gerstmayr2010a,
author = {Gerstmayr, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerstmayr - 2010 - Local visual homing in animals and humans Aspects of homing behaviour Homing behavior.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Local visual homing in animals and humans Aspects of homing behaviour Homing behavior}},
year = {2010}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2007 - Blockmatching along flow lines.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
pages = {1--36},
title = {{Blockmatching along flow lines}},
year = {2007}
}
@article{Gerstmayr2010,
author = {Gerstmayr, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerstmayr - 2010 - Vision-based Simultaneous Localization and Mapping.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Vision-based Simultaneous Localization and Mapping}},
year = {2010}
}
@article{Gerstmayr2007,
author = {Gerstmayr, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerstmayr - 2007 - Derivation of the Koenderink equation List of Figures.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
pages = {1--17},
title = {{Derivation of the Koenderink equation List of Figures}},
volume = {58},
year = {2007}
}
@article{Hillen2011a,
author = {Hillen, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hillen - 2011 - Biorobotics, Embodiment, {\&} (Spatial) Cognition.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Biorobotics, Embodiment, {\&} (Spatial) Cognition}},
year = {2011}
}
@article{Hillen2011,
author = {Hillen, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hillen - 2011 - Map-based navigation in animals and humans.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{Map-based navigation in animals and humans}},
year = {2011}
}
@article{Gerstmayr2008,
author = {Gerstmayr, Lorenz},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerstmayr - 2008 - An Improvement of the Lucas-Kanade Optical-Flow Algorithm for every Circumstance.pdf:pdf},
mendeley-groups = {Robotics/UniBi - Mobile Roboter/lgerstmayr},
title = {{An Improvement of the Lucas-Kanade Optical-Flow Algorithm for every Circumstance}},
year = {2008}
}
@article{IoTWorkingGroup,
author = {{IoT Working Group}},
file = {:home/tkorthals/Documents/Mendeley Desktop/IoT Working Group - Unknown - Future-proofing the Connected World 13 Steps to Developing Secure IoT Products.pdf:pdf},
keywords = {iot,security,smart,smart home,smarthome},
mendeley-groups = {Systems Engineering},
mendeley-tags = {iot,security,smart,smart home,smarthome},
title = {{Future-proofing the Connected World: 13 Steps to Developing Secure IoT Products}}
}
@article{Korthals2016,
author = {Korthals, Timo and Barther, Marvin and Herbrechtsmeier, Stefan},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korthals, Barther, Herbrechtsmeier - 2016 - Occupancy Grid Mapping with Highly Uncertain Range Sensors based on Inverse Particle Filters.pdf:pdf},
title = {{Occupancy Grid Mapping with Highly Uncertain Range Sensors based on Inverse Particle Filters}},
year = {2016}
}
@inproceedings{MeyerzuBorgsen2016,
author = {{Meyer zu Borgsen}, Sebastian and Korthals, Timo and Lier, Florian and Wachsmuth, Sven},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyer zu Borgsen et al. - 2016 - ToBI - Team of Bielefeld Enhancing Robot Behaviors and the Role of Multi-Robotics in RoboCup@Home.pdf:pdf},
title = {{ToBI - Team of Bielefeld: Enhancing Robot Behaviors and the Role of Multi-Robotics in RoboCup@Home}},
year = {2016}
}
@article{Kersting2015,
author = {Kersting, Martin},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kersting - 2015 - Independent and future-proof decoupling of hardware and software through image abstraction.pdf:pdf},
keywords = {api,camera,cvb,stemmer},
mendeley-groups = {Robotics/TeleWerkBank/Stemmer},
mendeley-tags = {api,camera,cvb,stemmer},
title = {{Independent and future-proof : decoupling of hardware and software through image abstraction}},
year = {2015}
}
@inproceedings{HerbrechtsmeierKorthals2016,
author = {Herbrechtsmeier, Stefan and Korthals, Timo and Sch{\"{o}}pping, Thomas and R{\"{u}}ckert, Ulrich},
booktitle = {ICSTCC},
file = {:home/tkorthals/Documents/Mendeley Desktop/Herbrechtsmeier et al. - 2016 - AMiRo A Modular {\&} Customizable Open-Source Mini Robot Platform.pdf:pdf},
isbn = {9781509027200},
title = {{AMiRo: A Modular {\&} Customizable Open-Source Mini Robot Platform}},
year = {2016}
}
@techreport{Sharma2016,
author = {Sharma, Suchit},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sharma - 2016 - Installation of a RGBD sensor and simu- lation of laser scanner for building maps with CoreSLAM on AMiRo.pdf:pdf},
keywords = {ASE,Autonommous Systems Engineering},
mendeley-groups = {Robotics/AMiRo},
mendeley-tags = {ASE,Autonommous Systems Engineering},
title = {{Installation of a RGBD sensor and simu- lation of laser scanner for building maps with CoreSLAM on AMiRo}},
year = {2016}
}
@techreport{Daberkow2016,
author = {Daberkow, Julian and Exner, Julian and Gatting, Andreas and Michalski, Timo and Oestreich, Hendrik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Daberkow et al. - 2016 - Autonomes Ladeverhalten f{\"{u}}r den AMiRo im Rahmen eines Fu{\ss}ballszenarios.pdf:pdf},
keywords = {ASE,Autonomous Systems Engineering},
mendeley-groups = {Robotics/AMiRo},
mendeley-tags = {ASE,Autonomous Systems Engineering},
title = {{Autonomes Ladeverhalten f{\"{u}}r den AMiRo im Rahmen eines Fu{\ss}ballszenarios}},
year = {2016}
}
@inproceedings{Kragh2016,
address = {Aarhus},
author = {Kragh, Mikkel and Christiansen, Peter and Korthals, Timo and Jungeblut, Thorsten and Karstoft, Henrik and J{\o}rgensen, Rasmus N.},
booktitle = {International Conference on Agricultural Engineering},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kragh et al. - 2016 - Multi-Modal Obstacle Detection and Evaluation of Occupancy Grid Mapping in Agriculture.pdf:pdf},
title = {{Multi-Modal Obstacle Detection and Evaluation of Occupancy Grid Mapping in Agriculture}},
url = {http://conferences.au.dk/uploads/tx{\_}powermail/2016cigr{\_}-{\_}multi-modal{\_}obstacle{\_}detection{\_}and{\_}evaluation{\_}of{\_}evidence{\_}grid{\_}mapping{\_}in{\_}agriculture.pdf},
year = {2016}
}
@book{Miskowicz2016,
abstract = {Event-based systems are a class of reactive systems deployed in a wide spectrum of engineering disciplines including control, communication, signal processing, and electronic instrumentation. Activities in event-based systems are triggered in response to events usually representing a significant change of the state of controlled or monitored physical variables. Event-based systems adopt a model of calls for resources only if it is necessary, and therefore, they are characterized by efficient utilization of communication bandwidth, computation capability, and energy budget. Currently, the economical use of constrained technical resources is a critical issue in various application domains because many systems become increasingly networked, wireless, and spatially distributed. Event-Based Control and Signal Processing examines the event-based paradigm in control, communication, and signal processing, with a focus on implementation in networked sensor and control systems. Featuring 23 chapters contributed by more than 60 leading researchers from around the world, this book covers: Methods of analysis and design of event-based control and signal processing Event-driven control and optimization of hybrid systems Decentralized event-triggered control Periodic event-triggered control Model-based event-triggered control and event-triggered generalized predictive control Event-based intermittent control in man and machine Event-based PID controllers Event-based state estimation Self-triggered and team-triggered control Event-triggered and time-triggered real-time architectures for embedded systems Event-based continuous-time signal acquisition and DSP Statistical event-based signal processing in distributed detection and estimation Asynchronous spike event coding technique with address event representation Event-based processing of non-stationary signals Event-based digital (FIR and IIR) filters Event-based local bandwidth estimation and signal reconstruction Event-Based Control and Signal Processing is the first extensive study on both event-based control and event-based signal processing, presenting scientific contributions at the cutting edge of modern science and engineering.},
author = {Miskowicz, Marek},
file = {:home/tkorthals/Documents/Mendeley Desktop/Miskowicz - 2016 - Event-Based Control and Signal Processing.pdf:pdf},
isbn = {148225655X},
mendeley-groups = {Systems Engineering},
pages = {582},
publisher = {CRC Press},
title = {{Event-Based Control and Signal Processing}},
year = {2016}
}
@article{Dietmayer2005,
author = {Dietmayer, Klaus and Kirchner, Alexander},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dietmayer, Kirchner - 2005 - Fusionsarchitekturen zur Umfeldwahrnehmung f{\"{u}}r zuk{\"{u}}nftige Fahrerassistenzsysteme.pdf:pdf},
journal = {Fahrerassistenzsysteme},
mendeley-groups = {CLAAS itsowl/Books},
title = {{Fusionsarchitekturen zur Umfeldwahrnehmung f{\"{u}}r zuk{\"{u}}nftige Fahrerassistenzsysteme}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=IdVIKkGSDw4C{\&}oi=fnd{\&}pg=PA59{\&}dq=Fusionsarchitekturen+zur+Umfeldwahrnehmung+f{\"{u}}r+zuk{\"{u}}nftige+Fahrerassistenzsysteme{\&}ots=UcE5p4pnEJ{\&}sig=urYR0WOelb5WrP6SdycEgHZEIZc},
year = {2005}
}
@book{Zurawski2006,
abstract = {Embedded systems are nearly ubiquitous, and books on individual topics or components of embedded systems are equally abundant. Unfortunately, for those designers who thirst for knowledge of the big picture of embedded systems there is not a drop to drink. Until now. The Embedded Systems Handbook is an oasis of information, offering a mix of basic and advanced topics, new solutions and technologies arising from the most recent research efforts, and emerging trends to help you stay current in this ever-changing field. With preeminent contributors from leading industrial and academic institutions around the globe, this authoritative handbook presents timely tutorials, surveys, and technological overviews spanning the range of issues and technologies involved in embedded systems. Many of the technology developments, deployments, and trends are made available in this book for the first time. Six sections provide coherence to the presentation, detailing: A broad introduction to embedded systems System- and network-on-chip (SoC/NoC) design Testing of embedded core-based integrated circuits Networked embedded systems Sensor networks, and Automotive, industrial automation, and intelligent sensor applications With concise yet comprehensive coverage of the latest developments, solutions, tools, products, and research results, the Embedded Systems Handbook is ideal for both novices and seasoned engineers looking to enhance and expand embedded systems capabilities.},
address = {London},
author = {Zurawski, Richard},
booktitle = {Embedded Systems Handbook},
editor = {Zurawski, Richard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zurawski - 2006 - Embedded Systems Handbook.pdf:pdf},
isbn = {9781420074109},
keywords = {Blackboard,ECU,Publisher subscriber,RTS},
mendeley-groups = {Systems Engineering/Embedded Systems},
mendeley-tags = {Blackboard,ECU,Publisher subscriber,RTS},
pages = {1503},
publisher = {CRC Press},
title = {{Embedded Systems Handbook}},
year = {2006}
}
@techreport{Amir2004,
abstract = {The Spread toolkit is a group communication system available from www.spread.org. Spread provides a range of reliability, ordering and stability guarantees for message delivery. Spread supports a rich fault model that includes process crashes and recoveries and network partitions and merges under the extended virtual synchrony semantics. The standard virtual synchrony semantics is also supported.},
author = {Amir, Yair and Danilov, Claudiu and Miskin-Amir, Michal and Schultz, John and Stanton, Jonathan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Amir et al. - 2004 - The Spread Toolkit Architecture and Performance.pdf:pdf},
keywords = {network,spread},
mendeley-groups = {Robotics/Architectures},
mendeley-tags = {network,spread},
pages = {1--2},
title = {{The Spread Toolkit: Architecture and Performance}},
url = {http://www.cnds.jhu.edu/pub/papers/cnds-2004-1.pdf},
year = {2004}
}
@book{koubaa2016robot,
abstract = {ROS (Robot Operating System) provides libraries and tools to help software developers create robot applications. It provides hardware abstraction, device drivers, libraries, visualizers, message-passing, package management, and more. ROS is licensed under an open source, BSD license.},
author = {Koubaa, A.},
booktitle = {Studies in Computational Intelligence},
doi = {10.1007/978-3-319-26054-9},
file = {:home/tkorthals/Documents/Mendeley Desktop/Koubaa - 2016 - Robot Operating System (ROS) The Complete Reference.pdf:pdf},
isbn = {9783319260549},
issn = {1860949X},
mendeley-groups = {Robotics/Architectures,Robotics/ROS},
number = {1},
publisher = {Springer International Publishing},
title = {{Robot Operating System (ROS): The Complete Reference}},
url = {http://courses.csail.mit.edu/6.141/spring2012/pub/lectures/Lec06-ROS.pdf},
volume = {1},
year = {2016}
}
@article{Borman2009,
abstract = {This tutorial discusses the ExpectationMaximization (EM) algorithm of Demp- ster, Laird and Rubin 1. The approach taken follows that of an unpublished note by Stuart Russel, but fleshes out some of the gory details. In order to ensure that the presentation is reasonably self-contained, some of the results on which the derivation of the algorithm is based are presented prior to the main results. The EM algorithm has become a popular tool in statistical estimation problems involving incomplete data, or in problems which can be posed in a sim- ilar form, such as mixture estimation 3, 4. The EM algorithm has also been used in various motion estimation frameworks 5 and variants of it have been used in multiframe superresolution restoration methods which combine motion estimation along the lines of 2.},
author = {Borman, Sean},
doi = {10.1097/RLU.0b013e3181b06c41\r00003072-200909000-00002},
file = {:home/tkorthals/Documents/Mendeley Desktop/Borman - 2009 - The Expectation Maximization Algorithm - A short tutorial.pdf:pdf},
issn = {15360229},
journal = {Submitted for publication},
keywords = {EM,Expectation Maximization},
mendeley-groups = {Master},
mendeley-tags = {EM,Expectation Maximization},
number = {x},
pages = {1--9},
pmid = {19692813},
title = {{The Expectation Maximization Algorithm - A short tutorial}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.8193{\&}rep=rep1{\&}type=pdf},
volume = {25},
year = {2009}
}
@article{Dempster1977,
abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
archivePrefix = {arXiv},
arxivId = {0710.5696v2},
author = {Dempster, A.P. AP and Laird, N.M. NM and Rubin, DB Donald B.},
doi = {http://dx.doi.org/10.2307/2984875},
eprint = {0710.5696v2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dempster, Laird, Rubin - 1977 - Maximum likelihood from incomplete data via the EM algorithm.pdf:pdf},
isbn = {0000000779},
issn = {00359246},
journal = {Journal of the Royal Statistical Society Series B Methodological},
mendeley-groups = {Master},
number = {1},
pages = {1--38},
pmid = {9501024},
title = {{Maximum likelihood from incomplete data via the EM algorithm}},
url = {http://www.jstor.org/stable/10.2307/2984875},
volume = {39},
year = {1977}
}
@inproceedings{Nuss2014,
abstract = {Occupancy grid mapping, street topology estimation, and object tracking are basic modules of vehicular environmental perception systems. For the sake of expandability and adaptability, this contribution proposes a hierarchical modular environmental perception architecture (HMEP). It limits the interactivity between individual basic modules. In a combination module, the consistency between occupancy grid cells and object tracks is evaluated. This allows to distinguish between static and dynamic parts of the environment in a post- processing step. Efficient algorithms for implementation of the combination module are provided and an evaluation based on simulation and real data is presented.},
author = {Nuss, Dominik and Stuebler, Manuel and Dietmayer, Klaus},
booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
doi = {10.1109/IVS.2014.6856516},
isbn = {9781479936380},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {1371--1377},
title = {{Consistent environmental modeling by use of occupancy grid maps, digital road maps, and multi-object tracking}},
year = {2014}
}
@article{Danescu2011,
abstract = {Modeling and tracking the driving environment is a complex problem due to the heterogeneous nature of the real world. In many situations, modeling the obstacles and the driving surfaces can be achieved by the use of geometrical objects, and tracking becomes the problem of estimating the parameters of these objects. In the more complex cases, the scene can be modeled and tracked as an occupancy grid. This paper presents a novel occupancy grid tracking solution based on particles for tracking the dynamic driving environment. The particles will have a dual nature{\&}{\#}x2014;they will denote hypotheses, as in the particle filtering algorithms, but they will also be the building blocks of our modeled world. The particles have position and speed, and they can migrate in the grid from cell to cell, depending on their motion model and motion parameters, but they will be also created and destroyed using a weighting-resampling mechanism that is specific to particle filtering algorithms. The tracking algorithm will be centered on particles, instead of cells. An obstacle grid derived from processing a stereovision-generated elevation map is used as measurement information, and the measurement model takes into account the uncertainties of the stereo reconstruction. The resulting system is a flexible real-time tracking solution for dynamic unstructured driving environments.},
author = {Danescu, Radu and Oniga, Florin and Nedevschi, Sergiu},
doi = {10.1109/TITS.2011.2158097},
issn = {15249050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Environment modeling,occupancy grids,particle filtering,stereovision,tracking},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
number = {4},
pages = {1331--1342},
title = {{Modeling and tracking the driving environment with a particle-based occupancy grid}},
volume = {12},
year = {2011}
}
@inproceedings{Li2012,
abstract = {Autonomous mapping, especially in the form of SLAM (Simultaneous Localization And Mapping), has long since been used for many indoor robotic applications and is also useful in outdoor intelligent vehicle applications such as object detection. Most existing research works on environment mapping and object detection in outdoor applications have been dedicated to single vehicle system. On the other hand, multi-vehicle cooperative perception based on inter-vehicle data sharing can bring considerable benefits in many scenarios that are challenging for a single vehicle system. In this paper, a new method for occupancy grid maps merging is proposed: an objective function based on occupancy likelihood is introduced to measure the consistency degree of maps alignment; genetic algorithm implemented in a dynamic scheme is adopted to optimize the objective function. A scheme of multi-vehicle cooperative local mapping and moving object detection using the proposed occupancy grid maps merging method is also introduced. Real-data tests are given to demonstrate the effectiveness of the introduced method.},
author = {Li, Hao and Nashashibi, Fawzi},
booktitle = {2012 12th International Conference on Control, Automation, Robotics and Vision, ICARCV 2012},
doi = {10.1109/ICARCV.2012.6485231},
isbn = {9781467318716},
keywords = {SLAM,cooperative perception,moving object detection,occupancy grid map},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {632--637},
title = {{A new method for occupancy grid maps merging: Application to multi-vehicle cooperative local mapping and moving object detection in outdoor environment}},
year = {2012}
}
@article{Jungnickel2014,
abstract = {Autonomous driving is one of the most challenging tasks of the automotive industry. As a subtask, the estimation of driveable and non driveable space is often solved by applying occupancy grids. The information about non driveable space can be used to improve object tracking. This paper presents an approach for object tracking and modelling in an occupancy grid map. Tracking objects on grid cells yields the advantage of a consistent environmental model on the occupancy grid map. We introduce the occupancy grid map as the only information source for the object tracking module. Taking advantage of the Dempster Shafer theory, a dynamic belief of conflicting cells can be estimated. This dynamic belief is then accumulated in a tracked object model. This is a grid based free form object model that uses detached grid cells to model vehicles in urban environment. We reduce false positives and initialization time by maintaining a dynamic belief for each object.},
author = {Jungnickel, Ruben and Korf, Franz},
doi = {10.1109/ITSC.2014.6958060},
isbn = {978-1-4799-6078-1},
journal = {17th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
keywords = {DATMO,Evidential Grid,Laser Scanner,Object Tracking,Occupancy Grid Map,Particle Filter},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {2310--2316},
title = {{Object tracking and dynamic estimation on evidential grids}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6958060},
year = {2014}
}
@article{Vu2011,
abstract = {We present a real-time algorithm for simultaneous localization and local mapping (local SLAM) with detection and tracking of moving objects (DATMO) in dynamic outdoor environments from a moving vehicle equipped with a laser scanner, short-range radars and odometry. To correct the vehicle odometry we introduce a new fast implementation of incremental scan matching method that can work reliably in dynamic outdoor environments. After obtaining a good vehicle localization, the map surrounding of the vehicle is updated incrementally and moving objects are detected without a priori knowledge of the targets. Detected moving objects are finally tracked by a Multiple Hypothesis Tracker (MHT) coupled with an adaptive Interacting Multiple Model (IMM) filter. The experimental results on datasets collected from different scenarios such as: urban streets, country roads and highways demonstrate the efficiency of the proposed algorithm. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Vu, Trung Dung and Burlet, Julien and Aycard, Olivier},
doi = {10.1016/j.inffus.2010.01.004},
isbn = {0000000000000},
issn = {15662535},
journal = {Information Fusion},
keywords = {Interacting Multiple Model,Laser radar data fusion,Moving object detection,Multiple object tracking,Occupancy grid,Simultaneous localization and mapping},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
number = {1},
pages = {58--69},
title = {{Grid-based localization and local mapping with moving object detection and tracking}},
volume = {12},
year = {2011}
}
@inproceedings{Brechtel2010,
abstract = {Bayesian Occupancy Filtering is an alternative to classical object tracking. Instead of estimating the state of objects in the environment, the latter is separated into equidistant cells. Tracking the occupancy state of these grid-cells is sufficient for many applications in robotics and cell-measurements can be easily produced from almost any kind of sensor. In [6] a sophisticated occupancy filter named BOFUM (Bayesian Occupancy Tracking using prior Map Knowledge) is introduced, which is able to infer velocities solely from occupancy measurements. It also features an advanced process model with motion uncertainty, which can be specialized for different application needs. In this paper we present an approach for recursively applying importance sampling (IS) to approximate the BOFUM calculations. The approach is similar to well known particle filters, but for a discrete cell perspective. In our experiments we achieved a speedup of at least 40-times by using the IS, thus making the algorithm applicable in real-world applications. We evaluate the consequences of approximation in an urban traffic scenario and also show the drawbacks of sampling.},
author = {Brechtel, Sebastian and Gindele, Tobias and Dillmann, R{\"{u}}diger},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509931},
isbn = {9781424450381},
issn = {10504729},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {3932--3938},
title = {{Recursive importance sampling for efficient grid-based occupancy filtering in dynamic environments}},
year = {2010}
}
@article{Danescu2012,
abstract = {This paper presents an occupancy grid tracking solution based on particles. The particles will have a dual nature - they will denote hypotheses, as in the particle filtering algorithms, but they will also be the building blocks of our modeled world. The particles have position and speed, and they can migrate in the grid from cell to cell depending on their motion model and motion parameters, but they will also be created and destroyed using a weighting-resampling mechanism specific to particle filter algorithms. An obstacle grid derived from processing a stereovision-generated elevation map is used as measurement information, and the measurement model takes into account the uncertainties of the stereo reconstruction. The resulted system is a flexible, real-time tracking solution for dynamic unstructured driving environments.},
author = {Danescu, Radu and Pantilie, Cosmin and Oniga, Florin and Nedevschi, Sergiu},
doi = {10.1109/MITS.2011.2178492},
isbn = {9781424478668},
issn = {1931-0587},
journal = {IEEE Intelligent Transportation Systems Magazine},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
number = {1},
pages = {6--20},
title = {{Particle grid tracking system stereovision based obstacle perception in driving environments}},
volume = {4},
year = {2012}
}
@inproceedings{Tanzmeister2014,
abstract = {Mapping and tracking in dynamic environments for autonomously-moving robots is still challenging, despite being essential tasks. They are often done separately using occupancy grids and established object tracking algorithms. In this work, an approach is presented that estimates a uniform, low-level, grid-based world model including dynamic and static objects, their uncertainties, as well as their velocities. It does not require existing object tracks to filter out data points not used for creating and updating the map. Nor does it require that measurements can be classified into belonging to a static or to a moving object. Promising results from experiments with an autonomous vehicle equipped with a laser scanner demonstrate the usefulness of the approach.},
author = {Tanzmeister, Georg and Thomas, Julian and Wollherr, Dirk and Buss, Martin},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2014.6907756},
isbn = {978-1-4799-3685-4},
issn = {10504729},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {6090--6095},
title = {{Grid-based mapping and Tracking in dynamic environments using a uniform evidential environment representation}},
year = {2014}
}
@inproceedings{Dubois2011,
abstract = {This work is related to the development of a marker less system allowing the tracking of elderly people at home. Microsoft Kinect is a low cost 3D camera adapted to the tracking of human movements. We propose a method for making the fusion of the information provided by several Kinects. The observed space is tesselated into cells forming a 3D occupancy grid. We calculate a probability of occupation for each cell of the grid. From this probability we distinguish whether the cells are occupied or not by a static object (wall) or a mobile object (chair, human being). This categorization is realized in real-time using a simple three states HMM. The proposed method for discriminating between mobile and static objects in a room is the main contribution of this paper. The use of HMMs allows to deal with an aliasing problem since mobile objects result in the same observation as static objects. The approach is evaluated in simulation and in a real environment showing an efficient real-time discrimination between cells occupied by mobile objects and cells occupied by static objects.},
author = {Dubois, Amandine and Dib, Abdallah and Charpillet, Fran{\c{c}}ois},
booktitle = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
doi = {10.1109/ICTAI.2011.188},
isbn = {9780769545967},
issn = {10823409},
keywords = {Depth image,Hidden Markov model,Mobile object tracking,Occupancy grid},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {170--176},
title = {{Using HMMs for discriminating mobile from static objects in a 3D occupancy grid}},
year = {2011}
}
@inproceedings{Bouzouraa2010,
abstract = {in this paper we present a novel environment perception system based on an occupancy grid mapping and a multi-object tracking. The goal of such a system is to create a harmonic, consistent and complete representation of the vehicle environment as a base for future advanced driver assistance systems. In addition to a mathematical formulation of the problem we present a robust algorithm to detect dynamic obstacles from the occupancy map and show how both, the mapping process and the tracking can benefit from each other. Therefore, the concept of moving objects with associated dynamic cells is introduced. The presented techniques are applicable to both 2D and 3D mapping and can be also extended to correct the ego motion from the occupancy map and the object tracks. Unlike many publications over the last years our work provides real time performance and an accurate detection of obstacles with real laser and radar sensors and can fulfill the requirements of future driver assistance systems.},
author = {Bouzouraa, Mohamed Essayed and Hofmann, Ulrich},
booktitle = {2010 IEEE Intelligent Vehicles Symposium},
doi = {10.1109/IVS.2010.5548106},
isbn = {978-1-4244-7866-8},
issn = {1931-0587},
keywords = {2D mapping,3D mapping,Heuristic algorithms,Laser fusion,Laser modes,Laser radar,Radar tracking,Robustness,Sensor fusion,Sensor systems,Vehicle driving,Vehicle dynamics,advanced driver assistance systems,cartography,driver information systems,dynamic obstacles detection,ego motion,environment perception system,image sensors,laser sensors,multiobject tracking,object detection,occupancy grid mapping fusion,radar sensors,tracking},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {294--300},
title = {{Fusion of occupancy grid mapping and model based object tracking for driver assistance systems using laser and radar sensors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5548106},
year = {2010}
}
@inproceedings{Schutz2014,
abstract = {Robust tracking of extended objects plays a major role in research on highly automated driving applications and advanced driver assistance systems. This paper proposes a new approach to estimate the extension of dynamic objects based on object-local occupancy grid maps. This enables estimating free-formed object shapes while being robust against errors coming from, e.g., incorrect segmentation or association. Its benefit is shown based on 4-layer laser scanner sensor data and is evaluated against a ground truth based on a D-GPS system fused with a highly accurate IMU.},
author = {Schutz, Markus and Appenrodt, Nils and Dickmann, Jurgen and Dietmayer, Klaus},
booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
doi = {10.1109/IVS.2014.6856504},
isbn = {9781479936380},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {1205--1210},
title = {{Occupancy grid map-based extended object tracking}},
year = {2014}
}
@misc{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - Unknown - Detektion und Tracking dynamische Objekte in Occupancy Grids.pdf:pdf},
title = {{Detektion und Tracking dynamische Objekte in Occupancy Grids}}
}
@article{Konrad2011,
author = {Konrad, Marcus and Fuchsy, Manuel and Loehlein, Otto and Dietmayer, Klaus},
file = {:home/tkorthals/Documents/Mendeley Desktop/Konrad et al. - 2011 - Detektion und Tracking dynamischer Objekte in Occupancy Grids.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {105--114},
title = {{Detektion und Tracking dynamischer Objekte in Occupancy Grids}},
url = {http://www.ifr.ing.tu-bs.de/institut/veranstaltungen/fas2011/fas11{\_}programm.pdf},
year = {2011}
}
@article{Moore2016,
abstract = {Accurate state estimation for a mobile robot often requires the fusion of data from multiple sensors. Software that performs sensor fusion should therefore support the inclusion of a wide array of heterogeneous sensors. This paper presents a software package, robot{\_}localization, for the robot operating system (ROS). The package currently contains an implementation of an extended Kalman filter (EKF). It can support an unlimited number of inputs from multiple sensor types, and allows users to customize which sensor data fields are fused with the current state estimate. In this work, we motivate our design decisions, discuss implementation details, and provide results from real-world tests. {\textcopyright} Springer International Publishing Switzerland 2016.},
author = {Moore, Thomas and Stouch, Daniel},
doi = {10.1007/978-3-319-08338-4_25},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moore, Stouch - 2016 - A generalized extended Kalman filter implementation for the robot operating system.pdf:pdf},
isbn = {9783319083377},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Extended kalman filter,Localization,Robot operating System,Sensor fusion},
mendeley-groups = {Robotics/Localization},
pages = {335--348},
title = {{A generalized extended Kalman filter implementation for the robot operating system}},
volume = {302},
year = {2016}
}
@article{Challa2004,
author = {Challa, Subhash and Koks, D O N},
file = {:home/tkorthals/Documents/Mendeley Desktop/Challa, Koks - 2004 - Bayesian and Dempster – Shafer fusion.pdf:pdf},
keywords = {bayesian fusion,chapman,dempster,kalman filter,kolmogorov prediction integral,shafer fusion},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {April},
pages = {145--176},
title = {{Bayesian and Dempster – Shafer fusion}},
volume = {29},
year = {2004}
}
@article{Elkady2012,
abstract = {Autonomous robots are complex systems that require the interaction between numerous heterogeneous components (software and hardware). Because of the increase in complexity of robotic applications and the diverse range of hardware, robotic middleware is designed to manage the complexity and heterogeneity of the hardware and applications, promote the integration of new technologies, simplify software design, hide the complexity of low-level communication and the sensor heterogeneity of the sensors, improve software quality, reuse robotic software infrastructure across multiple research efforts, and to reduce production costs. This paper presents a literature survey and attribute-based bibliography of the current state of the art in robotic middleware design. The main aim of the survey is to assist robotic middleware researchers in evaluating the strengths and weaknesses of current approaches and their appropriateness for their applications. Furthermore, we provide a comprehensive set of appropriate bibliographic references that are classified based on middleware attributes.},
author = {Elkady, Ayssam and Sobh, Tarek},
doi = {10.1155/2012/959013},
file = {:home/tkorthals/Documents/Mendeley Desktop/Elkady, Sobh - 2012 - Robotics Middleware A Comprehensive Literature Survey and Attribute-Based Bibliography.pdf:pdf},
isbn = {1687-9600},
issn = {1687-9600},
journal = {Journal of Robotics},
mendeley-groups = {Robotics/Middleware},
pages = {15},
title = {{Robotics Middleware: A Comprehensive Literature Survey and Attribute-Based Bibliography}},
url = {http://dx.doi.org/10.1155/2012/959013},
volume = {2012},
year = {2012}
}
@article{Smart2007,
abstract = {Despite many decades of work in robotics, we are still lacking a well-accepted common software architecture, middleware, and shared low-level functionality. Most research groups still write their own systems, and any software developed by these groups tends to be strongly tied to their architecture, their middleware, and their robots. This make the sharing of software and, by extension, well-implemented algorithms, extremely difficult, if not impossible. This lack of sharing is seriously impeding robotics research, as we spend our time reimplementing known algorithms and techniques, rather than discovering new ones. In this paper, we outline some of the key problems that stand in the way of developing a widely-accepted set of middleware for robotics. We discuss why the development of this middleware is vital to the long-term success of our field, and offer some suggestions on how to get started.},
author = {Smart, William},
file = {:home/tkorthals/Documents/Mendeley Desktop/Smart - 2007 - Is a common middleware for robotics possible.pdf:pdf},
journal = {{\ldots} the Evaluation of Robot Architectures and Middleware},
mendeley-groups = {Robotics/Middleware},
title = {{Is a common middleware for robotics possible?}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.3135{\&}rep=rep1{\&}type=pdf},
year = {2007}
}
@article{Prochazka2015,
abstract = {The objective of our research is to explore crowd dynamics under different circumstances, especially its optional applications in sustainable tourism. The terminology (crowd phenomena, pedestrian behaviour, local interaction, motion patterns) is explained and a brief overview of three theoretical models (cellular automata model, social force model and network model) is provided. Then our visitor flow model is suggested and the case study, the model of the crowd dynamics of visitors in the ZOO, is specified. NetLogo was used for implementation.},
author = {Proch{\'{a}}zka, Jan and Cimler, Richard and Ol{\v{s}}evi{\v{c}}ov{\'{a}}, Kamila},
doi = {10.1007/978-3-319-10783-7},
file = {:home/tkorthals/Documents/Mendeley Desktop/Proch{\'{a}}zka, Cimler, Ol{\v{s}}evi{\v{c}}ov{\'{a}} - 2015 - Emergent Trends in Robotics and Intelligent Systems.pdf:pdf},
isbn = {978-3-319-10782-0},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
mendeley-groups = {Robotics/Middleware},
pages = {303--312},
title = {{Emergent Trends in Robotics and Intelligent Systems}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84921395595{\&}partnerID=tZOtx3y1},
volume = {316},
year = {2015}
}
@techreport{DIN1973,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {DIN},
booktitle = {DIN},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/DIN - 1973 - Graphische Darstellung in Koordinatensystemen.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
mendeley-groups = {Normen},
pmid = {25246403},
title = {{Graphische Darstellung in Koordinatensystemen}},
year = {1973}
}
@phdthesis{Druke2013,
author = {Dr{\"{u}}ke, Christian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dr{\"{u}}ke - 2013 - Navigation in Geb{\"{a}}uden mit Hilfe der Inertialsensorik eines Smartphones.pdf:pdf},
title = {{Navigation in Geb{\"{a}}uden mit Hilfe der Inertialsensorik eines Smartphones}},
year = {2013}
}
@article{Bardaro2014,
author = {Bardaro, G},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bardaro - 2014 - High level control architecture and dynamic simulation for an autonomous all terrain robot.pdf:pdf},
mendeley-groups = {Robotics/Architectures},
title = {{High level control architecture and dynamic simulation for an autonomous all terrain robot}},
url = {https://www.politesi.polimi.it/handle/10589/97402},
year = {2014}
}
@article{Muad2004,
abstract = {Vision based automatic lane tracking system requires information such as lane markings, road curvature and leading vehicle be detected before capturing the next image frame. Placing a camera on the vehicle dashboard and capturing the forward view results in a perspective view of the road image. The perspective view of the captured image somehow distorts the actual shape of the road, which involves the width, height, and depth. Respectively, these parameters represent the x, y and z components. As such, the image needs to go through a pre-processing stage to remedy the distortion using a transformation technique known as an inverse perspective mapping (IPM). This paper outlines the procedures involved.},
author = {a.M. Muad and Hussain, A. and Samad, S.a. and Mustaffa, M.M. and Majlis, B.Y.},
doi = {10.1109/TENCON.2004.1414393},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muad et al. - 2004 - Implementation of inverse perspective mapping algorithm for the development of an automatic lane tracking system.pdf:pdf},
isbn = {0-7803-8560-8},
journal = {2004 IEEE Region 10 Conference TENCON 2004.},
keywords = {foreshortening factor,inverse perspective mapping,ipm,vanishing point},
mendeley-groups = {CLAAS itsowl/Inverse Perspective Mapping},
pages = {207--210},
title = {{Implementation of inverse perspective mapping algorithm for the development of an automatic lane tracking system}},
volume = {A},
year = {2004}
}
@book{Chen2012,
author = {Chen, Xiaoping and Stone, Peter and Sucar, Luis Enrique and Zant, Tijn Van Der},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chen et al. - 2012 - RoboCup 2012 Robot Soccer World Cup XVI.pdf:pdf},
isbn = {9783642392498},
keywords = {scanline,scanlines},
mendeley-groups = {Robotics/RoboCup},
mendeley-tags = {scanline,scanlines},
title = {{RoboCup 2012: Robot Soccer World Cup XVI}},
year = {2012}
}
@article{Johnson1998,
abstract = {Based on "Stereo inverse perspective mapping: theory and applications"$\backslash$n(Betozzi, Broggi, and$\backslash$n$\backslash$nFasioli, 1998) along with "GOLD: A Parallel Real-Time Stereo Vision$\backslash$nSystem for Generic Obstacle$\backslash$n$\backslash$nand Lane Detection" (Bertozzi and Broggi, 1998). Between these two$\backslash$npapers, we were finally able$\backslash$n$\backslash$nto fill in the holes in the definitions of their equations, variable,$\backslash$nand coordinates.$\backslash$n$\backslash$nWe modified variable names for convenience and reworked things slightly$\backslash$nso that the world$\backslash$n$\backslash$ncoordinate system would be right-handed and to allow for a non-square$\backslash$nimage.},
author = {Johnson, Ericand and Hamburger, Randy},
file = {:home/tkorthals/Documents/Mendeley Desktop/Johnson, Hamburger - 1998 - Test of Bertozzi and Broggi's Inverse Perspective Mapping Functions.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Inverse Perspective Mapping},
pages = {2--5},
title = {{Test of Bertozzi and Broggi's Inverse Perspective Mapping Functions}},
url = {http://www.eng.utah.edu/{~}hamburge/ http://www.eng.utah.edu/{~}hamburge/CVprojectCode/},
year = {1998}
}
@inproceedings{Konrad2011_2,
author = {Konrad, Marcus and Dietmayer, Klaus},
booktitle = {International Workshop on Intelligent Transportation},
mendeley-groups = {Robotics/Maps/OGM},
pages = {167--172},
title = {{Occupancy Grid Mapping using the Dempster-Shafer-Theory}},
year = {2011}
}
@article{Bertozzi1996,
abstract = {This paper describes the GOLD (generic obstacle and lane$\backslash$ndetection) system, a stereo vision-based hardware and software$\backslash$narchitecture developed to increment road safety of moving vehicles: it$\backslash$nallows detection of both generic obstacles (without constraints on$\backslash$nsymmetry or shape) and the lane position in a structured environment$\backslash$n(with painted lane markings). It has been implemented on the PAPRICA$\backslash$nsystem and works at a rate of 10 Hz},
author = {Bertozzi, M. and Broggi, a.},
doi = {10.1109/IVS.1996.566380},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bertozzi, Broggi - 1996 - Real-time lane and obstacle detection on the GOLD system.pdf:pdf},
isbn = {0-7803-3652-6},
journal = {Proceedings of Conference on Intelligent Vehicles},
mendeley-groups = {CLAAS itsowl/Inverse Perspective Mapping},
title = {{Real-time lane and obstacle detection on the GOLD system}},
year = {1996}
}
@article{Konrad2011,
abstract = {This paper presents a generic grid mapping approach which can be used to map huge areas. A special map definition based on so called grid patches is proposed to limit memory usage and make it real time capable. The grid cells of this map can hold arbitrary data which is calculated based on arbitrary sensors. Here, methods for mapping occupancy likelihoods based on laser scanner data, gray values calculated by an Inverse Perspective Mapping from video images and intensities from an imaging radar sensor are proposed. Furthermore, this contribution presents a road course estimation based on such a grid map which yields estimations above 120 m. Therefore, a digital road map (comparable to maps of GPS navigation systems) is matched to a laser scanner based grid map. In general, this approach is generic as well. Exemplarily, a method based on an occupancy grid map is presented.},
author = {Konrad, Marcus and Szczot, Magdalena and Sch{\"{u}}le, Florian and Dietmayer, Klaus},
doi = {10.1109/IVS.2011.5940514},
file = {:home/tkorthals/Documents/Mendeley Desktop/Konrad et al. - 2011 - Generic grid mapping for road course estimation.pdf:pdf},
isbn = {9781457708909},
issn = {1931-0587},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
keywords = {Inverse Perspective Mapping,Radar Grid Map},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM,Robotics/Maps},
mendeley-tags = {Inverse Perspective Mapping,Radar Grid Map},
number = {Iv},
pages = {851--856},
title = {{Generic grid mapping for road course estimation}},
year = {2011}
}
@article{Patzelt2015,
author = {Patzelt, Florian and Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Patzelt, Korthals - 2015 - Training Neuronal Nets to approximate the Inverse Sensor Model for the AMiRo - Presentation.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{Training Neuronal Nets to approximate the Inverse Sensor Model for the AMiRo - Presentation}},
year = {2015}
}
@techreport{Patzelt2015a,
author = {Patzelt, Florian and Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Patzelt, Korthals - 2015 - Training von neuronalen Netzen zur Approximation eines inversen Sensormodells f{\"{u}}r den AMiRo.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{Training von neuronalen Netzen zur Approximation eines inversen Sensormodells f{\"{u}}r den AMiRo}},
year = {2015}
}
@misc{Barther2015a,
author = {Barther, Marvin and Sharma, Suchit and Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Barther, Sharma, Korthals - 2015 - Automatic Odometry Calibration of the AMiRo Differential Kinematic - Presentation.ppt:ppt},
mendeley-groups = {Robotics/AMiRo},
title = {{Automatic Odometry Calibration of the AMiRo Differential Kinematic - Presentation}},
year = {2015}
}
@article{Jung,
author = {Jung, Changbae},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jung - Unknown - Project 1 Odometry.pdf:pdf},
pages = {1--3},
title = {{Project 1: Odometry}}
}
@misc{Goodfellow2016,
abstract = {The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
mendeley-groups = {Machine Learning},
title = {{Deep Learning}},
url = {http://www.deeplearningbook.org/},
year = {2016}
}
@article{Koenig2004,
abstract = { Simulators have played a critical role in robotics research as tools for quick and efficient testing of new concepts, strategies, and algorithms. To date, most simulators have been restricted to 2D worlds, and few have matured to the point where they are both highly capable and easily adaptable. Gazebo is designed to fill this niche by creating a 3D dynamic multi-robot environment capable of recreating the complex worlds that would be encountered by the next generation of mobile robots. Its open source status, fine grained control, and high fidelity place Gazebo in a unique position to become more than just a stepping stone between the drawing board and real hardware: data visualization, simulation of remote environments, and even reverse engineering of blackbox systems are all possible applications. Gazebo is developed in cooperation with the Player and Stage projects (Gerkey, B. P., et al., July 2003), (Gerkey, B. P., et al., May 2001), (Vaughan, R. T., et al., Oct. 2003), and is available from http://playerstage.sourceforge.net/gazebo/ gazebo.html.},
author = {Koenig, N. and Howard, a.},
doi = {10.1109/IROS.2004.1389727},
file = {:home/tkorthals/Documents/Mendeley Desktop/Koenig, Howard - 2004 - Design and use paradigms for Gazebo, an open-source multi-robot simulator.pdf:pdf},
isbn = {0-7803-8463-6},
journal = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
mendeley-groups = {Robotics/Simulation},
pages = {2149--2154},
title = {{Design and use paradigms for Gazebo, an open-source multi-robot simulator}},
volume = {3},
year = {2004}
}
@article{Herbrechtsmeier2016,
author = {Herbrechtsmeier, Stefan},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herbrechtsmeier - 2016 - Modell eines agilen Leiterplattenentwurfsprozesses basierend auf der interdisziplin{\"{a}}ren Entwicklung eines modu.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{Modell eines agilen Leiterplattenentwurfsprozesses basierend auf der interdisziplin{\"{a}}ren Entwicklung eines modularen autonomen Miniroboters}},
year = {2016}
}
@article{Hatle2012,
author = {Hatle, Mark and Ashfield, Bruce},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hatle, Ashfield - 2012 - Introduction to the Yocto Project.pdf:pdf},
mendeley-groups = {Systems Engineering/Yocto},
title = {{Introduction to the Yocto Project}},
year = {2012}
}
@techreport{Adams2006,
author = {Adams, Martin D},
file = {:home/tkorthals/Documents/Mendeley Desktop/Adams - 2006 - Exploration with a Map Occupancy Filter.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
title = {{Exploration with a Map Occupancy Filter}},
year = {2006}
}
@misc{Coue,
author = {Cou{\'{e}}, Christopher},
keywords = {Bayesian Occupency Filters,Bayesian robotics,Multi-target tracking,bayesian state estimation,occupancy grid,probabilistic robotics},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {2003},
title = {{Bayesian Programming}},
url = {http://emotion.inrialpes.fr/BP/spip.php?article52}
}
@misc{FurgoEarthdataInc.2011,
author = {{Furgo Earthdata Inc.}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Furgo Earthdata Inc. - 2011 - LiDAR Mapping Fact Sheet - Turning Spatial Data into Knowledge.pdf:pdf},
mendeley-groups = {Robotics/Sensing},
pages = {5},
title = {{LiDAR Mapping Fact Sheet - Turning Spatial Data into Knowledge}},
url = {http://www.fugroearthdata.com/pdfs/fct{\_}lidar-educational.pdf},
year = {2011}
}
@phdthesis{Abel2015,
author = {Abel, Robert},
file = {:home/tkorthals/Documents/Mendeley Desktop/Abel - 2015 - Implementation and Evaluation of a Co-Processor Interface for an Autonomous Mini Robot.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{Implementation and Evaluation of a Co-Processor Interface for an Autonomous Mini Robot}},
year = {2015}
}
@article{Birk2006,
abstract = {Mapping can potentially be speeded up in a significant way by using multiple robots exploring different parts of the environment. But the core question of multirobot mapping is how to integrate the data of the different robots into a single global map. A significant amount of research exists in the area of multirobot mapping that deals with techniques to estimate the relative robots poses at the start or during the mapping process. With map merging, the robots in contrast individually build local maps without any knowledge about their relative positions. The goal is then to identify regions of overlap at which the local maps can be joined together. A concrete approach to this idea is presented in form of a special similarity metric and a stochastic search algorithm. Given two maps m and m', the search algorithm transforms m' by rotations and translations to find a maximum overlap between m and m'. In doing so, the heuristic similarity metric guides the search algorithm toward optimal solutions. Results from experiments with up to six robots are presented based on simulated as well as real-world map data},
author = {Birk, Andreas and Carpin, Stefano},
doi = {10.1109/JPROC.2006.876965},
file = {:home/tkorthals/Documents/Mendeley Desktop/Birk, Carpin - 2006 - Merging occupancy grid maps from multiple robots.pdf:pdf},
isbn = {978-1-4673-6358-7},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Artificial intelligence,Intelligent control,Intelligent robots,Mobile robots,Terrain mapping},
mendeley-groups = {Robotics/Maps/OGM},
number = {7},
pages = {1384--1397},
title = {{Merging occupancy grid maps from multiple robots}},
volume = {94},
year = {2006}
}
@book{stachniss09,
author = {Stachniss, Cyrill},
booktitle = {Springer Tracts in Advanced Robotics},
doi = {10.1007/978-3-642-01097-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stachniss - 2009 - Robotic Mapping and Exploration.pdf:pdf},
isbn = {978-3-642-01096-5},
mendeley-groups = {Robotics/Maps},
title = {{Robotic Mapping and Exploration}},
year = {2009}
}
@article{Konrad2012,
abstract = {Grid maps are a reliable representation of the environment. Based on a generic grid map definition, this paper presents three formulations: a laser scanner based occupancy grid, a video grid based on the Inverse Perspective Mapping and a novel feature grid, where lane marking features are used. Furthermore, this contribution presents a road course estimation based on such grid maps which yields estimations above 120 m. Therefore, a digital road map (comparable to maps of GPS navigation systems) is matched to a grid map. Thus, a global position in the road map is estimated. Finally, a novel evaluation approach is presented to quantize the results of this grid map based map match.},
author = {Konrad, Marcus and Nuss, Dominik and Dietmayer, Klaus},
doi = {10.1109/IVS.2012.6232218},
file = {:home/tkorthals/Documents/Mendeley Desktop/Konrad, Nuss, Dietmayer - 2012 - Localization in digital maps for road course estimation using grid maps.pdf:pdf},
isbn = {9781467321198},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
keywords = {Inverse Perspective Mapping},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM,Robotics/Maps},
mendeley-tags = {Inverse Perspective Mapping},
pages = {87--92},
title = {{Localization in digital maps for road course estimation using grid maps}},
year = {2012}
}
@book{Winner2015,
abstract = {In diesem Grundlagenwerk werden die Fahrerassistenzsysteme f{\"{u}}r aktive Sicherheit und Fahrerentlastung in Aufbau und Funktion ausf{\"{u}}hrlich erkl{\"{a}}rt. Dazu z{\"{a}}hlen die bekannten und mittlerweile zur Standardausstattung z{\"{a}}hlenden Systeme wie ABS, ESP oder ACC genauso wie die Systeme zum Kollisionsschutz, f{\"{u}}r den Fahrspurwechsel oder zum komfortablen Einparken. Die dazu erforderlichen Komponenten wie Sensoren, Aktoren, mechatronische Subsysteme und Bet{\"{a}}tigungselemente werden dargestellt, ebenso die nutzergerechte Gestaltung der Mensch-Maschine-Schnittstelle zwischen Assistenzsystem und Fahrer. Drei Kapitel {\"{u}}ber die Besonderheiten von Fahrerassistenzsystemen bei Nutzfahrzeugen und Motorr{\"{a}}dern runden den umfassenden Ansatz ab. Der Schwerpunkt des Buchs liegt auf der Betrachtung des Fahrzeugs als Gesamtsystem.},
address = {Wiesbaden},
author = {Winner, Hermann},
file = {:home/tkorthals/Documents/Mendeley Desktop/Winner - 2015 - Handbuch Fahrerassistenzsysteme - Grundlagen, Komponenten und Systeme f{\"{u}}r aktive Sicherheit und Komfort.pdf:pdf},
isbn = {9783658057336},
mendeley-groups = {CLAAS itsowl/Books},
pages = {1221},
publisher = {Vieweg+Teubner Verlag},
title = {{Handbuch Fahrerassistenzsysteme - Grundlagen, Komponenten und Systeme f{\"{u}}r aktive Sicherheit und Komfort}},
year = {2015}
}
@book{Braunl2006,
abstract = {It all started with a new robot lab course I had developed to accompany my robotics lectures. We already had three large, heavy, and expensive mobile robots for research projects, but nothing simple and safe, which we could give to students to practice on for an introductory course. We selected a mobile robot kit based on an 8-bit controller, and used it for the first couple of years of this course. This gave students not only the enjoy- ment of working with real robots but, more importantly, hands-on experience with control systems, real-time systems, concurrency, fault tolerance, sensor and motor technology, etc. It was a very successful lab and was greatly enjoyed by the students. Typical tasks were, for example, driving straight, finding a light source, or following a leading vehicle. Since the robots were rather inexpensive, it was possible to furnish a whole lab with them and to con- duct multi-robot experiments as well. Simplicity, however, had its drawbacks. The robot mechanics were unreli- able, the sensors were quite poor, and extendability and processing power were very limited. What we wanted to use was a similar robot at an advanced level. The processing power had to be reasonably fast, it should use precision motors and sensors, and – most challenging – the robot had to be able to do on-board image processing. This had never been accomplished before on a robot of such a small size (about 12cm 9cm 14cm). Appropriately, the robot project was called “EyeBot”. It consisted of a full 32-bit controller (“EyeCon”), interfacing directly to a digital camera (“EyeCam”) and a large graphics display for visual feedback. A row of user buttons below the LCD was included as “soft keys” to allow a simple user interface, which most other mobile robots lack. The processing power of the controller is about 1,000 times faster than for robots based on most 8-bit controllers (25MHz processor speed versus 1MHz, 32-bit data width versus 8-bit, compiled C code versus interpretation) and this does not even take into account special CPU features like the “time processor unit” (TPU). The EyeBot family includes several driving robots with differential steer- ing, tracked vehicles, omni-directional vehicles, balancing robots, six-legged walkers, biped android walkers, autonomous flying and underwater robots, as well as simulation systems for driving robots (“EyeSim”) and underwater robots (“SubSim”). EyeCon controllers are used in several other projects, with and without mobile robots. Numerous universities use EyeCons to drive their own mobile robot creations. We use boxed EyeCons for experiments in a sec- ond-year course in Embedded Systems as part of the Electrical Engineering, Information Technology, and Mechatronics curriculums. And one lonely Eye- Con controller sits on a pole on Rottnest Island off the coast of Western Aus- tralia, taking care of a local weather station.},
author = {Br{\"{a}}unl, Thomas},
booktitle = {Springer, ISBN},
doi = {10.1007/3-540-34319-9},
file = {:home/tkorthals/Documents/Mendeley Desktop/Br{\"{a}}unl - 2006 - Embedded robotics.pdf:pdf},
isbn = {9783540343189},
mendeley-groups = {Robotics/Control},
pages = {454},
title = {{Embedded robotics}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Embedded+Robotics{\#}3{\%}5Cnhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Embedded+robotics{\%}238},
year = {2006}
}
@misc{Easwar2003,
author = {Easwar, Nandini and Shah, Jogen},
file = {:home/tkorthals/Documents/Mendeley Desktop/Easwar, Shah - 2003 - Object Tracking using Particle Filter.ppt:ppt},
mendeley-groups = {Vision/Tracking,Robotics/IPF},
title = {{Object Tracking using Particle Filter}},
year = {2003}
}
@incollection{plascencia2009sensor,
author = {Plascencia, Alfredo Ch{\'{a}}vez and Bendtsen, Jan Dimon},
booktitle = {Applications of Soft Computing},
mendeley-groups = {Robotics/Maps},
pages = {13--22},
publisher = {Springer},
title = {{Sensor Fusion Map Building-Based on Fuzzy Logic Using Sonar and SIFT Measurements}},
year = {2009}
}
@article{Mondada2007,
abstract = {This short paper explains how the Khepera robot was developed, from the initial idea to the its commercialisation by K-Team. The goal of this paper is not a scientific analysis but an historical overview of the steps made in the development of this robot since 1991. The papers introduces first the situation of the team who started the development, then decisions made in creating the actual Khepera are briefly described, as well as some important steps in the commercialisation of the robot. We conclude with the current status of Khepera, and introduce other products that have evolved from Khepera.},
author = {Mondada, F and Franzi, E and Guignard, A},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mondada, Franzi, Guignard - 2007 - The Development of Khepera.pdf:pdf},
isbn = {978-0-13-281081-4},
journal = {Proceedings of the 1st International Khepera Workshop},
keywords = {Khepera,Tabletop robotics,developement,tabletop robotics},
mendeley-groups = {Robotics/Robots},
mendeley-tags = {Khepera,Tabletop robotics,developement,tabletop robotics},
pages = {7--14},
title = {{The Development of Khepera}},
volume = {64},
year = {2007}
}
@inproceedings{tobi2015,
author = {{Meyer zu Borgsen}, Sebastian and Korthals, Timo and Ziegler, Leon and Wachsmuth, Sven},
file = {:home/tkorthals/Documents/Mendeley Desktop/Meyer zu Borgsen et al. - 2015 - ToBI-Team of Bielefeld The Human-Robot Interaction System for RoboCup@Home 2015.pdf:pdf},
title = {{ToBI-Team of Bielefeld The Human-Robot Interaction System for RoboCup@Home 2015}},
year = {2015}
}
@inproceedings{Korthals2016c,
author = {Korthals, Timo and Skiba, Andreas and Krause, Thilo},
booktitle = {Informatik in der Land-, Forst und Ern{\"{a}}hrungswirtschaft},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals, Skiba, Krause - 2016 - Evidenzkarten-basierte Sensorfusion zur Umfelderkennung und Interpretation in der Ernte.pdf:pdf},
keywords = {evidenzkarten,kartografierung,sensorfusion,umfelderkennung},
pages = {15--18},
title = {{Evidenzkarten-basierte Sensorfusion zur Umfelderkennung und Interpretation in der Ernte}},
year = {2016}
}
@article{Burguera2009,
abstract = {This paper presents a novel approach to mobile robot localization using sonar sensors. This approach is based on the use of particle filters. Each particle is augmented with local environment information which is updated during the mission execution. An experimental characterization of the sonar sensors used is provided in the paper. A probabilistic measurement model that takes into account the sonar uncertainties is defined according to the experimental characterization. The experimental results quantitatively evaluate the presented approach and provide a comparison with other localization strategies based on both the sonar and the laser. Some qualitative results are also provided for visual inspection.},
author = {Burguera, Antoni and Gonz{\'{a}}lez, Yolanda and Oliver, Gabriel},
doi = {10.3390/s91210217},
file = {:home/tkorthals/Documents/Mendeley Desktop/Burguera, Gonz{\'{a}}lez, Oliver - 2009 - Sonar sensor models and their application to mobile robot localization.pdf:pdf},
issn = {14248220},
journal = {Sensors},
keywords = {Mobile robot localization,Particle filter,Sonar},
mendeley-groups = {Robotics/Maps,Robotics/Sensing},
number = {12},
pages = {10217--10243},
pmid = {22303171},
title = {{Sonar sensor models and their application to mobile robot localization}},
volume = {9},
year = {2009}
}
@techreport{Collins2007,
author = {Collins, Thomas and Collins, J J and Ryan, Conor and Eaton, Malachy},
file = {:home/tkorthals/Documents/Mendeley Desktop/Collins et al. - 2007 - Occupancy Grid Mapping An Empirical Evaluation.pdf:pdf},
keywords = {Benchmarking,Evaluation,Evidence Grid Mapping,Evidence Grid Maps,OGM,Occupancy,Occupancy Grid Mapping,Occupancy Grid Maps},
mendeley-groups = {Robotics/Maps},
mendeley-tags = {Benchmarking,Evaluation,Evidence Grid Mapping,Evidence Grid Maps,OGM,Occupancy,Occupancy Grid Mapping,Occupancy Grid Maps},
title = {{Occupancy Grid Mapping: An Empirical Evaluation}},
url = {http://www.robot-standards.eu/Documents{\_}RoSta{\_}wiki/RoSta{\_}Presentation.pdf},
year = {2007}
}
@article{Pedre2014,
author = {Pedre, Sol and Nitsche, Mat{\'{i}}as and Pessacg, Facundo and Caccavelli, Javier and {De Crist{\'{o}}foris}, Pablo},
doi = {10.1007/978-3-319-10401-0_17},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pedre et al. - 2014 - Design of a multi-purpose low-cost mobile robot for research and education.pdf:pdf},
isbn = {9783319104003},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {Robotics/Robots},
pages = {185--196},
title = {{Design of a multi-purpose low-cost mobile robot for research and education}},
volume = {8717 LNAI},
year = {2014}
}
@article{Hilder2014,
author = {Hilder, James and Naylor, Rebecca and Rizihs, Artjoms and Franks, Daniel and Timmis, Jon},
doi = {10.1007/978-3-319-10401-0_14},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hilder et al. - 2014 - The Pi Swarm A low-cost platform for swarm robotics research and education.pdf:pdf},
isbn = {9783319104003},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Swarm robotics,Tracking},
mendeley-groups = {Robotics/Robots},
pages = {151--162},
title = {{The Pi Swarm: A low-cost platform for swarm robotics research and education}},
volume = {8717 LNAI},
year = {2014}
}
@phdthesis{Limberg2016,
author = {Limberg, Christian},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Limberg - 2016 - Entwicklung eines Bildverarbeitungssystems zur Klassifikation in Getreidefeldern anhand kamerabasierter Umfeldsensorik.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{Entwicklung eines Bildverarbeitungssystems zur Klassifikation in Getreidefeldern anhand kamerabasierter Umfeldsensorik unter Zuhilfenahme maschineller Lernverfahren}},
year = {2016}
}
@phdthesis{Ziesenis2016,
author = {Ziesenis, Jacob},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ziesenis - 2016 - Entwicklung einer kamerabasierten Gutfluss{\"{u}}berwachung f{\"{u}}r Schneidwerke von M{\"{a}}hdreschern.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{Entwicklung einer kamerabasierten Gutfluss{\"{u}}berwachung f{\"{u}}r Schneidwerke von M{\"{a}}hdreschern}},
year = {2016}
}
@article{Carvalho2013,
abstract = {Building occupancy grid maps with sonar sensors is a challenging task due to angular uncertainty, specular reflections and crosstalk. This paper presents a quantitative comparison of two probabilistic and one heuristic approaches to the robotic mapping using real sonar data – inverse and forward sensor models and the CEMAL methods. Moreover, the two probabilistic methods are also tested pre-filtering the sonar data with the CEsp filter, which is part of the CEMAL approach. The results show that, using the pre-filtering, all algorithms present a similar and better performance, while without filtering the inverse method presents the highest error.},
author = {Carvalho, Jo{\~{a}}o and Ventura, Rodrigo},
doi = {10.1007/978-3-642-38628-2_105},
file = {:home/tkorthals/Documents/Mendeley Desktop/Carvalho, Ventura - 2013 - Comparative evaluation of occupancy grid mapping methods using sonar sensors.pdf:pdf},
isbn = {9783642386275},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {889--896},
title = {{Comparative evaluation of occupancy grid mapping methods using sonar sensors}},
volume = {7887 LNCS},
year = {2013}
}
@phdthesis{Hund2009,
author = {Hund, Marcus},
file = {:home/tkorthals/Documents/Mendeley Desktop/Hund - 2009 - Perzeptuelle Organisation von Objektgrenzen unter Verwendung anisotroper Regularisierungsmethoden.pdf:pdf},
title = {{Perzeptuelle Organisation von Objektgrenzen unter Verwendung anisotroper Regularisierungsmethoden}},
year = {2009}
}
@article{Stachniss,
author = {Stachniss, Cyrill},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stachniss - Unknown - Robot Mapping Features vs . Volumetric Maps Grid Maps Example.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
title = {{Robot Mapping Features vs . Volumetric Maps Grid Maps Example}}
}
@phdthesis{Wall2015,
author = {Wall, Eduard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wall - 2015 - Vergleichsstudie Zur Analyse Qualifizierter Unterschiede Von GPS-Receivern.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{Vergleichsstudie Zur Analyse Qualifizierter Unterschiede Von GPS-Receivern}},
year = {2015}
}
@article{Homm2010,
abstract = {Accurate maps of the static environment are essential for many advanced driver-assistance systems. In this paper a new method for the fast computation of occupancy grid maps with laser range-finders and radar sensors is proposed. The approach utilizes the Graphics Processing Unit to overcome the limitations of classical occupancy grid computation in automotive environments. It is possible to generate highly accurate grid maps in just a few milliseconds without the loss of sensor precision. Moreover, in the case of a lower resolution radar sensor it is shown that it is suitable to apply super-resolution algorithms to achieve the accuracy of a higher resolution laser-scanner. Finally, a novel histogram based approach for road boundary detection with lidar and radar sensors is presented.},
author = {Homm, F and Kaempchen, N and Ota, J and Burschka, D},
doi = {10.1109/IVS.2010.5548091},
file = {:home/tkorthals/Documents/Mendeley Desktop/Homm et al. - 2010 - Efficient occupancy grid computation on the GPU with lidar and radar for road boundary detection.pdf:pdf},
isbn = {9781424478682},
issn = {1931-0587},
journal = {Intelligent Vehicles Symposium IV 2010 IEEE},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM},
pages = {1006--1013},
title = {{Efficient occupancy grid computation on the GPU with lidar and radar for road boundary detection}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5548091},
year = {2010}
}
@article{Dreßler2001,
author = {Dre{\ss}ler, J{\"{o}}rg},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dre{\ss}ler - 2001 - Navigation mobiler Systeme in Indoor-Umgebungen.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Localizing},
number = {August},
title = {{Navigation mobiler Systeme in Indoor-Umgebungen}},
year = {2001}
}
@article{Lien2013,
author = {Lien, Torgrim Aalvik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lien - 2013 - Mobile Robotics in Precision Agriculture.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Localizing},
number = {July},
title = {{Mobile Robotics in Precision Agriculture}},
year = {2013}
}
@article{Freitas2012,
abstract = {This paper addresses the design, development and eld-testing of a$\backslash$nlocalization system for agricultural$\backslash$n$\backslash$nvehicles. The Autonomous Prime Movers (APMs) are electrical vehicles$\backslash$ndesigned to operate in specialty$\backslash$n$\backslash$ncrops, more specically in orchards. In order to accomplish geo-referenced$\backslash$ntasks inside the crops, the vehicles$\backslash$n$\backslash$nmust know their pose with sub-metric accuracy. One of our requirements$\backslash$nis that the localization system shouldn't$\backslash$n$\backslash$nadd to the vehicle's hardware cost, so as to keep the acquisition$\backslash$ncost to growers as low as possible. Therefore,$\backslash$n$\backslash$nwe conne ourselves to solutions that use only the sensor suite already$\backslash$ninstalled on the robot for navigation - in$\backslash$n$\backslash$nour case, laser scanners and steering and wheel encoders. The developed$\backslash$nlocalization methodology employs an$\backslash$n$\backslash$nExtended Kalman Filter. The APM pose is predicted using encoder odometry$\backslash$nand updated with point and line$\backslash$n$\backslash$nfeatures detected with the laser. Tests conducted at our experimental$\backslash$norchard-like environment in Pittsburgh$\backslash$n$\backslash$nand actual apple orchards in Pennsylvania and Washington states indicate$\backslash$nthat the localization system is able$\backslash$n$\backslash$nto estimate the vehicle pose with sub-metric accuracy.},
author = {Freitas, Gustavo and Zhang, Ji and Hamner, Bradley and Bergerman, Marcel and Kantor, George},
doi = {10.1007/978-3-642-33503-7_36},
file = {:home/tkorthals/Documents/Mendeley Desktop/Freitas et al. - 2012 - A Low-Cost, Practical Localization System for Agricultural Vehicles.pdf:pdf},
journal = {Intelligent Robotics and Applications Lecture Notes in Computer Science},
keywords = {Autonomous Agricultural Vehicles,Extended Kalman Filter,GPS-Free Localization},
mendeley-groups = {CLAAS itsowl/Localizing},
pages = {365--375},
title = {{A Low-Cost, Practical Localization System for Agricultural Vehicles}},
volume = {7508},
year = {2012}
}
@techreport{Bontsema,
author = {Bontsema, Jan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bontsema - Unknown - CROPS Report Summary.pdf:pdf},
mendeley-groups = {CLAAS itsowl/CROPS},
pages = {1--4},
title = {{CROPS Report Summary}}
}
@book{Mitchell2012,
abstract = {As a response to the strong interest and activities in the intelligent control community, this special section on Multisensor Fusion and Integration is intended to introduce to control engineers and researchers, an emerging new technology, multisensor data fusion. Growing out of military applications, the technology has become one of the promising new fields with diversified potential in many commercial and industrial applications such as robotics, automated manufacturing, remote sensing, image processing, and signal processing. It is a timely answer to the call to provide an overall perspective on the technology. The objective of this preface is to present a brief review of some of the well-known data fusion architectures, to identify some important issues in sensor fusion that create confusion in both the research and the applications communities, and finally to provide an overview of the papers contributed for this special section.},
author = {Mitchell, H. B. and Kokar, M. and Kim, K.},
booktitle = {Data Fusion: Concepts and Ideas},
doi = {10.1007/978-3-642-27222-6_7},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mitchell, Kokar, Kim - 2012 - Data Fusion Concepts and Ideas.pdf:pdf},
isbn = {978-3-642-27221-9, 978-3-642-27222-6},
issn = {09670661},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {5},
pages = {347},
pmid = {21033193},
title = {{Data Fusion: Concepts and Ideas}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-27222-6{\_}1{\%}5Cnhttp://link.springer.com/chapter/10.1007/978-3-642-27222-6{\_}5{\%}5Cnhttp://www.sciencedirect.com/science/article/pii/096706619490345X{\%}5Cnhttp://linkinghub.elsevier.com/retrieve/pii/096706619490345X{\%}5Cnht},
volume = {2},
year = {2012}
}
@phdthesis{Ritter2008,
abstract = {The present investigation was a Monte Carlo experiment designed to evaluate the performance of several metrics in spotting correlational outliers. Specifically, the metrics that were compared were the Mahalanobis D², Bacon MLD, Carrig D, MCD, Robust PCLOW and Robust PCHIGH. This was the first comparative simulation study to include robust PCLOW and robust PCHIGH. The Mahalanobis D², MCD, Robust PCLOW and Robust PCHIGH were each applied using an approximate statistical criterion. The Carrig D and Bacon MLD were applied using a "natural drop" approach that separated scores on the metric into two groups: outlying and non-outlying. The "natural drop" utilizes a k-means algorithm from cluster analysis to separate the scores into the two groups. Both majority and contaminant observations were generated from multivariate normal distributions based on factor-analytic models. Experimental factors included majority versus contaminant communality level, majority-contaminant factor models scenario, number of variables, sample size and fraction of outliers. Results indicated that the "natural drop" method of application for the Carrig D and Bacon MLD leads to intolerably high false-alarm rates. Overall, PCLOW clearly outperformed PCHIGH. Suprisingly, PCLOW did not distinguish itself from MCD in terms of performance as expected in certain experimental conditions. The conditions in this study were limited. Future comparative studies of the metrics could include conditions of non-normality and hybrid types of outliers (i.e. outliers that are both mean shift and correlational). Despite its poor performance in this study, I theorize that robust PCHIGH could have an advantage over MCD in spotting certain kinds of mean-shift outliers. Also, research into the distributional properties of the Carrig D is warranted.},
author = {Ritter, Paul Muse},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ritter - 2008 - A Comparative Study of Correlational Outlier Detection Metrics.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
pages = {236},
school = {University of Texas in Austin},
title = {{A Comparative Study of Correlational Outlier Detection Metrics}},
url = {http://hdl.handle.net/2152/18106},
year = {2008}
}
@article{Kumar2009,
author = {Kumar, Manish and Garg, Devendra P},
doi = {10.5772/55579},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kumar, Garg - 2009 - Multi-Sensor Data Fusion in Presence of Uncertainty and Inconsistency in Data.pdf:pdf},
isbn = {9783902613523},
journal = {Sensor and Data Fusion},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {February},
pages = {225--244},
title = {{Multi-Sensor Data Fusion in Presence of Uncertainty and Inconsistency in Data}},
year = {2009}
}
@article{Khaleghi2013,
abstract = {There has been an ever-increasing interest in multi-disciplinary research on multisensor data fusion technology, driven by its versatility and diverse areas of application. Therefore, there seems to be a real need for an analytical review of recent developments in the data fusion domain. This paper proposes a comprehensive review of the data fusion state of the art, exploring its conceptualizations, benefits, and challenging aspects, as well as existing methodologies. In addition, several future directions of research in the data fusion community are highlighted and described. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Khaleghi, Bahador and Khamis, Alaa and Karray, Fakhreddine O. and Razavi, Saiedeh N.},
doi = {10.1016/j.inffus.2011.08.001},
file = {:home/tkorthals/Documents/Mendeley Desktop/Khaleghi et al. - 2013 - Multisensor data fusion A review of the state-of-the-art.pdf:pdf},
isbn = {15662535},
issn = {15662535},
journal = {Information Fusion},
keywords = {Fusion methodologies,Multisensor data fusion,Taxonomy},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {1},
pages = {28--44},
publisher = {Elsevier B.V.},
title = {{Multisensor data fusion: A review of the state-of-the-art}},
url = {http://dx.doi.org/10.1016/j.inffus.2011.08.001},
volume = {14},
year = {2013}
}
@article{Korthals2015,
author = {Korthals, Timo and Krause, Thilo and R{\"{u}}ckert, Ulrich},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korthals, Krause, R{\"{u}}ckert - 2015 - Evidence Grid Based Information Fusion for Semantic Classifiers in Dynamic Sensor Networks.pdf:pdf},
journal = {Machine Learning for Cyber Physical Systems},
number = {1},
pages = {6},
title = {{Evidence Grid Based Information Fusion for Semantic Classifiers in Dynamic Sensor Networks}},
volume = {1},
year = {2015}
}
@article{Durrant-Whyte:1988:SMM:55067.55074,
address = {Thousand Oaks, CA, USA},
author = {Durrant-Whyte, H F},
doi = {10.1177/027836498800700608},
issn = {0278-3649},
journal = {Int. J. Rob. Res.},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {6},
pages = {97--113},
publisher = {Sage Publications, Inc.},
title = {{Sensor Models and Multisensor Integration}},
url = {http://dx.doi.org/10.1177/027836498800700608},
volume = {7},
year = {1988}
}
@phdthesis{elmenreich:2002,
address = {Treitlstr. 3/3/182-1, 1040 Vienna, Austria},
author = {Elmenreich, Wilfried},
file = {:home/tkorthals/Documents/Mendeley Desktop/Elmenreich - 2002 - Sensor Fusion in Time-Triggered Systems.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
school = {Technische Universit{\{}{\"{a}}{\}}t Wien, Institut f{\{}{\"{u}}{\}}r Technische Informatik},
title = {{Sensor Fusion in Time-Triggered Systems}},
year = {2002}
}
@book{matarić2007robotics,
author = {Matari{\'{c}}, M J},
file = {:home/tkorthals/Documents/Mendeley Desktop/Matari{\'{c}} - 2007 - The Robotics Primer.pdf:pdf},
isbn = {9780262633543},
mendeley-groups = {Robotics},
publisher = {MIT Press},
series = {Intelligent robotics and autonomous agents},
title = {{The Robotics Primer}},
url = {https://books.google.de/books?id=WWJPjgz-jgEC},
year = {2007}
}
@book{Bishop2007a,
abstract = {This leading textbook provides a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. This is the first machine learning textbook to include a comprehensive coverage of recent developments such as probabilistic graphical models and deterministic inference methods, and to emphasize a modern Bayesian perspective. It is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. This hard cover book has 738 pages in full colour, and there are 431 graded exercises (with solutions available below). Extensive support is provided for course instructors.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M.},
booktitle = {Journal of Electronic Imaging},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bishop - 2007 - Pattern Recognition and Machine Learning - Solutions to Exercises.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
keywords = {Bott,Exercises,Machine Learning},
mendeley-groups = {Machine Learning},
mendeley-tags = {Exercises,Machine Learning},
number = {1},
pages = {101},
pmid = {15003161},
title = {{Pattern Recognition and Machine Learning - Solutions to Exercises}},
year = {2007}
}
@misc{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - Unknown - Kulturelle Differenzen bei gesch{\"{a}}ftsbesprechungen zwischen Deutschen und Chinesen.pptx:pptx},
mendeley-groups = {Chinesisch},
title = {{Kulturelle Differenzen bei gesch{\"{a}}ftsbesprechungen zwischen Deutschen und Chinesen}}
}
@techreport{Gebbers2015,
author = {Gebbers, Robin},
doi = {10.13140/2.1.4038.2244},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gebbers - 2015 - Current Crop and Soil Sensors for Precision Agriculture.pdf:pdf},
mendeley-groups = {CLAAS itsowl/CROPS},
number = {SEPTEMBER 2014},
title = {{Current Crop and Soil Sensors for Precision Agriculture}},
year = {2015}
}
@misc{,
mendeley-groups = {CLAAS itsowl/CROPS},
pages = {http://www.crops--robots.eu/},
title = {{CROPS - Clever Robots for Crops}}
}
@book{Mitchell2014,
abstract = {This textbook provides a comprehensive introduction to the concepts and idea of multisensor data fusion. It is an extensively revised second edition of the author's successful book: "Multi-Sensor Data Fusion: An Introduction" which was originally published by Springer-Verlag in 2007. The main changes in the new book are: New Material: Apart from one new chapter there are approximately 30 new sections, 50 new examples and 100 new references. At the same time, material which is out-of-date has been eliminated and the remaining text has been rewritten for added clarity. Altogether, the new book is nearly 70 pages longer than the original book. Matlab code: Where appropriate we have given details of Matlab code which may be downloaded from the worldwide web. In a few places, where such code is not readily available, we have included Matlab code in the body of the text. Layout. The layout and typography has been revised. Examples and Matlab code now appear on a gray background for easy identification and advancd material is marked with an asterisk. The book is intended to be self-contained. No previous knowledge of multi-sensor data fusion is assumed, although some familarity with the basic tools of linear algebra, calculus and simple probability is recommended. Although conceptually simple, the study of mult-sensor data fusion presents challenges that are unique within the education of the electrical engineer or computer scientist. To become competent in the field the student must become familiar with tools taken from a wide range of diverse subjects including: neural networks, signal processing, statistical estimation, tracking algorithms, computer vision and control theory. All too often, the student views multi-sensor data fusion as a miscellaneous assortment of different processes which bear no relationship to each other. In contrast, in this book the processes are unified by using a common statistical framework. As a consequence, the underlying pattern of relationships that exists between the different methodologies is made evident. The book is illustrated with many real-life examples taken from a diverse range of applications and contains an extensive list of modern references.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Mitchell, H. B.},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mitchell - 2014 - Data Fusion Concepts and Ideas.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
keywords = {Sensor fusion,multi sensor fusion},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
pmid = {15003161},
title = {{Data Fusion: Concepts and Ideas}},
url = {http://www.americanbanker.com/issues/179{\_}124/which-city-is-the-next-big-fintech-hub-new-york-stakes-its-claim-1068345-1.html http://www.ncbi.nlm.nih.gov/pubmed/15003161 http://cid.oxfordjournals.org/lookup/doi/10.1093/cid/cir991 http://www.scielo.cl/pdf/u},
year = {2014}
}
@techreport{Vitzrabin,
author = {Vitzrabin, Efi and Edan, Yael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Vitzrabin, Edan - Unknown - Sensor Fusion.pdf:pdf},
mendeley-groups = {CLAAS itsowl/CROPS},
title = {{Sensor Fusion}}
}
@book{schoepping2015,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2015. The Autonomous Mini Robot (AMiRo) is a modular and extensible mini robot platform, designed for scientific research and education. Its decentralized architecture enables to easily add or remove functionalities as required for any application. A well defined physical and electrical interface offers the possibility to design new modules with minimal effort. The open-source software framework for the AMiRo is already growing, since the robot is commonly used for research, education, and competitions. Several demonstrations of the system are given, which present its capabilities. Starting with a fuzzy controller for line following, these demonstrations include remote controlling as well as an implementation of an artificial neural network running on the platform.},
author = {Sch{\"{o}}pping, Thomas and Korthals, Timo and Herbrechtsmeier, Stefan and R{\"{u}}ckert, Ulrich},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-19258-1_17},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sch{\"{o}}pping et al. - 2015 - AMiRo A Mini Robot for Scientific Applications.pdf:pdf},
isbn = {9783319192574},
issn = {16113349 03029743},
keywords = {Education robot,Edutainment,Minirobots,Mobile robots,Research robot},
mendeley-groups = {Robotics/AMiRo},
pages = {199--205},
title = {{AMiRo: A Mini Robot for Scientific Applications}},
url = {http://link.springer.com/10.1007/978-3-319-19258-1{\_}17},
volume = {9094},
year = {2015}
}
@inproceedings{Walter2013,
abstract = {Discovering the linguistic structure of a language solely from spoken input asks for two steps: phonetic and lexical discovery. The first is concerned with identifying the categorical subword unit inventory and relating it to the underlying acoustics, while the second aims at discovering words as repeated patterns of subword units. The hierarchical approach presented here accounts for classification errors in the first stage by modelling the pronunciation of a word in terms of subword units probabilistically: a hidden Markov model with discrete emission probabilities, emitting the observed subword unit sequences. We describe how the system can be learned in a completely unsupervised fashion from spoken input. To improve the initialization of the training of the word pronunciations, the output of a dynamic time warping based acoustic pattern discovery system is used, as it is able to discover similar temporal sequences in the input data. This improved initialization, using only weak supervision, has led to a 40{\%} reduction in word error rate on a digit recognition task. {\textcopyright} 2013 IEEE.},
author = {Walter, O. and Korthals, T. and Haeb-Umbach, R. and Raj, B.},
booktitle = {2013 IEEE Workshop on Automatic Speech Recognition and Understanding, ASRU 2013 - Proceedings},
doi = {10.1109/ASRU.2013.6707761},
file = {:home/tkorthals/Documents/Mendeley Desktop/Walter et al. - 2013 - A hierarchical system for word discovery exploiting DTW-based initialization.pdf:pdf},
isbn = {9781479927562},
keywords = {Unsupervised,acoustic units,word discovery},
pages = {386--391},
title = {{A hierarchical system for word discovery exploiting DTW-based initialization}},
year = {2013}
}
@phdthesis{Fackelmeier2012,
abstract = {In dieser Arbeit werden mikrowellenbasierte Methoden zur Detektion von Wildtieren bei der Fr{\"{u}}hjahrsmahd untersucht. F{\"{u}}r die Detektion dieser verdeckten Zielobjekte wird ein multistatisches Radar entwickelt, wobei der Schwerpunkt auf der Optimierung der Antenneneigenschaften und der Antennenanordnung hinsichtlich einer zuverl{\"{a}}ssigen Detektion liegt. Zur weiteren Systemoptimierung wird eine Arrayantenne mit frequenzabh{\"{a}}ngiger Strahlschwenkung mit sehr geringem Bandbreitenbedarf entwickelt. Ein kosteng{\"{u}}nstiges, realisiertes Radarsystem wird beschrieben, und mit diesem werden Detektionsmessungen bei unterschiedlichen Umgebungsbedingungen durchgef{\"{u}}hrt und diskutiert.},
author = {Fackelmeier, Andreas},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fackelmeier - 2012 - Mikrowellengest{\"{u}}tzte Detektion von Wildtieren.pdf:pdf},
isbn = {978-3843903837},
keywords = {Radar,Wildretter},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
mendeley-tags = {Radar,Wildretter},
pages = {120},
school = {Technische Universit{\"{a}}t M{\"{u}}nchen},
title = {{Mikrowellengest{\"{u}}tzte Detektion von Wildtieren}},
year = {2012}
}
@book{Liggins2001,
abstract = {The emerging technology of multisensor data fusion has a wide range of applications, both in Department of Defense (DoD) areas and in the civilian arena. The techniques of multisensor data fusion draw from an equally broad range of disciplines, including artificial intelligence, pattern recognition, and statistical estimation. With the rapid evolution of computers and the maturation of data fusion technology, the door to using data fusion in everyday applications is now wide open and presenting great opportunities. The Handbook of Multisensor Data Fusion provides a unique, comprehensive, and up-to-date resource for data fusion systems designers and researchers. Divided into five parts, it: {\textperiodcentered} offers a thorough introduction to data fusion terminology and models {\textperiodcentered} describes advanced techniques for data association, target tracking, and identification {\textperiodcentered} presents practical information on system development, including requirements analysis, systems engineering, algorithm selection, database design, human-computer interfaces, and performance assessment {\textperiodcentered} introduces applications from the DoD, NASA, DARPA, and condition-based monitoring of complex machinery {\textperiodcentered} supplies data fusion resources and Web sites The contributing authors are all recognized leaders in data fusion and have collaborated to provide what promises to be the definitive reference for this rapidly developing field. Whether you are a researcher, system designer, implementer, or student, in the Handbook of Multisensor Data Fusion you'll find everything you need, from a basic introduction and survey of data fusion technology to advanced mathematics and theory, including very practical advice on data fusion system development and implementation.},
author = {Liggins, Martin E. and Hall, David L. and Llinas, David},
booktitle = {Handbook of Multisensor Data Fusion},
file = {:home/tkorthals/Documents/Mendeley Desktop/Liggins, Hall, Llinas - 2001 - Handbook of multisensor data fusion.pdf:pdf},
isbn = {978-1420053081},
keywords = {multisensorfusion,sensor fusion,sensorfusion},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
mendeley-tags = {multisensorfusion,sensor fusion,sensorfusion},
pages = {537},
title = {{Handbook of multisensor data fusion}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Handbook+of+multisensor+data+fusion{\#}2},
year = {2001}
}
@techreport{Petersen,
abstract = {Die Klassifizierungsleistung mehrstufiger Mustererkennungssysteme ist wesentlich durch die Struktur des Systems und die Art der eingesetzten Verfahren zur Merkmalextraktion bestimmt. Eine Aufgabe besteht bei der Konstruktion mehrstufiger Systeme darin, die zur VerfUgung stehenden Extraktionsverfahren und die Systemstruktur aufeinander abzustimmen. Zu diesem Zweck werden Verfahren beschrieben und miteinander verglichen, welche es gestatten, die Verteilung der Muster im Merkmalraum zu bestimmen und daraus Ma{\#}e abzuleiten, die Auskunft Uber die Trennbarkeit der Klassen im Merkmalraum geben. In einem weiteren Schritt k{\~{}}nnen die Trennbarkeiten von Klassenpaaren zur Bestimmung von Gruppentrennbarkeiten und damit zur Strukturierung von mehrstufigen Systemen herangezogen werden.},
author = {Petersen, H. and Vorst{\"{a}}dt, N.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Petersen, Vorst{\"{a}}dt - Unknown - Zur Strukturierung Mehrstufiger Mustererkennungsverfahren.pdf:pdf},
keywords = {Trennbarkeit,Trennbarkeitsma{\ss}e,separability},
mendeley-groups = {Machine Learning},
mendeley-tags = {Trennbarkeit,Trennbarkeitsma{\ss}e,separability},
title = {{Zur Strukturierung Mehrstufiger Mustererkennungsverfahren}},
url = {http://download.springer.com/static/pdf/724/chp:10.1007/3-540-07410-4{\_}642.pdf?originUrl=http://link.springer.com/chapter/10.1007/3-540-07410-4{\_}642{\&}token2=exp=1446196532{~}acl=/static/pdf/724/chp:10.1007/3-540-07410-4{\_}642.pdf?originUrl=http:/}
}
@book{Friedenthal2011,
abstract = {This book is the bestselling, authoritative guide to SysML for systems and software engineers, providing a comprehensive and practical resource for modeling systems with SysML. Fully updated to cover newly released version 1.3, it includes a full description of the modeling language along with a quick reference guide, and shows how an organization or project can transition to model-based systems engineering using SysML, with considerations for processes, methods, tools, and training. Numerous examples help readers understand how SysML can be used in practice, while reference material facilitates studying for the OMG Systems Modeling Professional (OCSMP) Certification Program, designed to test candidates' knowledge of SysML and their ability to use models to represent real-world systems.},
author = {Friedenthal, Sanford and Moore, Alan and Steiner, Rick},
edition = {2nd},
file = {:home/tkorthals/Documents/Mendeley Desktop/Friedenthal, Moore, Steiner - 2011 - A Practical Guide to SysML.pdf:pdf},
isbn = {9780123852069},
keywords = {SysML,System Engineering,Systems Engineering,XML},
mendeley-groups = {CLAAS itsowl/System Engineering},
mendeley-tags = {SysML,System Engineering,Systems Engineering,XML},
pages = {640},
publisher = {Morgan Kaufmann},
title = {{A Practical Guide to SysML}},
year = {2011}
}
@article{Taha2013,
author = {Taha, Walid},
file = {:home/tkorthals/Documents/Mendeley Desktop/Taha - 2013 - A First Course on Cyber Physical Systems.pdf:pdf},
keywords = {CPS,Cyber Physical Systems,Teaching},
mendeley-groups = {CLAAS itsowl/CPS},
mendeley-tags = {CPS,Cyber Physical Systems,Teaching},
pages = {1--3},
title = {{A First Course on Cyber Physical Systems}},
year = {2013}
}
@article{Zadeh1986,
abstract = {During the past two years, the Dempster-Shafer theory of evidence has attracted considerable attention within the AI community as a promising method of dealing with uncertainty in expert systems. As presented in the literature, the theory is hard to master. In a simple approach that is outlined in this paper, the Dempster-Shafer theory is viewed in the context of relational databases as the application of familiar retrieval techniques to second-order relations, that is, relations in which the data entries are relations in first normal form. The relational viewpoint clarifies some of the controversial issues in the Dempster-Shafer theory and facilitates its use in AI-oriented applications.},
author = {Zadeh, Lotfi a.},
doi = {http://dx.doi.org/10.1609/aimag.v7i2.542},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zadeh - 1986 - Simple View of the Dempster-Shafer Theory of Evidence and Its Implication for the Rule of Combination.pdf:pdf},
isbn = {0738-4602},
issn = {07384602},
journal = {AI Magazine},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {2},
pages = {85--90},
title = {{Simple View of the Dempster-Shafer Theory of Evidence and Its Implication for the Rule of Combination.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0022733771{\&}partnerID=tZOtx3y1{\%}5Cnhttp://www.aaai.org/ojs/index.php/aimagazine/article/view/542},
volume = {7},
year = {1986}
}
@phdthesis{Korthals2013,
author = {Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Korthals - 2013 - Un{\"{u}}berwachtes Lernen von Laut- und Worteinheiten mittels hierarchischer, generativer Modelle.pdf:pdf},
mendeley-groups = {Master},
number = {August},
title = {{Un{\"{u}}berwachtes Lernen von Laut- und Worteinheiten mittels hierarchischer, generativer Modelle}},
year = {2013}
}
@article{Kamaev2012,
author = {Kamaev, Andrey},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kamaev - 2012 - Arm neon SIMD.pdf:pdf},
mendeley-groups = {Software},
title = {{Arm neon SIMD}},
year = {2012}
}
@misc{Lazarevic,
author = {Lazarevic, Aleksandar (United Technology Research Center)},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lazarevic - Unknown - Anomalie Detection A Tutorial.ppt:ppt},
mendeley-groups = {CLAAS itsowl/Anomalie Detection},
title = {{Anomalie Detection: A Tutorial}}
}
@techreport{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2014 - OpenCV 3.0 Overview.pptx:pptx},
mendeley-groups = {Software},
title = {{OpenCV 3.0 Overview}},
year = {2014}
}
@inproceedings{704,
address = {Lyon},
author = {Moringen, Jan and Nordmann, Arne and Wrede, Sebastian},
booktitle = {ERF2013 Working Session on Infrastructure for Robot Analysis and Benchmarking},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moringen, Nordmann, Wrede - 2013 - Cross-Platform Data Acquisition and Transformation for Whole-Systems Experimentation.pdf:pdf},
keywords = {CoR-Lab Publication},
mendeley-groups = {Robotics/RSB},
title = {{Cross-Platform Data Acquisition and Transformation for Whole-Systems Experimentation}},
year = {2013}
}
@inproceedings{,
booktitle = {Actual Tasks on Agricultural Engineering},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2015 - Actual Tasks on Agricultural Engineering - Proceedings of the 43rd International Symposium on Agricultural Engineering.pdf:pdf},
keywords = {Agricultural Engineering,Agriculture},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Conferences},
mendeley-tags = {Agricultural Engineering,Agriculture},
title = {{Actual Tasks on Agricultural Engineering - Proceedings of the 43rd International Symposium on Agricultural Engineering}},
year = {2015}
}
@book{Field2007,
author = {Field, Harry S. and Solie, John B.},
edition = {third},
file = {:home/tkorthals/Documents/Mendeley Desktop/Field, Solie - 2007 - Introduction to Agricultural Engineering Technology - A Problem Solvin Approach.pdf:pdf},
isbn = {9780387369136},
keywords = {Agricultural Engineering,Agriculture},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Books},
mendeley-tags = {Agricultural Engineering,Agriculture},
publisher = {Springer},
title = {{Introduction to Agricultural Engineering Technology - A Problem Solvin Approach}},
year = {2007}
}
@inproceedings{,
booktitle = {Actual Tasks on Agricultural Engineering},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2014 - Actual Tasks on Agricultural Engineering - Proceedings of the 42rd International Symposium on Agricultural Engineering.pdf:pdf},
keywords = {Agricultural Engineering,Agriculture},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Conferences},
mendeley-tags = {Agricultural Engineering,Agriculture},
title = {{Actual Tasks on Agricultural Engineering - Proceedings of the 42rd International Symposium on Agricultural Engineering}},
year = {2014}
}
@inproceedings{,
booktitle = {Actual Tasks on Agricultural Engineering},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2012 - Actual Tasks on Agricultural Engineering - Proceedings of the 40rd International Symposium on Agricultural Engineering.pdf:pdf},
keywords = {Agricultural Engineering,Agriculture},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Conferences},
mendeley-tags = {Agricultural Engineering,Agriculture},
title = {{Actual Tasks on Agricultural Engineering - Proceedings of the 40rd International Symposium on Agricultural Engineering}},
year = {2012}
}
@inproceedings{,
booktitle = {Actual Tasks on Agricultural Engineering},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Actual Tasks on Agricultural Engineering - Proceedings of the 41rd International Symposium on Agricultural Engineering.pdf:pdf},
keywords = {Agricultural Engineering,Agriculture},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Conferences},
mendeley-tags = {Agricultural Engineering,Agriculture},
title = {{Actual Tasks on Agricultural Engineering - Proceedings of the 41rd International Symposium on Agricultural Engineering}},
year = {2013}
}
@article{Xu1994,
author = {Xu, Lei and Xu, Lei and Jordan, Michael I. and Jordan, Michael I. and Hinton, Geoffrey E. and Hinton, Geoffrey E.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Xu et al. - 1994 - An alternative model for mixtures of experts.pdf:pdf},
issn = {1049-5258},
journal = {Nips},
mendeley-groups = {Robotics/Sensing},
number = {7},
pages = {633--640},
title = {{An alternative model for mixtures of experts}},
url = {http://scholar.google.com/scholar?q=intitle:An+Alternative+Model+for+Mixtures+of+Experts{\#}0},
year = {1994}
}
@article{Li2014,
abstract = {Occupancy grid map is a popular tool for representing the surrounding environments of mobile robots/intelligent vehicles. Its applications can be dated back to the 1980s, when researchers utilized sonar or LiDAR to illustrate environments by occupancy grids. However, in the literature, research on vision-based occupancy grid mapping is scant. Furthermore, when moving in a real dynamic world, traditional occupancy grid mapping is required not only with the ability to detect occupied areas, but also with the capability to understand dynamic environments. The paper addresses this issue by presenting a stereo-vision-based framework to create a dynamic occupancy grid map, which is applied in an intelligent vehicle driving in an urban scenario. Besides representing the surroundings as occupancy grids, dynamic occupancy grid mapping could provide the motion information of the grids. The proposed framework consists of two components. The first is motion estimation for the moving vehicle itself and independent moving objects. The second is dynamic occupancy grid mapping, which is based on the estimated motion information and the dense disparity map. The main benefit of the proposed framework is the ability of mapping occupied areas and moving objects at the same time. This is very practical in real applications. The proposed method is evaluated using real data acquired by our intelligent vehicle platform "SeTCar" in urban environments.},
author = {Li, You and Ruichek, Yassine},
doi = {10.3390/s140610454},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li, Ruichek - 2014 - Occupancy grid mapping in urban environments from a moving on-board stereo-vision system.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Intelligent vehicles,Occupancy grid map,U-V disparity image},
mendeley-groups = {Robotics/Maps},
number = {6},
pages = {10454--10478},
pmid = {24932866},
title = {{Occupancy grid mapping in urban environments from a moving on-board stereo-vision system}},
volume = {14},
year = {2014}
}
@misc{Grabowski2000,
abstract = {In this article, we present the design of a team of heterogeneous, centimeter-scale robots that collaborate to map and explore unknown environments. The robots, called Millibots, are configured from modular components that include sonar and IR sensors, camera, communication, computation, and mobility modules. Robots with different configurations use their special capabilities collaboratively to accomplish a given task. For mapping and exploration with multiple robots, it is critical to know the relative positions of each robot with respect to the others. We have developed a novel localization system that uses sonar-based distance measurements to determine the positions of all the robots in the group. With their positions known, we use an occupancy grid Bayesian mapping algorithm to combine the sensor data from multiple robots with different sensing modalities. Finally, we present the results of several mapping experiments conducted by a userguided team of five robots operating in a roo...},
author = {Grabowski, Robert and Navarro-Serment, Luis E. and Paredis, Christiaan J J and Khosla, Pradeep K.},
booktitle = {Autonomous Robots},
doi = {10.1023/A:1008933826411},
file = {:home/tkorthals/Documents/Mendeley Desktop/Grabowski et al. - 2000 - Heterogeneous teams of modular robots for mapping and exploration.crdownload:crdownload},
issn = {09295593},
mendeley-groups = {Robotics/Maps},
number = {3},
pages = {293--308},
title = {{Heterogeneous teams of modular robots for mapping and exploration}},
volume = {8},
year = {2000}
}
@article{Rudin2004,
abstract = {We study two boosting algorithms, Coordinate Ascent Boosting and Approximate$\backslash$nCoordinate Ascent Boosting, which are explicitly designed to produce$\backslash$nmaximum margins. To derive these algorithms, we introduce a smooth$\backslash$napproximation of the margin that one can maximize in order to produce$\backslash$na maximum margin classifier. Our first algorithm is simply coordinate$\backslash$nascent on this function, involving a line search at each step. We$\backslash$nthen make a simple approximation of this line search to reveal our$\backslash$nsecond algorithm. These algorithms are proven to asymptotically achieve$\backslash$nmaximum margins, and we provide two convergence rate calculations.$\backslash$nThe second calculation yields a faster rate of convergence than the$\backslash$nfirst, although the first gives a more explicit (still fast) rate.$\backslash$nThese algorithms are very similar to AdaBoost in that they are based$\backslash$non coordinate ascent, easy to implement, and empirically tend to$\backslash$nconverge faster than other boosting algorithms. Finally, we attempt$\backslash$nto understand AdaBoost in terms of our smooth margin, focusing on$\backslash$ncases where AdaBoost exhibits cyclic behavior.},
author = {Rudin, Cynthia and Schapire, Robert E and Daubechies, Ingrid},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rudin, Schapire, Daubechies - 2004 - Boosting Based on a Smooth Margin.pdf:pdf},
issn = {03029743},
journal = {Learning Theory},
mendeley-groups = {Robotics/Sensing},
number = {0302-9743},
pages = {502--517},
title = {{Boosting Based on a Smooth Margin}},
volume = {3120/2004},
year = {2004}
}
@article{Moerland1997,
author = {Moerland, Perry},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moerland - 1997 - Some Methods for Training Mixtures of Experts.pdf:pdf},
mendeley-groups = {Robotics/Sensing},
pages = {IDIAP--Com 97--05},
title = {{Some Methods for Training Mixtures of Experts}},
year = {1997}
}
@article{Dedieu,
author = {Dedieu, Eric and del {R. Mill{\'{a}}n}, Jos{\'{e}}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dedieu, R. Mill{\'{a}}n - Unknown - Efficient Occupancy Grids for Variable Resolution Map Building.pdf:pdf},
mendeley-groups = {Robotics/Maps},
title = {{Efficient Occupancy Grids for Variable Resolution Map Building}}
}
@article{Freund2001,
abstract = {We propose a new boosting algorithm. This boosting algorithm is an adaptive version of the boost by majority algorithm and combines bounded goals of the boost by majority algorithm with the adaptivity of AdaBoost. The method used for making boost-by-majority adaptive is to consider the limit in which each of the boosting iterations makes an infinitesimally small contribution to the process as a whole. This limit can be modeled using the differential equations that govern Brownian motion. The new boosting algorithm, named BrownBoost, is based on finding solutions to these differential equations. The paper describes two methods for finding approximate solutions to the differential equations. The first is a method that results in a provably polynomial time algorithm. The second method, based on the Newton-Raphson minimization procedure, is much more efficient in practice but is not known to be polynomial.},
author = {Freund, Yoav},
doi = {10.1023/A:1010852229904},
file = {:home/tkorthals/Documents/Mendeley Desktop/Freund - 2001 - An adaptive version of the boost by majority algorithm.pdf:pdf},
isbn = {1581131674},
issn = {08856125},
journal = {Machine Learning},
keywords = {AdaBoost,Boosting,Brownian motion,Drifting games,Ensamble learning},
mendeley-groups = {Robotics/Sensing},
number = {3},
pages = {293--318},
title = {{An adaptive version of the boost by majority algorithm}},
volume = {43},
year = {2001}
}
@article{Segal2009,
abstract = {In this paper we combine the Iterative Closest Point ('ICP') and ‘point-to-plane ICP‘ algorithms into a single probabilistic framework. We then use this framework to model locally planar surface structure from both scans instead of just the ”model” scan as is typically done with the point-to-plane method. This can be thought of as ‘plane-to-plane'. The new approach is tested with both simulated and real-world data and is shown to outperform both standard ICP and point-to-plane. Furthermore, the new approach is shown to be more robust to incorrect correspondences, and thus makes it easier to tune the maximum match distance parameter present in most variants of ICP. In addition to the demonstrated performance improvement, the proposed model allows for more expressive probabilistic models to be incorporated into the ICP framework. While maintaining the speed and simplicity of ICP, the Generalized-ICP could also allow for the addition of outlier terms, measurement noise, and other probabilistic techniques to increase robustness.},
author = {Segal, a and Haehnel, D and Thrun, S},
doi = {10.1.1.149.3870},
file = {:home/tkorthals/Documents/Mendeley Desktop/Segal, Haehnel, Thrun - 2009 - Generalized-ICP.pdf:pdf},
journal = {Robotics: Science and Systems},
keywords = {ICP,point-to-plane,point-to-point,registration},
mendeley-groups = {Robotics/Maps},
title = {{Generalized-ICP}},
year = {2009}
}
@article{Arbuckle2002,
abstract = { This paper introduces the concept of a temporal occupancy grid as a method for modeling and classifying spatial areas according to the time properties of their occupancy. The method extends the idea of occupancy grids by considering occupancy over a number of different timescales. This paper presents the basic formalism and its implementation using planar laser rangefinders. It includes the results of a number of validation experiments, and an experiment in which we demonstrate the ability to locate doors in a real-world setting.},
author = {Arbuckle, D. and Howard, a. and Mataric, M.},
doi = {10.1109/IRDS.2002.1041424},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arbuckle, Howard, Mataric - 2002 - Temporal occupancy grids a method for classifying the spatio-temporal properties of the environment.pdf:pdf},
isbn = {0-7803-7398-7},
journal = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
mendeley-groups = {Robotics/Maps},
pages = {409--414},
title = {{Temporal occupancy grids: a method for classifying the spatio-temporal properties of the environment}},
volume = {1},
year = {2002}
}
@article{Masoudnia2014,
author = {Masoudnia, Saeed and Ebrahimpour, Reza},
doi = {10.1007/s10462-012-9338-y},
file = {:home/tkorthals/Documents/Mendeley Desktop/Masoudnia, Ebrahimpour - 2014 - Mixture of experts A literature survey.pdf:pdf},
issn = {02692821},
journal = {Artificial Intelligence Review},
keywords = {Classifier combining,Mixture of experts,Mixture of explicitly localised expert,Mixture of implicitly localised experts},
mendeley-groups = {Robotics/Sensing},
number = {2},
pages = {275--293},
title = {{Mixture of experts: A literature survey}},
volume = {42},
year = {2014}
}
@article{Ferrari2011,
author = {Ferrari, Denise B and Milioni, Armando Z},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ferrari, Milioni - 2011 - CHOICES AND PITFALLS CONCERNING MIXTURE-OF-EXPERTS MODELING.pdf:pdf},
keywords = {clustering,gating function,mem,mixture-of-experts model},
mendeley-groups = {Robotics/Sensing},
pages = {95--111},
title = {{CHOICES AND PITFALLS CONCERNING MIXTURE-OF-EXPERTS MODELING}},
volume = {31},
year = {2011}
}
@article{Yi2000,
author = {Yi, Zou and Khing, Hy and Seng, Cc},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yi, Khing, Seng - 2000 - Multi-ultrasonic sensor fusion for autonomous mobile robots.pdf:pdf},
issn = {0277786X},
journal = {Sensor fusion: Architectures, algorithms and applications; Proc. SPIE},
keywords = {dempster-shafer,mobile robot,sensor fusion,specular reflection,ultrasonic sensor},
mendeley-groups = {Robotics/Sensing},
number = {4051},
pages = {314--321},
title = {{Multi-ultrasonic sensor fusion for autonomous mobile robots}},
url = {http://www.cs.umu.se/research/ifor/dl/Sensors/Multi-ultrasonic sensor fusion for autonomous mobile robots.pdf},
volume = {IV},
year = {2000}
}
@article{Monks2012,
author = {M{\"{o}}nks, Uwe and Voth, Karl and Lohweg, Volker},
doi = {10.1109/CIP.2012.6232905},
file = {:home/tkorthals/Documents/Mendeley Desktop/M{\"{o}}nks, Voth, Lohweg - 2012 - An extended perspective on evidential aggregation rules in machine condition monitoring.pdf:pdf},
isbn = {9781467318785},
journal = {2012 3rd International Workshop on Cognitive Information Processing, CIP 2012},
mendeley-groups = {Robotics/Sensing},
number = {1},
pages = {0--5},
title = {{An extended perspective on evidential aggregation rules in machine condition monitoring}},
year = {2012}
}
@article{Lohweg2010,
abstract = {Many of the existing fusion approaches based on Dempster-Shafer Theory (DST) tend to be unreliable in various scenarios. Therefore, this topic is still in discussion. In this work a Two-Layer Conflict Solving (TLCS) data fusion scheme is proposed which is based on Dempster-Shafer Theory and on Fuzzy-Pattern-Classification (FPC) concepts. The aim is to provide an approach to data fusion which provides a stable conflict scenario handling. Furthermore, the scheme can easily be extended to fuzzy classification and is applicable to sensor fusion applications. Therefore, the suggested approach will contribute as a novel fuzzy fusion method.},
author = {Lohweg, Volker and M{\"{o}}nks, Uwe},
doi = {10.1109/CIP.2010.5604094},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lohweg, M{\"{o}}nks - 2010 - Sensor fusion by Two-Layer Conflict Solving.pdf:pdf},
isbn = {9781424464593},
issn = {2150-4938},
journal = {2010 2nd International Workshop on Cognitive Information Processing, CIP2010},
mendeley-groups = {Robotics/Sensing},
number = {July 2015},
pages = {370--375},
title = {{Sensor fusion by Two-Layer Conflict Solving}},
year = {2010}
}
@article{Dempster1967,
author = {Dempster, A. P.},
doi = {10.1214/aoms/1177698950},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dempster - 1967 - Upper and Lower Probabilities Induced by a Multivalued Mapping.pdf:pdf},
journal = {Ann. Math. Statist.},
mendeley-groups = {Robotics/Sensing},
number = {2},
pages = {325--339},
title = {{Upper and Lower Probabilities Induced by a Multivalued Mapping}},
url = {http://projecteuclid.org/euclid.aoms/1177698950},
volume = {38},
year = {1967}
}
@article{Li2008,
author = {Li, Rui and Lohweg, Volker},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li, Lohweg - 2008 - A Novel Data Fusion Approach using Two-Layer Conflict Solving.pdf:pdf},
journal = {IAPR Workshop on Cognitive Information Processing, {\ldots}},
mendeley-groups = {Robotics/Sensing},
number = {3},
pages = {132--136},
title = {{A Novel Data Fusion Approach using Two-Layer Conflict Solving}},
url = {http://www.eurasip.org/Proceedings/Ext/CIP2008/papers/1569094849.pdf},
year = {2008}
}
@book{Shafer1976,
address = {Princeton},
author = {Shafer, Glenn},
keywords = {dempster-shafer,evidence-theory},
mendeley-groups = {Machine Learning},
mendeley-tags = {dempster-shafer,evidence-theory},
publisher = {Princeton University Press},
title = {{A Mathematical Theory of Evidence}},
year = {1976}
}
@article{Thomas2010,
author = {Thomas, R and Laue, Tim and Judith, M and Burchardt, Armin and Damrose, Erik and Fabisch, Alexander and Feldpausch, Fynn and Gillmann, Katharina and Graf, Colin and Haas, Thijs Jeffry De and Alexander, H and Honsel, Daniel and Kastner, Philipp and Kastner, Tobias and Markowsky, Benjamin and Mester, Michael and Peter, Jonas and Jan, Ole and Riemann, Lars and Ring, Martin and Sauerland, Wiebke},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thomas et al. - 2010 - B-Human Team Report and Code Release 2010.pdf:pdf},
journal = {RoboCup 2010: Robot Soccer World Cup XII Preproceedings},
mendeley-groups = {Robotics},
pages = {1--127},
title = {{B-Human Team Report and Code Release 2010}},
year = {2010}
}
@article{Kargas2010,
author = {Kargas, Nikolaos and Kofinas, Nikolaos and Michelioudakis, Evangelos and Pavlakis, Nikolaos and Piperakis, Stylianos and Spanoudakis, Nikolaos I and Lagoudakis, Michail G},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kargas et al. - 2010 - Kouretes 2010 SPL Team Description Paper.pdf:pdf},
mendeley-groups = {Robotics},
pages = {1--8},
title = {{Kouretes 2010 SPL Team Description Paper}},
year = {2010}
}
@article{Kohlbrecher2011a,
abstract = {For many applications in Urban Search and Rescue (USAR) scenarios robots need to learn a map of unknown environments. We present a system for fast online learning of occupancy grid maps requiring low computational resources. It combines a robust scan matching approach using a LIDAR system with a 3D attitude estimation system based on inertial sensing. By using a fast approximation of map gradients and a multi-resolution grid, reliable localization and mapping capabilities in a variety of challenging environments are realized. Multiple datasets showing the applicability in an embedded hand-held mapping system are provided. We show that the system is sufficiently accurate as to not require explicit loop closing techniques in the considered scenarios. The software is available as an open source package for ROS.},
author = {Kohlbrecher, Stefan and {Von Stryk}, Oskar and Meyer, Johannes and Klingauf, Uwe},
doi = {10.1109/SSRR.2011.6106777},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kohlbrecher et al. - 2011 - A flexible and scalable SLAM system with full 3D motion estimation.pdf:pdf},
isbn = {9781612847696},
journal = {9th IEEE International Symposium on Safety, Security, and Rescue Robotics, SSRR 2011},
keywords = {Inertial Navigation,Robust and Fast Localization,Simultaneous Localization and Mapping},
mendeley-groups = {Robotics/SLAM},
pages = {155--160},
title = {{A flexible and scalable SLAM system with full 3D motion estimation}},
year = {2011}
}
@article{Coue2006,
abstract = {Reliable and efficient perception and reasoning in dynamic and densely cluttered environments are still major challenges for driver assistance systems. Most of today's systems use target tracking al- gorithms based on object models. They work quite well in simple en- vironments such as freeways, where few potential obstacles have to be considered. However, these approaches usually fail in more com- plex environments featuring a large variety of potential obstacles, as is usually the case in urban driving situations. In this paper, we propose a new approach for robust perception and risk assessment in highly dynamic environments. This approach is called Bayesian occupancy filtering; it basically combines a four-dimensional occu- pancy grid representation of the obstacle state space with Bayesian filtering techniques.},
author = {Coue, C. and Pradalier, C. and Laugier, C. and Fraichard, T. and Bessiere, P.},
doi = {10.1177/0278364906061158},
file = {:home/tkorthals/Documents/Mendeley Desktop/Coue et al. - 2006 - Bayesian Occupancy Filtering for Multitarget Tracking An Automotive Application.pdf:pdf},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
mendeley-groups = {Robotics/Maps},
number = {1},
pages = {19--30},
title = {{Bayesian Occupancy Filtering for Multitarget Tracking: An Automotive Application}},
volume = {25},
year = {2006}
}
@article{Haehnel2003,
abstract = {The problem of generating maps with mobile robots has received considerable attention over the past years. Most of the techniques developed so far have been designed for situations in which the environment is static during the mapping process. Dynamic objects, however, can lead to serious errors in the resulting maps such as spurious objects or misalignments due to localization errors. In this paper we consider the problem of creating maps with mobile robots in dynamic environments. We present a new approach that interleaves mapping and localization with a probabilistic technique to identify spurious measurements. In several experiments we demonstrate that our algorithm generates accurate 2D and 3D in different kinds of dynamic indoor and outdoor environments. We also use our algorithm to isolate the dynamic objects and generate 3D representation of them.},
author = {H{\"{a}}hnel, D. and Triebel, R. and Burgard, W. and Thrun, S.},
doi = {10.1109/ROBOT.2003.1241816},
file = {:home/tkorthals/Documents/Mendeley Desktop/H{\"{a}}hnel et al. - 2003 - Map building with mobile robots in dynamic environments.pdf:pdf},
isbn = {0-7803-7736-2},
issn = {1050-4729},
journal = {2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422)},
mendeley-groups = {Robotics/Maps},
pages = {1557--1563},
pmid = {1241816},
title = {{Map building with mobile robots in dynamic environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1241816},
volume = {2},
year = {2003}
}
@article{Moravec1985,
abstract = {We describe the use of multiple wide-angle sonar range measurements to map the surroundings of an autonomous mobile robot. A sonar range reading provides information concerning empty and occupied volumes in a cone (subtending 30 degrees in our case) in front of the sensor. The reading is modelled as probability profiles projected onto a rasterized map, where somewhere occupied and everywhere empty areas are represented. Range measurements from multiple points of view (taken from multiple sensors on the robot, and from the same sensors after robot moves) are systematically integrated in the map. Overlapping empty volumes re-inforce each other, and serve to condense the range of occupied volumes. The map definition improves as more readings are added. The final map shows regions probably occupied, probably unoccupied, and unknown areas. The method deals effectively with clutter, and can be used for motion planning and for extended landmark recognition. This system has been tested on the Neptune mobile robot at CMU.},
author = {Moravec, H. and Elfes, A.},
doi = {10.1109/ROBOT.1985.1087316},
file = {:home/tkorthals/Documents/Mendeley Desktop/Moravec, Elfes - 1985 - High resolution maps from wide angle sonar.pdf:pdf},
isbn = {VO - 2},
journal = {Proceedings. 1985 IEEE International Conference on Robotics and Automation},
mendeley-groups = {Robotics/Maps},
pages = {116--121},
pmid = {1087316},
title = {{High resolution maps from wide angle sonar}},
url = {http://ieeexplore.ieee.org/document/1087316/},
volume = {2},
year = {1985}
}
@article{Keogh2005,
abstract = {The problem of indexing time series has attracted much interest. Most algorithms used to index time series utilize the Euclidean distance or some variation thereof. However, it has been forcefully shown that the Euclidean distance is a very brittle distance measure. Dy- namic time warping (DTW) is a much more robust distance measure for time series, allowing similar shapes to match even if they are out of phase in the time axis. Because of this flexi- bility, DTW is widely used in science, medicine, industry and finance. Unfortunately, however, DTW does not obey the triangular inequality and thus has resisted attempts at exact indexing. Instead, many researchers have introduced approximate indexing techniques or abandoned the idea of indexing and concentrated on speeding up sequential searches. In this work, we intro- duce a novel technique for the exact indexing of DTW. We prove that our method guarantees no false dismissals and we demonstrate its vast superiority over all competing approaches in the largest and most comprehensive set of time series indexing experiments ever undertaken.},
author = {Keogh, Eamonn and Ratanamahatana, Chotirat Ann},
doi = {10.1007/s10115-004-0154-9},
file = {:home/tkorthals/Documents/Mendeley Desktop/Keogh, Ratanamahatana - 2005 - Exact indexing of dynamic time warping.pdf:pdf},
isbn = {9781558608696},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Dynamic time warping,Indexing,Lower bounding,Time series},
mendeley-groups = {CLAAS itsowl/Lane Detection},
pages = {358--386},
title = {{Exact indexing of dynamic time warping}},
volume = {7},
year = {2005}
}
@article{Cilulko2013,
abstract = {Thermography is an imaging method which registers infrared waves in the electromagnetic spectrum that are emitted by all objects on the Earth. The state and properties of the studied objects and organisms can be evaluated by analyzing images of temperature distribution on their surface. Thermography has numerous practical applications, including in construction, industry, and the military and civil services. In natural sciences, thermal imaging techniques support safe and non-invasive measurements and the acquisition of results that cannot be obtained by any other method. Infrared thermography also creates a wide range of applications for human and veterinary medicine, ecology, zoology, and other natural sciences. Thermal imaging equipment is used to detect injuries, inflammations, and infectious diseases to control reproduction (detection of estrus and pregnancy, determination of male fertility) and lactation processes. The discussed method is applied to investigate thermoregulation in animals, to analyze the effect of environmental factors on animal behavior, to localize individuals and their habitats, and to determine the size of wildlife populations. Despite a wide range of practical applications, thermal imaging has a number of limitations which should be taken into account in studies that rely on infrared thermography techniques.},
author = {Cilulko, Justyna and Janiszewski, Pawe{\l} and Bogdaszewski, Marek and Szczygielska, Eliza},
doi = {10.1007/s10344-012-0688-1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cilulko et al. - 2013 - Infrared thermal imaging in studies of wild animals.pdf:pdf},
issn = {16124642},
journal = {European Journal of Wildlife Research},
keywords = {Detection of animals,Estimation of population size,Non-invasive tests,Thermography},
mendeley-groups = {CLAAS itsowl/Thermal Imaging},
number = {1},
pages = {17--23},
title = {{Infrared thermal imaging in studies of wild animals}},
volume = {59},
year = {2013}
}
@article{Israel2011,
author = {Israel, Martin and Evers, Stephan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Israel, Evers - 2011 - Mustererkennung zur Detektion von Rehkitzen in Thermalbildern.pdf:pdf},
journal = {17. und 18. Workshop Computer-Bildanalyse in der Landwirtschaft},
mendeley-groups = {CLAAS itsowl/Thermal Imaging},
pages = {1--6},
title = {{Mustererkennung zur Detektion von Rehkitzen in Thermalbildern}},
url = {http://elib.dlr.de/71467/1/Mustererkennung{\_}zur{\_}Detektion{\_}von{\_}Rehkitzen{\_}in{\_}Thermalbildern.pdf},
year = {2011}
}
@article{Bouzouraa2010,
abstract = {in this paper we present a novel environment perception system based on an occupancy grid mapping and a multi-object tracking. The goal of such a system is to create a harmonic, consistent and complete representation of the vehicle environment as a base for future advanced driver assistance systems. In addition to a mathematical formulation of the problem we present a robust algorithm to detect dynamic obstacles from the occupancy map and show how both, the mapping process and the tracking can benefit from each other. Therefore, the concept of moving objects with associated dynamic cells is introduced. The presented techniques are applicable to both 2D and 3D mapping and can be also extended to correct the ego motion from the occupancy map and the object tracks. Unlike many publications over the last years our work provides real time performance and an accurate detection of obstacles with real laser and radar sensors and can fulfill the requirements of future driver assistance systems.},
author = {Bouzouraa, M.E. and Hofmann, U.},
doi = {10.1109/IVS.2010.5548106},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouzouraa, Hofmann - 2010 - Fusion of occupancy grid mapping and model based object tracking for driver assistance systems using laser a.pdf:pdf},
isbn = {978-1-4244-7866-8},
issn = {1931-0587},
journal = {Intelligent Vehicles Symposium (IV), 2010 IEEE},
mendeley-groups = {Robotics/Maps},
pages = {294--300},
title = {{Fusion of occupancy grid mapping and model based object tracking for driver assistance systems using laser and radar sensors}},
year = {2010}
}
@article{Pathak2007,
abstract = {This paper presents a new technique for the update of a probabilistic spatial occupancy grid map using a forward sensor model. Unlike currently popular inverse sensor models, forward sensor models can be found experimentally and can represent sensor characteristics better. The formulation is applicable to both 2D and 3D range sensors and does not have some of the theoretical and practical problems associated with the current approaches which use forward models. As an illustration of this procedure, a new prototype 3D forward sensor model is derived using a beam represented as a spherical sector. Furthermore, this model is used for fusion of point-clouds obtained from different 3D sensors, in particular, time-of-flight sensors (Swiss-ranger, laser range finders), and stereo vision cameras. Several techniques are described for an efficient data-structure representation and implementation. The range beams from different sensors are fused in a common local Cartesian occupancy map. Experimental results of this fusion are presented and evaluated using Hough-transform performed on the grid.},
author = {Pathak, Kaustubh and Birk, Andreas and Poppinga, Jann and Schwertfeger, S{\"{o}}ren},
doi = {10.1109/IROS.2007.4399406},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pathak et al. - 2007 - 3D Forward sensor modeling and application to occupancy grid based sensor fusion.pdf:pdf},
isbn = {1424409128},
journal = {IEEE International Conference on Intelligent Robots and Systems},
mendeley-groups = {CLAAS itsowl/Sensorfusion/OGM,Robotics/Maps},
pages = {2059--2064},
title = {{3D Forward sensor modeling and application to occupancy grid based sensor fusion}},
volume = {2},
year = {2007}
}
@article{Konolige1997,
abstract = {Occupancy grids are a probabilistic method for fusing multiplesensor readings into surface maps of the environment. Although theunderlying theory has been understood for many years, the intricacies ofapplying it to realtime sensor interpretation have been neglected. Thispaper analyzes how refined sensor models (including specularity models) andassumptions about independence are crucial issues for occupancy gridinterpretation. Using this analysis, the MURIEL method for occupancy gridupdate is developed. Experiments show how it can dramatically improve thefidelity of occupancy grid map-making in specular and realtimeenvironments.},
author = {Konolige, Kurt},
doi = {10.1023/A:1008806422571},
file = {:home/tkorthals/Documents/Mendeley Desktop/Konolige - 1997 - Improved Occupancy Grids for Map Building.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
keywords = {map-making,occupancy grids,sensor fusion},
mendeley-groups = {Robotics/Maps},
number = {4},
pages = {351--367},
title = {{Improved Occupancy Grids for Map Building}},
url = {http://dx.doi.org/10.1023/A:1008806422571},
volume = {4},
year = {1997}
}
@article{Carlson2005,
abstract = {A model of the world built from sensor data may be incorrect even if the sensors are functioning correctly. Possible causes include the use of inappropriate sensors (e.g. a laser looking through glass walls), sensor inaccuracies accumulate (e.g. localization errors), the a priori models are wrong, or the internal representation does not match the world (e.g. a static occupancy grid used with dynamically moving objects). We are interested in the case where the constructed model of the world is flawed, but there is no access to the ground truth that would allow the system to see the discrepancy, such as a robot entering an unknown environment. This paper considers the problem of determining when something is wrong using only the sensor data used to construct the world model. It proposes 11 interpretation inconsistency indicators based on the Dempster-Shafer conflict metric, Con, and evaluates these indicators according to three criteria: ability to distinguish true inconsistency from sensor noise (classification), estimate the magnitude of discrepancies (estimation), and determine the source(s) (if any) of sensing problems in the environment (isolation). The evaluation is conducted using data from a mobile robot with sonar and laser range sensors navigating indoor environments under controlled conditions. The evaluation shows that the Gambino indicator performed best in terms of estimation (at best 0.77 correlation), isolation, and classification of the sensing situation as degraded (7{\%} false negative rate) or normal (0{\%} false positive rate).},
archivePrefix = {arXiv},
arxivId = {1207.1374},
author = {Carlson, Jennifer and Murphy, Rr},
eprint = {1207.1374},
file = {:home/tkorthals/Documents/Mendeley Desktop/Carlson, Murphy - 2005 - Use of Dempster-Shafer Conflict Metric to Detect Interpretation Inconsistency.pdf:pdf},
isbn = {0-9749039-1-4},
journal = {Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence (UAI2005)},
mendeley-groups = {Robotics/Maps},
title = {{Use of Dempster-Shafer Conflict Metric to Detect Interpretation Inconsistency}},
url = {http://arxiv.org/abs/1207.1374},
volume = {abs/1207.1},
year = {2005}
}
@inproceedings{Elfes1990,
abstract = {In this paper we provide an overview of a new framework for robot perception, real-world modelling, and navigation that uses a stochastic tesselated representation of spatial information called the Occupancy Grid. The Occupancy Grid is a multi-dimensional random field model that maintains probabilistic estimates of the occupancy state of each cell in a spatial lattice. Bayesian estimation mechanisms employing stochastic sensor models allow incremental updating of the Occupancy Grid using multi-view, multi-sensor data, composition of multiple maps, decision-making, and incorporation of robot and sensor position uncertainty. We present the underlying stochastic formulation of the Occupancy Grid framework, and discuss its application to a variety of robotic tusks. These include range-based mapping, multi-sensor integration, path-planning and obstacle avoidance, handling of robot position uncertainty, incorporation of pre-compiled maps, recovery of geometric representations, and other related problems. The experimental results show that the Occupancy Grid approach generates dense world models, is robust under sensor uncertainty and errors, and allows explicit handling of uncertainty. It supports the development of robust and agile sensor interpretation methods, incremental discovery procedures, and composition of information from multiple sources. Furthermore, the results illustrate that robotic tasks can be addressed through operations performed di- rectly on the Occupancy Grid, and that these operations have strong parallels to operations performed in the image processing domain.},
author = {Elfes, Alberto},
booktitle = {Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence},
file = {:home/tkorthals/Documents/Mendeley Desktop/Elfes - 1990 - Occupancy Grids A Stochastical Spatial Representation for Active Robot Perception.pdf:pdf},
mendeley-groups = {Robotics/Maps},
title = {{Occupancy Grids: A Stochastical Spatial Representation for Active Robot Perception}},
year = {1990}
}
@article{Burgard,
author = {Burgard, Wolfram and Stachniss, Cyrill},
file = {:home/tkorthals/Documents/Mendeley Desktop/Burgard, Stachniss - Unknown - Graph-Based SLAM.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Graph},
title = {{Graph-Based SLAM}},
url = {http://ais.informatik.uni-freiburg.de/teaching/ss13/robotics/slides/16-graph-slam.pdf}
}
@inproceedings{matthies1988integration,
author = {Matthies, Larry and Elfes, Alberto},
booktitle = {Robotics and Automation, 1988. Proceedings., 1988 IEEE International Conference on},
mendeley-groups = {Robotics/Maps},
organization = {IEEE},
pages = {727--733},
title = {{Integration of sonar and stereo range data using a grid-based representation}},
year = {1988}
}
@article{Grisetti2010,
author = {Grisetti, Giorgio and Kummerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1109/MITS.2010.939925},
file = {:home/tkorthals/Documents/Mendeley Desktop/Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf:pdf},
isbn = {1939-1390 VO - 2},
issn = {1939-1390},
mendeley-groups = {Robotics/SLAM/Graph,Robotics/SLAM},
pages = {1--11},
title = {{A Tutorial on Graph-Based SLAM}},
url = {http://www2.informatik.uni-freiburg.de/{~}stachnis/pdf/grisetti10titsmag.pdf},
year = {2010}
}
@article{Abbeel,
author = {Abbeel, Pieter},
file = {:home/tkorthals/Documents/Mendeley Desktop/Abbeel - Unknown - GraphSLAM.pdf:pdf},
mendeley-groups = {Robotics/SLAM/Graph},
title = {{GraphSLAM}}
}
@article{Kuipers1978,
abstract = {A person's cognitive map. or knowledge of large-scale space, is built up from observa- tions gathered as he travels through the environment. It acts as a problem solver to find routes and relative positions, as well as describing the current location. The TOUR model captures the mulaple representations that make up the cognitive map, the problem-solving strategies it uses, and the mechanisms for assimdating new information. The representations have rich collections of stales of partial knowledge, which support many of the performance characteristics of common-sense knowledge.},
author = {Kuipers, B},
doi = {10.1016/S0364-0213(78)80003-2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kuipers - 1978 - Modeling spatial knowledge.pdf:pdf},
isbn = {0364-0213},
issn = {03640213},
journal = {Cognitive Science},
mendeley-groups = {Robotics/Maps},
number = {2},
pages = {129--153},
title = {{Modeling spatial knowledge}},
url = {http://doi.wiley.com/10.1016/S0364-0213(78)80003-2},
volume = {2},
year = {1978}
}
@article{Chatila1985,
abstract = { In order to understand its environment, a mobile robot should be able to model consistently this environment, and to locate itself correctly. One major difficulty to be solved is the inaccuracies introduced by the sensors. The approach proposed in this paper to cope with this problem relies on 1) defining general principles to deal with uncertainties : the use of a multisensory system, favo ring of the data collected by the more accurate sensor in a given situation, averaging of different but consistent measurements of the same entity weighted with their associated uncertainties, and 2) a methodology enabling a mobile robot to define its own reference landmarks while exploring its environment. These ideas are presented together with an example of their application on the mobile robot HILARE.},
author = {Chatila, R. and Laumond, J.},
doi = {10.1109/ROBOT.1985.1087373},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chatila, Laumond - 1985 - Position referencing and consistent world modeling for mobile robots.pdf:pdf},
journal = {Proceedings. 1985 IEEE International Conference on Robotics and Automation},
mendeley-groups = {Robotics/Maps},
pmid = {1087373},
title = {{Position referencing and consistent world modeling for mobile robots}},
volume = {2},
year = {1985}
}
@phdthesis{Haehnel2004,
abstract = {Today, mapping is largely considered the most difficult perceptual problem in robotics. Different problems like the statistical dependence, the correspondence problem, or dynamic elements makes mapping so hard. The basic technique for mapping is incremental scan matching. We present a method, which maximizes the likelihood of a scan, given a motion model and the map built so far. This approach is the constitutive techniques for further methods which addresses special topics of the previous described problems. In this thesis we describe following methods: We present a technique which combines a people tracker in the mapping process to filter measurements caused by walking people. Additional to the fact that maps contains less spurious objects, the accuracy of the results can be increased. We present a second technique which is able to filter measurements caused by dynamic objects. This time dynamic objects are not limited to walking persons, every dynamic object can be filtered out if the place of this object was seen as both: as free space as well as occupied space. An EM-technique is used to optimize the mapping results and in several practical experiments we will show that this approach can effectively filter beams of different dynamic objects like humans, cars etc. A famous problem in mapping is the so called closing loop problem. When closing the cycle, the robot has to find out where it is relative to its previously built map. This problem is complicated by the fact that at the time of cycle closing, the robot's accumulated pose error might be unboundedly large. We describe an efficient version of the Rao-Blackwellized mapping approach. Using a Rao-Blackwellized particle filter is a good techniques for estimating the posterior. In combination with the scan matching technique we can decrease the number of particles, so that it can be executed online. The Rao-Blackwellized mapping approach suffers from the inherent problem of all particle filters: the particle depletion problem. We present a new algorithm for data association in SLAM. In essence, our approach searches the combinatorial tree of possible data association decisions. The search is lazy: only when an alternative assignment shows promise will it be evaluated. We tested our approach, and consistently found that it produces accurate maps, even if for maps with many large cycles. It can be difficult to distinguish places with data from range sensors as measurements can look the same at different positions. RFID tags have to nice property to be unique, they can report their identification numbers which are easy to distinguish. Unfortunately they don't provide any distance information, so that estimating the location of the RFID tags is a difficult problem. We present an approach to generate maps of RFID tags with mobile robots. We present a sensor model that allows us to compute the likelihood of tag detections given the relative position of the tag with respect to the robot. Additionally we describe how to compute a posterior about the position of a tag after the trajectory and the map is generated with a highly accurate Rao-Blackwellized mapping algorithm for laser range scans. We propose a technique for simultaneous scan registration and scan deformation for modeling nonrigid objects. The deformation is made possible through the definition of (soft) links between neighboring scan points, whose configuration is calculated during registration. To tackle the resulting optimization problem efficiently, we describe a hierarchical optimization techniques that operate on thinned graphs. Experimental results obtained using a mobile robot illustrate the viability of this approach. Finally, we present two examples for complete systems which are able to map their environment. The first system designed to autonomously explore and acquire 3D maps of abandoned mines is a 1,500 pound vehicle, nicknamed "Groundhog". The core of the Groundhog navigation system is comprised of a software package that solves the SLAM problem by acquiring 2D maps. Our research demonstrates that the autonomous acquisition of maps of abandoned mines is indeed feasible with autonomous robotic systems. The second system is an instrumented helicopter platform for 3D ground modeling. A real-time algorithm is developed that integrates pose estimates from multiple sensors with range data, acquired by a 2D laser range finders oriented perpendicular to the vehicle's flight direction. The algorithm uses a fast optimization technique to generate maps in real-time.},
author = {H{\"{a}}hnel, Dirk},
file = {:home/tkorthals/Documents/Mendeley Desktop/H{\"{a}}hnel - 2004 - Mapping with Mobile Robots.pdf:pdf},
mendeley-groups = {Robotics/Maps},
number = {December},
pages = {1--169},
school = {University of Freiburg},
title = {{Mapping with Mobile Robots}},
year = {2004}
}
@article{Kuipers1991,
abstract = {We have developed a robust qualitative method for robot exploration, mapping, and navigation in large-scale spatial environments. Experiments with a simulated robot in a variety of complex 2D environments have demonstrated that our qualitative method can build an accurate map of a previously unkown environment in spite of substantial random and systematic sensorimotor error. Most current approaches to robot exploration and mapping analyze sensor input to build a geometrically precise map of the environment, then extract topological structure from the geometric description. Our approach recognizes and exploits qualitative properties of large-scale before relatively error-prone geometrical properties. [sensorimotor {\textless}--{\textgreater} control] --{\textgreater} topology --{\textgreater} geometry At the control level, distinctive places and distinctive travel edges are identified based on the interaction between the robot's control strategies, its sensorimotor system, and the world. A distinctive place is defined as the local maximum of a distinctiveness measure appropriate to its immediate neighborhood, and is found by a hill-climbing control strategy. A distinctive travel edge, similarly, is defined by a suitable measure and a path-following control strategy. The topological network description is created by linking the distinctive places and travel edges.Metrical information is then incrementally assimilated into localgeometric descriptions of places and edges, and finally merged into a global geometric map. Topological ambiguity arising from sensorily indistinguishable places can be resolved at the topological level by the exploration strategy. With this representation, successful navigation is not critically dependent on the accuracy, or even the existence, of the geometrical description. We present examples demonstrating the process by which the robot explores and builds a map of a complex environment, including the effect of sensory errors. We also discuss new research directions that are suggested by this approach.},
author = {Kuipers, Benjamin and Byun, Yung-Tai},
doi = {10.1016/0921-8890(91)90014-C},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kuipers, Byun - 1991 - A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations.pdf:pdf},
isbn = {0262720175},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
mendeley-groups = {Robotics/Maps},
number = {1-2},
pages = {47--63},
title = {{A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations}},
volume = {8},
year = {1991}
}
@article{Matellan2008,
author = {Matell{\'{a}}n, Vicente},
file = {:home/tkorthals/Documents/Mendeley Desktop/Matell{\'{a}}n - 2008 - Multi-Agent versus Multi-Robot and Other Byzantian Discussions.pdf:pdf},
journal = {Journal Of Physical Agents},
mendeley-groups = {Robotics},
number = {1},
pages = {1--3},
title = {{Multi-Agent versus Multi-Robot and Other Byzantian Discussions}},
volume = {2},
year = {2008}
}
@phdthesis{Redenius2015,
author = {Redenius, Jannik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Redenius - 2015 - Bestimmung der Bestandsdichte eines Getreidefeldes durch bildgebende Umfeldsensorik bei M{\"{a}}hdreschern.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten,CLAAS itsowl},
title = {{Bestimmung der Bestandsdichte eines Getreidefeldes durch bildgebende Umfeldsensorik bei M{\"{a}}hdreschern}},
year = {2015}
}
@inproceedings{Elfes1992,
abstract = {An approach to dynamic planning and control of the perceptual activities of an autonomous mobile robot equipped with multiple sensor systems is considered. The robot is conceptually seen as an experimenter. The author discusses the explicit characterization of task-specific information requirements, the use of stochastic sensor models to determine the utility of sensory actions and perform sensor selection, and the application of information-theoretic models to measure the extent, accuracy, and complexity of the robot's world model. It is shown how the loci of interest of relevant information and the corresponding loci of observation can be computed, allowing the robot to servo on the information required to solve a given task. The use of these models is outlined in the development of strategies for perception control, and in the integration of perception and locomotion. Some illustrations of the methodology are provided},
author = {Elfes, Alberto},
doi = {10.1109/ROBOT.1992.220056},
file = {:home/tkorthals/Documents/Mendeley Desktop/Elfes - 1992 - Dynamic control of robot perception using multi-property inference grids.pdf:pdf},
keywords = {Inference Map},
mendeley-groups = {Robotics/Control,Robotics/Maps},
mendeley-tags = {Inference Map},
title = {{Dynamic control of robot perception using multi-property inference grids}},
year = {1992}
}
@article{Zelinsky1998,
author = {Zelinsky, Alexander},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zelinsky - 1998 - Mobile Robot Navigation based on localisation using Hidden Markov Models.pdf:pdf},
mendeley-groups = {Robotics/Navigation},
pages = {56--61},
title = {{Mobile Robot Navigation based on localisation using Hidden Markov Models.}},
year = {1998}
}
@article{Tripathi2014,
abstract = {Sensor data fusion using more than one senor such as sonar sensors fusion reduces uncertainties generated from a single sensor. To learn the environment using more than one sensor information, an accurate sensor model as well as a reasonable sensor fusion methodology is needed. In this work, the Moravec-Elfes sonar model for occupancy grid representation and the recursive Bayes update rule in sensor fusion is applied. The environment of the mobile robot may be highly uneven for that only one type of sensors are not enough. Hence to increase the sensor accuracy to a great extent, the information obtained from two sonar and two laser sensors are combined for identifying different shape of objects.},
author = {Tripathi, Priyanshu and Nagla, K.S. and Singh, Harvir and Mahajan, Sudhir},
doi = {10.1109/ICICICT.2014.6781251},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tripathi et al. - 2014 - Occupancy grid mapping for mobile robot using sensor fusion.pdf:pdf},
isbn = {978-1-4799-2900-9},
journal = {2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)},
keywords = {Bayesian inference,Laser fusion,Measurement by laser beam,Moravec-Elfes sonar model,Navigation,Occupancy grid,Robot sensing systems,Sensor fusion,Sonar,belief networks,laser beam applications,laser sensors,mobile robot,mobile robots,object shape identification,occupancy grid mapping,occupancy grid representation,recursive Bayes update rule,sensor accuracy,sensor data fusion,sensor fusion,sensor information,sensor model,sonar,sonar and laser sensors,sonar sensor fusion},
mendeley-groups = {Robotics/Maps},
pages = {47--51},
title = {{Occupancy grid mapping for mobile robot using sensor fusion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6781251},
year = {2014}
}
@phdthesis{Nuchter2006,
author = {N{\"{u}}chter, Andreas},
doi = {10.1353/ral.2006.0077},
file = {:home/tkorthals/Documents/Mendeley Desktop/N{\"{u}}chter - 2006 - Semantische dreidimensionale Karten f{\"{u}}r autonome mobile Roboter.pdf:pdf},
isbn = {3898383032},
keywords = {3D-Laserscanner,3D-Objekterkennung und -lokalisierung,3D-Szeneninterpretation,6D SLAM,Bonn,Kurt3D,Maps,Robotergest{\"{u}}tzte 3D-Kartenerstellung,Scanmatching,semantische Kartierung},
mendeley-groups = {Robotics/Maps},
mendeley-tags = {Bonn,Maps},
number = {3},
pages = {1--164},
school = {University of Bonn},
title = {{Semantische dreidimensionale Karten f{\"{u}}r autonome mobile Roboter}},
volume = {37},
year = {2006}
}
@article{Garcia2008,
author = {Garcia, Ruben and Aycard, Olivier and Vu, Trung-dung},
file = {:home/tkorthals/Documents/Mendeley Desktop/Garcia, Aycard, Vu - 2008 - High Level Sensor Data Fusion for Automotive Applications using Occupancy Grids.pdf:pdf},
isbn = {9781424422876},
mendeley-groups = {Robotics/Maps},
number = {December},
pages = {17--20},
title = {{High Level Sensor Data Fusion for Automotive Applications using Occupancy Grids}},
year = {2008}
}
@article{Milstein2005,
author = {Milstein, Adam},
file = {:home/tkorthals/Documents/Mendeley Desktop/Milstein - 2005 - Occupancy Grid Maps for Localization and Mapping.pdf:pdf},
journal = {Motion Planning},
mendeley-groups = {Robotics/Maps},
pages = {381--408},
title = {{Occupancy Grid Maps for Localization and Mapping}},
year = {2005}
}
@article{Kohlbrecher2011,
author = {Kohlbrecher, Stefan},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kohlbrecher - 2011 - Grid-based occupancy mapping and automatic gaze control for soccer playing humanoid robots.pdf:pdf},
journal = {{\ldots} Humanoid Soccer Robots {\ldots}},
mendeley-groups = {Robotics/Maps},
number = {October},
title = {{Grid-based occupancy mapping and automatic gaze control for soccer playing humanoid robots}},
url = {http://humanoidsoccer.org/ws11/papers/HSR11{\_}Kohlbrecher.pdf},
year = {2011}
}
@article{Zou2012,
abstract = {Im Rahmen dieser Arbeit werden am Anfang bestehende Ans{\"{a}}tze zur Freiraumerkennung im auto- mobilen Umfeld untersucht. Nach der Wiederholung von Grundlagen wird zwei Algorithmen zur Frei- raumbestimmung basierend auf einer zur Verf{\"{u}}gung gestellten Occupancy-Gridmap mit Frei-Evidenz in Matlab bzw. C++ entworfen. Zum Schluss werden die entwickelten Methoden mit den vorher gesam- melten Messdaten in Framework wxWavE {\"{u}}berpr{\"{u}}ft und eine Zusammenfassung wird ausgegeben.},
author = {Zou, Ruimin},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zou - 2012 - Free Space Detection Based On Occupancy Gridmaps.pdf:pdf},
keywords = {Advanced Driver Assistance System,Dynamic Programming,Free Space Computation,Occupancy Gridmap,Stereo Vision},
mendeley-groups = {Robotics/Maps},
number = {April},
title = {{Free Space Detection Based On Occupancy Gridmaps}},
url = {http://www.ias.informatik.tu-darmstadt.de/uploads/Theses/Zhou{\_}MScThesis{\_}2012.pdf},
year = {2012}
}
@article{Thrun2002,
abstract = {This article provides a comprehensive introduction into the field of robotic mapping, with a focus on indoor mapping. It describes and compares various probabilistic techniques, as they are presently being applied to a vast array of mobile robot mapping problems. The history of robotic mapping is also described, along with an extensive list of open research problems.},
archivePrefix = {arXiv},
arxivId = {1004.4027},
author = {Thrun, Sebastian},
doi = {10.1126/science.298.5594.699f},
eprint = {1004.4027},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thrun - 2002 - Robotic Mapping A Survey.pdf:pdf},
isbn = {9781558608115},
issn = {00368075},
journal = {Science},
keywords = {bayes filters,expectation maximization algorithm,exploration,filters,kalman,mobile robots,robotic mapping},
mendeley-groups = {Robotics/Maps},
number = {February},
pages = {1--35},
pmid = {634412},
title = {{Robotic Mapping: A Survey}},
volume = {298},
year = {2002}
}
@article{Chaudhuri2011,
author = {Chaudhuri, Sourish and Harvilla, Mark and Raj, Bhiksha},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhuri, Harvilla, Raj - 2011 - Unsupervised Learning of Acoustic Unit Descriptors for Audio Content Representation and Classification.pdf:pdf;:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhuri, Harvilla, Raj - Unknown - Unsupervised Learning of Acoustic Unit Descriptors for Audio Content Representation and Classificat.pdf:pdf},
journal = {INTERSPEECH},
mendeley-groups = {Master},
title = {{Unsupervised Learning of Acoustic Unit Descriptors for Audio Content Representation and Classification}},
url = {http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/mharvill/papers/INTERSPEECH11{\_}Chaudhuri.pdf},
year = {2011}
}
@book{Fraden2004,
author = {Fraden, Jacob},
doi = {10.1007/b97321},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fraden - 2004 - Handbook of Modern Sensors.pdf:pdf},
isbn = {0-387-00750-4},
mendeley-groups = {Robotics/Sensing},
pages = {608},
title = {{Handbook of Modern Sensors}},
url = {http://link.springer.com/10.1007/b97321},
year = {2004}
}
@article{Navarro2013,
abstract = {Swarm robotics is a field of multi-robotics in which large number of robots are coordinated in a distributed and decentralised way. It is based on the use of local rules, and simple robots compared to the complexity of the task to achieve, and inspired by social insects. Large number of simple robots can perform complex tasks in a more efficient way than a single robot, giving robustness and flexibility to the group. In this article, an overview of swarm robotics is given, describing its main properties and characteristics and comparing it to general multi-robotic systems. A review of different research works and experimental results, together with a discussion of the future swarm robotics in real world applications completes this work.},
author = {Navarro, I{\~{n}}aki and Mat{\'{i}}a, Fernando},
doi = {10.5402/2013/608164},
file = {:home/tkorthals/Documents/Mendeley Desktop/Navarro, Mat{\'{i}}a - 2013 - An Introduction to Swarm Robotics.pdf:pdf},
issn = {2090-8806},
journal = {ISRN Robotics},
mendeley-groups = {Robotics,Robotics/Multirobotics},
pages = {1--10},
title = {{An Introduction to Swarm Robotics}},
url = {http://www.hindawi.com/isrn/robotics/2013/608164/},
volume = {2013},
year = {2013}
}
@article{Fulgenzi2009,
author = {Fulgenzi, Chiara and Spalanzani, Anne and Laugier, Christian},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fulgenzi, Spalanzani, Laugier - 2009 - Probabilistic Rapidly-exploring Random Trees for autonomous navigation among moving obstacles.pdf:pdf},
journal = {Workshop on safe navigation, IEEE International Conference on Robotics and Automation (ICRA)},
mendeley-groups = {Robotics/Navigation},
title = {{Probabilistic Rapidly-exploring Random Trees for autonomous navigation among moving obstacles.}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.186.9418{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{Kak2014,
author = {Kak, Avinash},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kak - 2014 - ML, MAP, and Bayesian - The Holy Trinity of Parameter Estimation and Data Prediction.pdf:pdf},
mendeley-groups = {Machine Learning},
number = {August},
title = {{ML, MAP, and Bayesian - The Holy Trinity of Parameter Estimation and Data Prediction}},
year = {2014}
}
@article{Wachsmuth2015f,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise1.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
title = {{RoboCupSeminar{\_}exercise1}},
year = {2015}
}
@article{Wachsmuth2015b,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise6.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
pages = {1--2},
title = {{RoboCupSeminar{\_}exercise6}},
year = {2015}
}
@article{Marder-eppstein1998,
author = {Marder-eppstein, Eitan and Berger, Eric and Foote, Tully and Gerkey, Brian and Konolige, Kurt},
file = {:home/tkorthals/Documents/Mendeley Desktop/Marder-eppstein et al. - 1998 - The Office Marathon.pdf:pdf},
mendeley-groups = {Robotics/Navigation},
title = {{The Office Marathon:}},
year = {1998}
}
@article{Defined2010,
author = {Defined, Sustainability},
doi = {10.1016/B978-0-7020-2797-0.00001-1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Defined - 2010 - Chapter 1.pdf:pdf},
isbn = {1111001111},
mendeley-groups = {Robotics/SLAM},
pages = {1--16},
pmid = {20314319},
title = {{Chapter 1}},
year = {2010}
}
@article{Wachsmuth2015d,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise2.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
title = {{RoboCupSeminar{\_}exercise2}},
year = {2015}
}
@article{Durrant-Whyte2006,
abstract = {This tutorial provides an introduction to Simultaneous Localisation and Mapping (SLAM) and the extensive research on SLAM that has been undertaken over the past decade. SLAM is the process by which a mobile robot can build a map of an environment and at the same time use this map to compute it's own location. The past decade has seen rapid and exciting progress in solving the SLAM problem together with many compelling implementations of SLAM methods. Part I of this tutorial (this paper), describes the probabilistic form of the SLAM problem, essential solution methods and significant implementations. Part II of this tutorial will be concerned with recent advances in computational methods and new formulations of the SLAM problem for large scale and complex environments.},
author = {Durrant-Whyte, Hugh and Bailey, Tim},
doi = {10.1109/MRA.2006.1638022},
file = {:home/tkorthals/Documents/Mendeley Desktop/Durrant-Whyte, Bailey - 2006 - Simultaneous localization and mapping (SLAM) part I The Essential Algorithms.pdf:pdf},
isbn = {1070-9932},
issn = {10709932},
journal = {Robotics {\&} Automation Magazine},
keywords = {SLAM problem,mobile robots,simultaneous localization and mapping problem},
mendeley-groups = {Robotics/SLAM},
pages = {99--110},
pmid = {8460702},
title = {{Simultaneous localization and mapping (SLAM): part I The Essential Algorithms}},
volume = {2},
year = {2006}
}
@article{Carroll1992,
abstract = {Passive Infrared sensors used for intrusion detection, especially those used on mobile robots, are vulnerable to false alarms caused by clutter objects such as radiators, steam pipes, windows, etc., as well as deliberately caused false alarms caused by decoy objects. To overcome these sources of false alarms, we are now combining thermal and ultrasonic signals, the results being a more robust system for detecting personnel. Our paper will discuss the fusion strategies used for combining sensor information. Our first strategy uses a statistical classifier using features such as the sonar cross-section, the received thermal energy, and ultrasonic range. Our second strategy uses s 3-layered neural classifier trained by backpropagation. The probability of correct classification and the false alarm rate for both strategies will be presented in the paper.},
author = {Carroll, Matthew S and Meng, M and Cadwallender, William K},
file = {:home/tkorthals/Documents/Mendeley Desktop/Carroll, Meng, Cadwallender - 1992 - Fusion of ultrasonic and infrared signatures for personnel detection by a mobile robot.pdf:pdf},
isbn = {0819407488},
issn = {0277786X},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
mendeley-groups = {Robotics/Multirobotics,Robotics/Sensing},
number = {1991},
pages = {619--629},
title = {{Fusion of ultrasonic and infrared signatures for personnel detection by a mobile robot}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0026762261{\&}partnerID=40{\&}md5=d90f76ab0e5d4ef1f995df5599648395},
volume = {1611},
year = {1992}
}
@article{Wachsmuth2015e,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise8.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
title = {{RoboCupSeminar{\_}exercise8}},
year = {2015}
}
@article{Wachsmuth2015,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise3.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
title = {{RoboCupSeminar{\_}exercise3}},
year = {2015}
}
@article{Kim2007,
author = {Kim, P. and Park, C. and Jong, Y. and Yun, J. and Mo, E. and Kim, C. and Jie, M. and Hwang, S. and Lee, K.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kim et al. - 2007 - Obstacle avoidance of a mobile robot using vision system and ultrasonic sensor.pdf:pdf},
journal = {Advanced Intelligent Computing Theories and Applications. With Aspects of Theoretical and Methodological Issues},
keywords = {limit-cycle,mobile robot,nearness diagram,obstacle,vision system},
mendeley-groups = {Robotics/Collision Avoidance},
pages = {545--553},
title = {{Obstacle avoidance of a mobile robot using vision system and ultrasonic sensor}},
url = {http://www.springerlink.com/index/W18684K784526131.pdf},
year = {2007}
}
@article{Gavrilut2008,
author = {Gavrilut, I. and Tiponut, V. and Gacsadi, a. and Tepelea, L.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gavrilut et al. - 2008 - Obstacles avoidance method for an autonomous mobile robot using two IR sensors.pdf:pdf},
issn = {18446035},
journal = {Journal of Electrical and Electronics Engineering},
keywords = {Behaviors,IR sensors,Mobile robot,Obstacles avoidance},
mendeley-groups = {Robotics/Collision Avoidance},
number = {1},
pages = {194--197},
title = {{Obstacles avoidance method for an autonomous mobile robot using two IR sensors}},
volume = {1},
year = {2008}
}
@article{Benet2002,
abstract = {The amplitude response of infrared (IR) sensors based on reflected amplitude of the surrounding objects is non-linear and depends on the reflectance characteristics of the object surface. As a result, the main use of IR sensors in robotics is for obstacle avoidance. Nevertheless, their inherently fast response is very attractive for enhancing the real-time operation of a mobile robot in, for instance, map building tasks. Thus, it seems that the development of new low-cost IR sensors able to accurately measure distances with reduced response times is worth researching. In this paper, a new IR sensor based on the light intensity back-scattered from objects and able to measure distances of up to 1m is described. Also, the sensor model is described and the expected errors in distance estimates are analysed and modelled. Finally, the experimental results obtained are discussed. {\textcopyright} 2002 Published by Elsevier Science B.V.},
author = {Benet, G. and Blanes, F. and Sim{\'{o}}, J.E. and P{\'{e}}rez, P.},
doi = {10.1016/S0921-8890(02)00271-3},
file = {:home/tkorthals/Documents/Mendeley Desktop/Benet et al. - 2002 - Using infrared sensors for distance measurement in mobile robots.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {distance measurement,error estimation,infrared sensors,integration,sensor models,ultrasonic and infrared data},
mendeley-groups = {Robotics/Maps},
number = {4},
pages = {255--266},
title = {{Using infrared sensors for distance measurement in mobile robots}},
volume = {40},
year = {2002}
}
@article{Bailey2006,
abstract = {This paper discusses the recursive Bayesian formulation of the simultaneous localization and mapping (SLAM) problem in which probability distributions or estimates of absolute or relative locations of landmarks and vehicle pose are obtained. The paper focuses on three key areas: computational complexity; data association; and environment representation},
archivePrefix = {arXiv},
arxivId = {there is not},
author = {Bailey, Tim and Durrant-Whyte, Hugh},
doi = {10.1109/MRA.2006.1678144},
eprint = {there is not},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bailey, Durrant-Whyte - 2006 - Simultaneous localization and mapping (SLAM) Part II.pdf:pdf},
isbn = {1070-9932 VO - 13},
issn = {10709932},
journal = {IEEE Robotics and Automation Magazine},
mendeley-groups = {Robotics/SLAM},
number = {3},
pages = {108--117},
pmid = {1638022},
title = {{Simultaneous localization and mapping (SLAM): Part II}},
volume = {13},
year = {2006}
}
@article{Thrun2003,
abstract = {This article describes a new algorithm for acquiring occupancy grid maps with mobile robots. Existing occupancy grid mapping algorithms decompose the high-dimensional mapping problem into a collection of one-dimensional problems, where the occupancy of each grid cell is estimated independently. This induces conflicts that may lead to inconsistent maps, even for noise-free sensors. This article shows how to solve the mapping problem in the original, high-dimensional space, thereby maintaining all dependencies between neighboring cells. As a result, maps generated by our approach are often more accurate than those generated using traditional techniques. Our approach relies on a statistical formulation of the mapping problem using forward models. It employs the expectation maximization algorithm for searching maps that maximize the likelihood of the sensor measurements.},
author = {Thrun, Sebastian},
doi = {10.1023/A:1025584807625},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thrun - 2003 - Learning occupancy grid maps with forward sensor models.pdf:pdf},
isbn = {0-7803-6612-3},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Bayesian techniques,Mapping,Mobile robotics,Probabilistic inference,Robot navigation,SLAM},
mendeley-groups = {Robotics/Maps},
number = {2},
pages = {111--127},
pmid = {563334},
title = {{Learning occupancy grid maps with forward sensor models}},
volume = {15},
year = {2003}
}
@article{Wachsmuth2013,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2013 - RoboCupSeminar Intro.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
title = {{RoboCupSeminar Intro}},
url = {http://www.cit-ec.de/},
year = {2013}
}
@article{Wachsmuth2015a,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise7.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
pages = {7},
title = {{RoboCupSeminar{\_}exercise7}},
year = {2015}
}
@article{Wachsmuth2015c,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exercise5.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
pages = {5--7},
title = {{RoboCupSeminar{\_}exercise5}},
year = {2015}
}
@article{Wachsmuth2015g,
author = {Wachsmuth, Sven and Ziegler, Leon},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wachsmuth, Ziegler - 2015 - RoboCupSeminar{\_}exerciseBonus.pdf:pdf},
mendeley-groups = {Robotics/RoboCup/ToBI},
pages = {1--2},
title = {{RoboCupSeminar{\_}exerciseBonus}},
year = {2015}
}
@article{Minguez2000,
abstract = {This paper presents a new real-time collision avoidance approach for mobile robots. The nearness diagram method (ND) performs a high level information extraction and interpretation of the environment. Subsequently, this information is used to generate the motion commands. The proposed approach is well-suited to deal with unknown, unstructured and dynamic environments, where problems of other approaches are avoided. Some experimental results are shown using an holonomic mobile base to demonstrate the usefulness of the method},
author = {Minguez, J. and Montano, L.},
doi = {10.1109/IROS.2000.895280},
file = {:home/tkorthals/Documents/Mendeley Desktop/Minguez, Montano - 2000 - Nearness diagram navigation (ND) a new real time collision avoidance approach.pdf:pdf},
isbn = {0-7803-6348-5},
journal = {Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113)},
mendeley-groups = {Robotics/Collision Avoidance},
title = {{Nearness diagram navigation (ND): a new real time collision avoidance approach}},
volume = {3},
year = {2000}
}
@article{Gutierrez-Osuna1998,
abstract = {This paper presents a probabilistic model of ultrasonic range
sensors using backpropagation neural networks trained on experimental
data. The sensor model provides the probability of detecting mapped
obstacles in the environment, given their position and orientation
relative to the transducer. The detection probability can be used to
compute the location of an autonomous vehicle from those obstacles that
are more likely to be detected. The neural network model is more
accurate than other existing approaches, since it captures the typical
multilobal detection pattern of ultrasonic transducers. Since the
network size is kept small, implementation of the model on a mobile
robot can be efficient for real-time navigation. An example that
demonstrates how the credence could be incorporated into the extended
Kalman filter (EKF) and the numerical values of the final neural network
weights are provided in the appendices},
author = {Gutierrez-Osuna, Ricardo and Janet, Jason a. and Luo, Ren C.},
doi = {10.1109/41.704895},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gutierrez-Osuna, Janet, Luo - 1998 - Modeling of ultrasonic range sensors for localization of autonomous mobile robots.pdf:pdf},
issn = {02780046},
journal = {IEEE Transactions on Industrial Electronics},
mendeley-groups = {Robotics/Maps},
number = {4},
pages = {654--662},
title = {{Modeling of ultrasonic range sensors for localization of autonomous mobile robots}},
volume = {45},
year = {1998}
}
@article{Wienke2013,
author = {Wienke, Johannes and Moringen, Jan and Wrede, Sebastian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wienke, Moringen, Wrede - 2013 - RSB – Robotics Service Bus.pdf:pdf},
mendeley-groups = {Robotics/RSB},
title = {{RSB – Robotics Service Bus}},
year = {2013}
}
@book{DBLP:conf/dars/2010,
doi = {10.1007/978-3-642-32723-0},
editor = {Martinoli, Alcherio and Mondada, Francesco and Correll, Nikolaus and Mermoud, Gr{\'{e}}gory and Egerstedt, Magnus and Hsieh, M Ani and Parker, Lynne E and St{\o}y, Kasper},
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2013 - Distributed Autonomous Robotic Systems - The 10th International Symposium.pdf:pdf},
isbn = {978-3-642-32722-3},
mendeley-groups = {Robotics,Robotics/Multirobotics},
publisher = {Springer},
series = {Springer Tracts in Advanced Robotics},
title = {{Distributed Autonomous Robotic Systems - The 10th International Symposium}},
url = {http://dx.doi.org/10.1007/978-3-642-32723-0},
volume = {83},
year = {2013}
}
@misc{Jakob2012,
author = {Jakob, Robert},
file = {:home/tkorthals/Documents/Mendeley Desktop/Jakob - 2012 - cmake - An introduction.pdf:pdf},
mendeley-groups = {Software},
title = {{cmake - An introduction}},
year = {2012}
}
@article{SebastianThrunJens-steffenGutmannDieterFoxWolframBurgard1998,
abstract = {The problem of concurrent mapping and localization has received considerable attention in the mobile robotics community. Existing approaches can largely be grouped into two distinct paradigms: topological and metric. This paper proposes a method that integrates both. It poses the mapping problem as a statistical maximum likelihood problem, and devises an efficient algorithm for search in likelihood space. It presents an novel mapping algorithm that integrates two phases: a topological and a metric mapping phase. The topological mapping phase solves a global position alignment problem between potentially indistinguishable, significant places. The subsequent metric mapping phase produces a fine-grained metric map of the environment in floating-point resolution. The approach is demonstrated empirically to scale up to large, cyclic, and highly ambiguous environments.},
author = {{Sebastian Thrun, Jens-steffen Gutmann, Dieter Fox, Wolfram Burgard}, Benjamin J. Kuipers},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sebastian Thrun, Jens-steffen Gutmann, Dieter Fox, Wolfram Burgard - 1998 - Integrating topological and metric maps for mobile robot nav.pdf:pdf},
journal = {15th AAAI National Conference on Artificial Intelligence},
mendeley-groups = {Robotics/Maps},
number = {1},
pages = {989--995},
title = {{Integrating topological and metric maps for mobile robot navigation: A statistical approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.187.7438},
year = {1998}
}
@phdthesis{GallartdelBurgo2013,
author = {{Gallart del Burgo}, Xavier},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gallart del Burgo - 2013 - Semantic Mapping in ROS.pdf:pdf},
mendeley-groups = {Robotics/Maps},
title = {{Semantic Mapping in ROS}},
year = {2013}
}
@article{Cowley2011,
abstract = {Multi-robot map building has advanced to the point where high quality occupancy grid data may be collected by multiple robots collaborating with only intermittent connectivity. However, the tasking of these agents to most efficiently build the map is a problem that has seen less attention. Unfamiliar, highly cluttered environments can confound exploration strategies that rely solely on occupancy grid frontier identification or even semantic classification methods keyed on geometric features. To reason about partial maps of novel, highly cluttered locations, hypotheses about significant structure in the disposition of free space may be used to guide exploration task assignment. A parsing of map data into places with semantic significance to the exploration task provides a foundation from which one may infer an efficient exploration strategy.},
author = {Cowley, Anthony and Taylor, Camillo J. and Southall, Ben},
doi = {10.1109/ICRA.2011.5980403},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cowley, Taylor, Southall - 2011 - Rapid multi-robot exploration with topometric maps.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Robotics/Multirobotics,Robotics/Maps},
pages = {1044--1049},
title = {{Rapid multi-robot exploration with topometric maps}},
year = {2011}
}
@article{Meyer-Delius2010,
abstract = {Accurate and robust localization is essential for the successful navigation of autonomous mobile robots. The majority of existing localization approaches, however, is based on the assumption that the environment is static which does not hold for most practical application domains. In this paper, we present a localization framework that can robustly track a robot's pose even in non-static environments. Our approach keeps track of the observations caused by unexpected objects in the environment using temporary local maps. It relies both on these temporary local maps and on a reference map of the environment for estimating the pose of the robot. Experimental results demonstrate that by exploiting the observations caused by unexpected objects our approach outperforms standard localization methods for static environments.},
author = {Meyer-Delius, Daniel and Hess, J{\"{u}}rgen and Grisetti, Giorgio and Burgard, Wolfram},
doi = {10.1109/IROS.2010.5648920},
file = {:home/tkorthals/Documents/Mendeley Desktop/Meyer-Delius et al. - 2010 - Temporary maps for robust localization in semi-static environments.pdf:pdf},
isbn = {9781424466757},
issn = {2153-0858},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
mendeley-groups = {Robotics/Maps},
pages = {5750--5755},
title = {{Temporary maps for robust localization in semi-static environments}},
year = {2010}
}
@article{Blasch,
author = {Blasch, Erik and Broussard, Randy},
file = {:home/tkorthals/Documents/Mendeley Desktop/Blasch, Broussard - Unknown - Physiologically Motivated Computational Visual Target Recognition Beta Selection.pdf:pdf},
keywords = {classification,pcnn,roc,sensor fusion,target recognition},
mendeley-groups = {Robotics/Sensing},
title = {{Physiologically Motivated Computational Visual Target Recognition Beta Selection}}
}
@article{Dirafzoon2013,
author = {Dirafzoon, Alireza and Lobaton, Edgar},
doi = {10.1109/IROS.2013.6697160},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dirafzoon, Lobaton - 2013 - Topological mapping of unknown environments using an unlocalized robotic swarm.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
mendeley-groups = {Robotics/Multirobotics,Robotics/Maps},
pages = {5545--5551},
title = {{Topological mapping of unknown environments using an unlocalized robotic swarm}},
year = {2013}
}
@article{Zhu2010,
author = {Zhu, Mengxia and Ding, Song and Wu, Qishi and Brooks, R. R. and Rao, N. S. V. and Iyengar, S. S.},
doi = {10.1145/1689239.1689248},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhu et al. - 2010 - Fusion of threshold rules for target detection in wireless sensor networks.pdf:pdf},
issn = {15504859},
journal = {ACM Transactions on Sensor Networks},
mendeley-groups = {Robotics/Multirobotics},
number = {2},
pages = {1--7},
title = {{Fusion of threshold rules for target detection in wireless sensor networks}},
volume = {6},
year = {2010}
}
@misc{Kawata2006,
author = {Kawata},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kawata - 2006 - Communication Protocol Specification For SCIP2.0 Standard.pdf:pdf},
mendeley-groups = {Robotics/Hardware/Hokuyo URG-04LX},
pages = {1--25},
title = {{Communication Protocol Specification For SCIP2.0 Standard}},
year = {2006}
}
@misc{Stanton2002,
author = {Stanton, Jr},
file = {:home/tkorthals/Documents/Mendeley Desktop/Stanton - 2002 - A Users Guide to Spread Version 0.11.pdf:pdf},
mendeley-groups = {Software},
title = {{A Users Guide to Spread Version 0.11}},
urldate = {2016-11-01},
year = {2002}
}
@article{ChristianDelis2000,
author = {{Christian Delis}},
file = {:home/tkorthals/Documents/Mendeley Desktop/Christian Delis - 2000 - Entwicklung einer Kooperationsplattform f{\"{u}}r den Hokuyo URG-04LX Laserscanner.pdf:pdf},
journal = {Bachelor-Arbeit},
mendeley-groups = {Robotics/Hardware/Hokuyo URG-04LX},
number = {6},
pages = {376--377},
title = {{Entwicklung einer Kooperationsplattform f{\"{u}}r den Hokuyo URG-04LX Laserscanner}},
volume = {23},
year = {2000}
}
@article{Badino2011,
abstract = {One of the fundamental requirements of an autonomous vehicle is the ability to determine its location on a map. Frequently, solutions to this localization problem rely on GPS information or use expensive three dimensional (3D) sensors. In this paper, we describe a method for long-term vehicle localization based on visual features alone. Our approach utilizes a combination of topological and metric mapping, which we call topometric localization, to encode the coarse topology of the route as well as detailed metric information required for accurate localization. A topometric map is created by driving the route once and recording a database of visual features. The vehicle then localizes by matching features to this database at runtime. Since individual feature matches are unreliable, we employ a discrete Bayes filter to estimate the most likely vehicle position using evidence from a sequence of images along the route. We illustrate the approach using an 8.8 km route through an urban and suburban environment. The method achieves an average localization error of 2.7 m over this route, with isolated worst case errors on the order of 10 m.},
author = {Badino, H. and Huber, D. and Kanade, T.},
doi = {10.1109/IVS.2011.5940504},
file = {:home/tkorthals/Documents/Mendeley Desktop/Badino, Huber, Kanade - 2011 - Visual topometric localization.pdf:pdf},
isbn = {9781457708909},
issn = {1931-0587},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
mendeley-groups = {Robotics/Localization},
pages = {794--799},
title = {{Visual topometric localization}},
year = {2011}
}
@article{Barther2015,
author = {Barther, Marvin and Sharma, Suchit and Korthals, Timo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Barther, Sharma, Korthals - 2015 - Automatic Odometry Calibration of the AMiRo Differential Kinematic.pdf:pdf},
mendeley-groups = {Robotics/Odometry,Robotics/AMiRo},
title = {{Automatic Odometry Calibration of the AMiRo Differential Kinematic}},
year = {2015}
}
@article{Monks2014,
author = {M{\"{o}}nks, Uwe and Lohweg, Volker},
file = {:home/tkorthals/Documents/Mendeley Desktop/M{\"{o}}nks, Lohweg - 2014 - FAST EVIDENCE-BASED INFORMATION FUSION.pdf:pdf},
isbn = {9781479936960},
journal = {4th International Workshop on Cognitive Information Processing},
mendeley-groups = {Robotics/Sensing},
title = {{FAST EVIDENCE-BASED INFORMATION FUSION}},
year = {2014}
}
@article{Community2010,
abstract = {OpenCV (Open Source Computer Vision) is a library of programming functions for real time computer vision. OpenCV is released under a BSD license, it is free for both academic and commercial use. The library has {\textgreater}500 optimized algorithms (see figure below). It is used around the world, has {\textgreater}2M downloads and {\textgreater}40K people in the user group. Uses range from interactive art, to mine inspection, stitching maps on the web on through advanced robotics.},
author = {Community, OpenCV},
file = {:home/tkorthals/Documents/Mendeley Desktop/Community - 2010 - The OpenCV Reference Manual.pdf:pdf},
journal = {October},
mendeley-groups = {Software},
pages = {1--1104},
title = {{The OpenCV Reference Manual}},
url = {http://opencv.willowgarage.com/documentation/cpp/index.html},
year = {2010}
}
@article{Wang2014,
author = {Wang, Zhangyang and Moll, Mark and Huang, Ps},
doi = {10.1109/CVPRW.2014.116},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wang, Moll, Huang - 2014 - Active Planning, Sensing and Recognition Using a Resource-Constrained Discriminant POMDP.pdf:pdf},
isbn = {9781479943081},
journal = {Kavrakilab.Org},
mendeley-groups = {Robotics/Navigation,Robotics/Active Sensing},
title = {{Active Planning, Sensing and Recognition Using a Resource-Constrained Discriminant POMDP}},
url = {http://www.kavrakilab.org/sites/default/files/2014 active planning, sensing and recognition using.pdf},
year = {2014}
}
@article{Fredslund2002,
abstract = {We study the problem of achieving global behavior in a group of distributed robots using only local sensing and minimal communication, in the context of formations. The goal is to have N mobile robots establish and maintain some predetermined geometric shape. We report results from extensive simulation experiments, and 40+ experiments with four physical robots, showing the viability of our approach. The key idea is that each robot keeps a single friend at a desired angle {\&}theta;, using some appropriate sensor. By panning the sensor by {\&}theta; degrees, the goal for all formations becomes simply to center the friend in the sensor's field of view. We also present a general analytical measure for evaluating formations and apply it to the position data from both simulation and physical robot experiments. We used two lasers to track the physical robots to obtain ground truth validation data.},
author = {Fredslund, Jakob and Matari{\'{c}}, Maja J.},
doi = {10.1109/TRA.2002.803458},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fredslund, Matari{\'{c}} - 2002 - A general algorithm for robot formations using local sensing And minimal communication.pdf:pdf},
isbn = {0-7803-7203-4},
issn = {1042296X},
journal = {IEEE Transactions on Robotics and Automation},
keywords = {Local sensing,Minimal communication,Multiple robot coordination,Robot formations},
mendeley-groups = {Robotics/Multirobotics},
number = {5},
pages = {837--846},
title = {{A general algorithm for robot formations using local sensing: And minimal communication}},
volume = {18},
year = {2002}
}
@article{Roy1998,
author = {Roy, Nicholas and Burgard, Wolfram and Fox, Dieter and Thrun, Sebastian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Roy et al. - 1998 - Coastal Navigation – Mobile Robot Navigation with Uncertainty in Dynamic Environments.pdf:pdf},
mendeley-groups = {Robotics/Navigation},
title = {{Coastal Navigation – Mobile Robot Navigation with Uncertainty in Dynamic Environments}},
year = {1998}
}
@article{Andrade-cetto2001,
author = {Andrade-cetto, Juan and Sanfeliu, Alberto},
file = {:home/tkorthals/Documents/Mendeley Desktop/Andrade-cetto, Sanfeliu - 2001 - Topological map learning for a mobile robot in indoor environments.pdf:pdf},
journal = {Proceedings of the 9th Spanish Symposium on Pattern Recognition and Image Analysis},
keywords = {map learning,mobile robot navigation,topological maps},
mendeley-groups = {Robotics/Maps},
number = {May},
pages = {221--226},
title = {{Topological map learning for a mobile robot in indoor environments}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=53KbtOmpPz4C{\&}oi=fnd{\&}pg=PA221{\&}dq=Topological+map+learning+for+a+mobile+robot+in+indoor+environments+?{\&}ots=7z26z7RgAT{\&}sig=gXE2Ip7G3IyfvshU1ShCb3UXp{\_}0},
volume = {1},
year = {2001}
}
@article{30720,
abstract = {An approach to robot perception and world modeling that uses a probabilistic tesselated representation of spatial information called the occupancy grid is reviewed. The occupancy grid is a multidimensional random field that maintains stochastic estimates of the occupancy state of the cells in a spatial lattice. To construct a sensor-derived map of the robot's world, the cell state estimates are obtained by interpreting the incoming range readings using probabilistic sensor models. Bayesian estimation procedures allow the incremental updating of the occupancy grid, using readings taken from several sensors over multiple points of view. The use of occupancy grids from mapping and for navigation is examined. Operations on occupancy grids and extensions of the occupancy grid framework are briefly considered.{\textless}{\textgreater}},
author = {Elfes, Alberto},
doi = {10.1109/2.30720},
file = {:home/tkorthals/Documents/Mendeley Desktop/Elfes - 1989 - Using occupancy grids for mobile robot perception and navigation.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {Bayes methods,Bayesian estimation,Decision making,Mobile robots,Navigation,Path planning,Remotely operated vehicles,Robot kinematics,Robot sensing systems,Robustness,Service robots,State estimation,cell state estimates,computerised navigation,mobile robot perception,mobile robots,multidimensional random field,multiple points of view,navigation,occupancy grid,path planning,probabilistic sensor models,probabilistic tesselated representation,range readings,sensor integration,sensor-derived map,single scanline stereo,sonar based mapping,spatial information,spatial lattice,world modeling},
mendeley-groups = {Robotics/Maps},
number = {6},
pages = {46--57},
title = {{Using occupancy grids for mobile robot perception and navigation}},
volume = {22},
year = {1989}
}
@phdthesis{Dingwert2014,
author = {Dingwert, Matthias},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dingwert - 2014 - Dynamische Merkmalsextraktion von Erntegutcharakteristika aus Daten eines Laserscanners.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Abschlussarbeiten},
title = {{Dynamische Merkmalsextraktion von Erntegutcharakteristika aus Daten eines Laserscanners}},
year = {2014}
}
@techreport{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2013 - Programmers Manual LASE2000D-22x Series.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Hardware},
title = {{Programmers Manual LASE2000D-22x Series}},
volume = {0},
year = {2013}
}
@techreport{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - 2014 - LASE 2000D-22x Series.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Hardware},
title = {{LASE 2000D-22x Series}},
year = {2014}
}
@book{SicilianoBrunoandKhatib2007,
editor = {{Siciliano, Bruno and Khatib}, Oussama},
isbn = {9783540239574},
mendeley-groups = {Robotics},
pages = {1611},
publisher = {Springer-Verlag New York, Inc.},
title = {{Springer Handbook of Robotics}},
year = {2007}
}
@article{Kuderer2014,
author = {Kuderer, Markus and Sprunk, Christoph and Kretzschmar, Henrik and Burgard, Wolfram},
doi = {10.1109/ICRA.2014.6907813},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kuderer et al. - 2014 - Online Generation of Homotopically Distinct Navigation Paths.pdf:pdf},
isbn = {9781479936847},
journal = {Proc. of the IEEE International Conference on Robotics and Automation (ICRA)},
keywords = {Autonomous Navigation,Motion and Path Planning,Reactive and Sensor-Based Planning},
mendeley-groups = {Robotics/Navigation},
pages = {6462--6467},
title = {{Online Generation of Homotopically Distinct Navigation Paths}},
url = {http://192.168.1.143:8181/newtemplate/bibtexbrowser.php?key=kuderer14iros{\&}bib=sprunkc.bib},
year = {2014}
}
@inproceedings{BrunoSteux2010,
abstract = {This paper presents a Laser-SLAM algorithm which has been programmed in less than 200 lines of Clanguage code. Our idea was to develop and implement a very simple SLAM algorithm that could be easily integrated into our particle-filter based localization subsystem. For our experiments, we have been using a homebrew robotic platform called MinesRover. It's a six wheels robot fully equipped with sensors, including a Hokuyo URG04 laser scanner. A typical example of our experiments is presented, showing the good performance of the algorithm. Furthermore, the full source code of the map update and map matching functions are provided in this paper. This work shows the possibility to perform complex tasks using simple and easily programmable algorithms.},
author = {{Bruno Steux}, Oussama El Hamzaoui},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bruno Steux - 2010 - CoreSLAM a SLAM Algorithm in less than 200 lines of C code.pdf:pdf},
keywords = {SLAM,laser scanner,localization,mapping,mobile robot,particle filter,tinyslam},
mendeley-groups = {Robotics,Robotics/SLAM},
mendeley-tags = {tinyslam},
title = {{CoreSLAM : a SLAM Algorithm in less than 200 lines of C code}},
url = {file:///home/tkorthals/Downloads/0912f5134a7837f5b8000000.pdf},
year = {2010}
}
@article{Poettering2015a,
author = {Poettering, Lennart and Sievers, Kay and Leemhuis, Thorsten and Systemd, Anschmei{\ss}er Das Init-system},
file = {:home/tkorthals/Documents/Mendeley Desktop/Poettering et al. - 2015 - Das Init-System Systemd , Teil 2.pdf:pdf},
mendeley-groups = {Software},
pages = {15--17},
title = {{Das Init-System Systemd , Teil 2}},
year = {2015}
}
@article{Poettering2015,
author = {Poettering, Lennart and Sievers, Kay and Leemhuis, Thorsten and Systemd, Schaltzentrale Das Init-system},
file = {:home/tkorthals/Documents/Mendeley Desktop/Poettering et al. - 2015 - Das Init-System Systemd , Teil 1.pdf:pdf},
mendeley-groups = {Software},
pages = {1--3},
title = {{Das Init-System Systemd , Teil 1}},
year = {2015}
}
@book{N.Matloff2008,
author = {{N. Matloff}, P. J. Salzman},
file = {:home/tkorthals/Documents/Mendeley Desktop/N. Matloff - 2008 - The art of Debugging.pdf:pdf},
isbn = {9781593271749},
mendeley-groups = {Software},
title = {{The art of Debugging}},
year = {2008}
}
@article{K.LeeC.Jung2011,
abstract = {Odometry using wheel encoders provides fundamental pose estimates for wheeled mobile robots. Systematic errors of odometry can be reduced by the calibration of kinematic parameters. The UMBmark method is one of the widely used calibration schemes for two wheel differential mobile robot. In this paper, an accurate calibration scheme of kinematic parameters is proposed by extending the conventional UMBmark. The contributions of this paper can be summarized as two issues. The first contribution is to present new calibration equations that remarkably reduce the systematic error of odometry. The new equations were derived to overcome the limitation of the conventional schemes. The second contribution is to propose the design guideline of the test track for calibration experiments. The calibration performance can be significantly improved by appropriate design of the test track. The numerical simulations and experimental results show that the odometry accuracy can be improved by the proposed calibration schemes.},
author = {{K. Lee, C. Jung}, W. Chung},
doi = {10.1007/s12206-011-0334-y},
file = {:home/tkorthals/Documents/Mendeley Desktop/K. Lee, C. Jung - 2011 - Accurate calibration of kinematic parameters for two wheel differential mobile robots.pdf:pdf},
journal = {Jornal of Mechanical and Technology},
keywords = {Calibration,Localization,Mobile robots,Odometry,Systematic errors},
mendeley-groups = {Robotics/Odometry},
number = {8},
pages = {1603--161},
title = {{Accurate calibration of kinematic parameters for two wheel differential mobile robots}},
volume = {25},
year = {2011}
}
@article{Borenstein1995,
abstract = {This paper describes a practical method for reducing odometry
errors caused by kinematic imperfections of a mobile robot. These
errors, here referred to as {\&}ldquo;systematic{\&}rdquo; errors, stay almost
constant over a prolonged period of time. Performing an occasional
calibration as described here will increase the robot's odometric
accuracy and reduce operation cost because an accurate mobile robot
requires fewer absolute positioning updates. Many manufacturers or
end-users calibrate their robots-usually in a time-consuming and
non-systematic trial and error approach. By contrast the authors' method
is systematic, provides near-optimal results, and can be performed
easily and without complicated equipment. Experimental results are
presented that show a consistent improvement of at least one order of
magnitude in odometric accuracy (with respect to systematic errors) for
a mobile robot calibrated with the procedure described in this paper
},
author = {Borenstein, J. and Feng, Liqiang Feng Liqiang},
doi = {10.1109/IROS.1995.525942},
file = {:home/tkorthals/Documents/Mendeley Desktop/Borenstein, Feng - 1995 - Correction of systematic odometry errors in mobile robots.pdf:pdf},
isbn = {0-8186-7108-4},
issn = {0277786X},
journal = {Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots},
mendeley-groups = {Robotics/Odometry},
pages = {569--574},
title = {{Correction of systematic odometry errors in mobile robots}},
volume = {3},
year = {1995}
}
@article{Borenstein1996,
author = {Borenstein, Johann and Feng, Liqiang},
file = {:home/tkorthals/Documents/Mendeley Desktop/Borenstein, Feng - 1996 - Measurement and Correction of Systematic Odometry Errors in Mobile R . obots.pdf:pdf},
journal = {IEEE Transactions on Robotics},
mendeley-groups = {Robotics/Odometry},
number = {5},
title = {{Measurement and Correction of Systematic Odometry Errors in Mobile R . obots}},
volume = {12},
year = {1996}
}
@article{Jung2011,
author = {Jung, Changbae and Chung, Woojin},
doi = {10.1007/s12206-011-0334-y},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jung, Chung - 2011 - Calibration of kinematic parameters for two wheel differential mobile robots by using experimental heading errors.pdf:pdf},
issn = {17298806},
journal = {International Journal of Advanced Robotic Systems},
keywords = {Calibration,Mobile robots,Odometry,Pose estimation,Systematic errors},
mendeley-groups = {Robotics/Odometry},
pages = {134--142},
title = {{Calibration of kinematic parameters for two wheel differential mobile robots by using experimental heading errors}},
volume = {8},
year = {2011}
}
@misc{Kleppe2013,
author = {Kleppe, Adam Leon and Skavhaug, Amund},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kleppe, Skavhaug - 2013 - Obstacle detection and mapping in low-cost, low-power multi-robot systems using an Inverted Particle Filter.pdf:pdf},
keywords = {computational power,low-cost,low-energy,mapping,obstacle detection,particle filter,power consumption},
mendeley-groups = {Robotics/AMiRo},
mendeley-tags = {computational power,low-cost,low-energy,mapping,obstacle detection,particle filter,power consumption},
title = {{Obstacle detection and mapping in low-cost, low-power multi-robot systems using an Inverted Particle Filter}},
url = {https://hal.archives-ouvertes.fr/hal-00849817/document},
urldate = {2015-01-14},
year = {2013}
}
@book{Thrun2005,
abstract = {Probablistic robotics is a growing area in the subject, concerned with perception and control in the face of uncertainty and giving robots a level of robustness in real-world situations. This book introduces techniques and algorithms in the field.},
address = {Cambridge, Mass.},
annote = {(2) ist die korrekte Varainte},
author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thrun, Burgard, Fox - 2005 - Probabilistic Robotics.pdf:pdf;:home/tkorthals/Documents/Mendeley Desktop/Thrun, Burgard, Fox - 2005 - Probabilistic Robotics(2).pdf:pdf},
isbn = {9780262201629},
keywords = {SLAM,localisation,mapping,robot},
mendeley-groups = {Robotics},
publisher = {MIT Press},
title = {{Probabilistic Robotics}},
year = {2005}
}
@article{Brooks1986,
abstract = {We describe a new architecture for controlling mobile robots. Layers of control system are built to let the robot operate at increasing levels of competence. Layers are made up of asynchronous modules which communicate over low bandwidth channels. Each module is an instance of a fairly simple computational machine. Higher level layers can subsume the roles of lower levels by suppressing their outputs. However, lower levels continue to function as higher levels are added. The result is a robust and flexible robot control system. The system is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings. In this paper we demonstrate the system controlling a detailed simulation of the robot.},
author = {Brooks, R},
file = {:home/tkorthals/Documents/Mendeley Desktop/Brooks - 1986 - A robust layered control system for a mobile robot(2).pdf:pdf},
journal = {Robotics and Automation, IEEE Journal of},
mendeley-groups = {Robotics/Control},
title = {{A robust layered control system for a mobile robot}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1087032},
year = {1986}
}
@article{Cumming2013,
author = {Cumming, G.},
doi = {10.1177/0956797613504966},
file = {:home/tkorthals/Documents/Mendeley Desktop/Cumming - 2013 - The New Statistics Why and How.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
mendeley-groups = {Machine Learning},
month = {nov},
number = {November},
title = {{The New Statistics: Why and How}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797613504966},
year = {2013}
}
@book{Kernbach2013,
abstract = {This book is devoted to mechatronic, chemical, bacteriological, biological, and hybrid systems, utilizing cooperative, networked, swarm, self-organizing, evolutionary and bio-inspired design principles and targeting underwater, ground, air, and space applications. It addresses issues such as open-ended evolution, self-replication, self-development, reliability, scalability, energy foraging, adaptivity, and artificial sociality. The book has been prepared by 52 authors from world-leading research groups in 14 countries. This book covers not only current but also future key technologies and is aimed at anyone who is interested in learning more about collective robotics and how it might affect our society.},
author = {Kernbach, S.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kernbach - 2013 - Handbook of collective robotics fundamentals and challenges.pdf:pdf},
isbn = {9789814316422},
mendeley-groups = {Robotics,Robotics/Multirobotics},
pages = {962},
publisher = {Pan Stanford},
title = {{Handbook of collective robotics: fundamentals and challenges}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=J6mAK8oJio8C{\&}oi=fnd{\&}pg=PP1{\&}dq=Handbook+of+Collective+Robotics:+Fundamentals+and+Challenges{\&}ots=8iVExLGnF3{\&}sig=rZlptopuf5dqGmysYACLOpTZ2Vo},
year = {2013}
}
@misc{Li2010,
author = {Li, Hanyi},
file = {:home/tkorthals/Documents/Mendeley Desktop/Li - 2010 - twb{\_}manual{\_}bielefeld.docx:docx},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
title = {twb{\_}manual{\_}bielefeld},
year = {2010}
}
@article{Tanoto2013a,
author = {Tanoto, Andry and Technology, Circuit},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanoto, Technology - 2013 - Teleworkbench II.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
number = {January},
title = {{Teleworkbench II}},
year = {2013}
}
@misc{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - Unknown - TWB{\_}GUI{\_}doc.docx:docx},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
title = {{TWB{\_}GUI{\_}doc}}
}
@article{Vaughan,
author = {Vaughan, Richard T},
file = {:home/tkorthals/Documents/Mendeley Desktop/Vaughan - Unknown - The Player Stage Gazebo project Open Source tools for robotics research Robotics research is hard.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
title = {{The Player / Stage / Gazebo project : Open Source tools for robotics research Robotics research is hard}}
}
@article{Gerkey2004,
author = {Gerkey, Brian P and Vaughan, Richard T},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gerkey, Vaughan - 2004 - Version 1.5 User Manual Brian P. Gerkey Richard T. Vaughan Andrew Howard.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
title = {{Version 1.5 User Manual Brian P. Gerkey Richard T. Vaughan Andrew Howard}},
year = {2004}
}
@article{Guideline2010,
author = {Guideline, The and Codes, Writing and Project, Teleworkbench},
file = {:home/tkorthals/Documents/Mendeley Desktop/Guideline, Codes, Project - 2010 - The Guideline for Writing Codes in the Teleworkbench Project Source Code Style.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
title = {{The Guideline for Writing Codes in the Teleworkbench Project Source Code Style}},
year = {2010}
}
@article{Client,
author = {Client, Install N X},
file = {:home/tkorthals/Documents/Mendeley Desktop/Client - Unknown - BeBot.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
number = {c},
pages = {2--4},
title = {{BeBot}}
}
@article{Arkin1989,
annote = {- Here: "role of the pilot" means that the robot is teleoperated and has an additional "motor schema manager"
- primitive behaviour -{\textgreater} combination -{\textgreater} complex behaviour
- There is no "world model", but the schemas react to their world via sensing
- schmea = motor schema + embedded perceptual schema which senses the world
- Schema instatiation = generic schema + parameters
- Motor-schemas are spawned during runtime to achive dirfferent behaviours
- There is no layering at all; it is more of a soup-
like collection of networked autonomous agents whose configuration changes dynamically as the needs and perceptions of the vehicle change.
As each motor SI has an embedded perceptual schema, if the perceptual process can pro- vide a measure of belief in its perception, the motor schema can reflect that belief by acting lethargically in the presence of questionable evidence or by discount- ing it entirely.},
author = {Arkin, R. C.},
doi = {10.1177/027836498900800406},
file = {:home/tkorthals/Documents/Mendeley Desktop/Arkin - 1989 - Motor Schema -- Based Mobile Robot Navigation.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
mendeley-groups = {Robotics/TeleWerkBank/DOCs},
month = {aug},
number = {4},
pages = {92--112},
title = {{Motor Schema -- Based Mobile Robot Navigation}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/027836498900800406},
volume = {8},
year = {1989}
}
@article{Tanoto2012,
author = {Tanoto, Andry and Li, Hanyi and Ruckert, Ulrich and Sitte, Joaquin},
doi = {10.1109/ISIC.2012.6398261},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanoto et al. - 2012 - Scalable and flexible vision-based multi-robot tracking system.pdf:pdf},
isbn = {978-1-4673-4600-9},
journal = {2012 IEEE International Symposium on Intelligent Control},
mendeley-groups = {Robotics/TeleWerkBank},
month = {oct},
pages = {19--24},
publisher = {Ieee},
title = {{Scalable and flexible vision-based multi-robot tracking system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6398261},
year = {2012}
}
@inproceedings{Tanoto2013,
author = {Tanoto, Andry and Gomez, JV and Mavridis, Nikolaos and Li, Hanyi},
booktitle = {IEEE European Conference on Mobile Robots},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanoto et al. - 2013 - Teletesting Remote Path Planning Experimentation and Benchmarking in the TeleWorkbench.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank},
title = {{Teletesting: Remote Path Planning Experimentation and Benchmarking in the TeleWorkbench}},
url = {http://pub.uni-bielefeld.de/publication/2634404},
year = {2013}
}
@article{Tanoto2011,
author = {Tanoto, A and Werner, F and R{\"{u}}ckert, U and Li, H},
file = {:home/tkorthals/Documents/Mendeley Desktop/Tanoto et al. - 2011 - Teleworkbench validating robot programs from simulation to prototyping with minirobots.pdf:pdf},
mendeley-groups = {Robotics/TeleWerkBank},
title = {{Teleworkbench: validating robot programs from simulation to prototyping with minirobots}},
url = {http://pub.uni-bielefeld.de/publication/2286604},
year = {2011}
}
@article{Mau2005,
author = {Mau, Sandra},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mau - 2005 - What is the Kalman Filter and How can it be used for Data Fusion.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion/Kalman,4{\_}Students},
number = {December},
title = {{What is the Kalman Filter and How can it be used for Data Fusion?}},
year = {2005}
}
@article{Bazzani,
author = {Bazzani, Loris and Bloisi, Domenico and Murino, Vittorio},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bazzani, Bloisi, Murino - Unknown - A Comparison of Multi Hypothesis Kalman Filter and Particle Filter for Multi-target Tracking.pdf:pdf},
mendeley-groups = {Vision/Tracking},
pages = {8},
title = {{A Comparison of Multi Hypothesis Kalman Filter and Particle Filter for Multi-target Tracking}}
}
@article{MIC-1988-4-2,
author = {Solberg, Ingar},
doi = {10.4173/mic.1988.4.2},
file = {:home/tkorthals/Documents/Mendeley Desktop/Solberg - 1988 - Data and Program Structure for a Modular Extended Kalman Filter.pdf:pdf},
journal = {Modeling, Identification and Control},
mendeley-groups = {CLAAS itsowl/Sensorfusion/Kalman},
number = {4},
pages = {179--189},
publisher = {Norwegian Society of Automatic Control},
title = {{Data and Program Structure for a Modular Extended Kalman Filter}},
volume = {9},
year = {1988}
}
@article{Freund1995,
author = {Freund, Yoav and Schapire, RE},
doi = {10.1006/jcss.1997.1504},
issn = {00220000},
journal = {Computational learning theory},
mendeley-groups = {Machine Learning},
month = {aug},
number = {1},
pages = {119--139},
title = {{A desicion-theoretic generalization of on-line learning and an application to boosting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002200009791504X http://link.springer.com/chapter/10.1007/3-540-59119-2{\_}166},
volume = {55},
year = {1995}
}
@book{Bishop2007,
abstract = {This leading textbook provides a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. This is the first machine learning textbook to include a comprehensive coverage of recent developments such as probabilistic graphical models and deterministic inference methods, and to emphasize a modern Bayesian perspective. It is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. This hard cover book has 738 pages in full colour, and there are 431 graded exercises (with solutions available below). Extensive support is provided for course instructors.},
author = {Bishop, Christopher M.},
booktitle = {Journal of Electronic Imaging},
doi = {10.1117/1.2819119},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bishop - 2007 - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {978-0387310732},
issn = {1017-9909},
keywords = {Machine Learning},
mendeley-groups = {Machine Learning},
mendeley-tags = {Machine Learning},
number = {4},
pages = {049901},
title = {{Pattern Recognition and Machine Learning}},
url = {http://electronicimaging.spiedigitallibrary.org/article.aspx?doi=10.1117/1.2819119},
volume = {16},
year = {2007}
}
@article{Klein1999,
author = {Klein, L. A.},
journal = {Bellingham, Wash},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {2},
title = {{Sensor and data fusion concepts and applications}},
volume = {35},
year = {1999}
}
@article{Hall1997,
abstract = {Multisensor data fusion is an emerging technology applied to Department
of Defense (DoD) areas such as automated target recognition, battlefield
surveillance, and guidance and control of autonomous vehicles, and
to non-DoD applications such as monitoring of complex machinery,
medical diagnosis, and smart buildings. Techniques for multisensor
data fusion are drawn from a wide range of areas including artificial
intelligence, pattern recognition, statistical estimation and other
areas. This paper provides a tutorial on data fusion, introducing
data fusion applications, process models, and identification of applicable
techniques. Comments are made on the state-of-the-art in data fusion},
author = {Hall, D L and Llinas, J},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Defense,Department DoD,aerospace artificial automated autonomous based b,complex computerised computing,control,data diagnosis,emerging estimation fusion,guidance,identification,instrumentation,intelligence,knowledge machinery,medical methods,military models,multisensor nonlinearities,of pattern process recognition,sensor smart statistical surveillance,systems,target technology,vehicles},
mendeley-groups = {CLAAS itsowl,CLAAS itsowl/Sensorfusion},
number = {1},
pages = {6--23},
title = {{An introduction to multisensor data fusion}},
volume = {85},
year = {1997}
}
@book{BrooksRichardR.andIyengar1997,
author = {{Brooks, Richard R. and Iyengar}, S. S.},
isbn = {0-13-901653-8},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
pages = {488},
publisher = {Prentice-Hall, Inc.},
title = {{Multi-sensor Fusion: Fundamentals and Applications with Software}},
year = {1997}
}
@article{Wienke2012a,
author = {Wienke, Johannes and Klotz, David and Wrede, Sebastian},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wienke, Klotz, Wrede - 2012 - A Framework for the Acquisition of Multimodal Human-Robot Interaction Data Sets with a Whole-System Perspe.pdf:pdf},
journal = {{\ldots} on Multimodal {\ldots}},
mendeley-groups = {Robotics/RSB},
title = {{A Framework for the Acquisition of Multimodal Human-Robot Interaction Data Sets with a Whole-System Perspective}},
url = {https://aiweb.techfak.uni-bielefeld.de/files/lrec2012mmc.pdf},
year = {2012}
}
@article{Lin2012,
author = {Lin, Yi and Hyypp{\"{a}}, Juha},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lin, Hyypp{\"{a}} - 2012 - Multiecho-Recording Mobile Laser Scanning for Enhancing Individual Tree Crown Reconstruction.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
number = {11},
pages = {4323--4332},
title = {{Multiecho-Recording Mobile Laser Scanning for Enhancing Individual Tree Crown Reconstruction}},
volume = {50},
year = {2012}
}
@article{Wang2012,
author = {Wang, Peng and Jiang, Wenhao and Li, Xin and Kang, Shaochen and Xin, Jinglei},
doi = {10.4304/jcp.7.5.1176-1183},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2012 - Research for Multi-sensor Information Fusion Algorithm of Search and Rescue Robot Based on Embedded Control Network.pdf:pdf},
issn = {1796-203X},
journal = {Journal of Computers},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
month = {may},
number = {5},
pages = {1176--1183},
title = {{Research for Multi-sensor Information Fusion Algorithm of Search and Rescue Robot Based on Embedded Control Network}},
url = {http://ojs.academypublisher.com/index.php/jcp/article/view/5307},
volume = {7},
year = {2012}
}
@article{Sun2011,
author = {Sun, Kai},
doi = {10.1109/ISCID.2011.186},
file = {:home/tkorthals/Documents/Mendeley Desktop/Sun - 2011 - An Enhanced Adaboost Algorithm for Information Recommendation System.pdf:pdf},
isbn = {978-1-4577-1085-8},
journal = {2011 Fourth International Symposium on Computational Intelligence and Design},
keywords = {data mining,enhanced adaboost,information recommendation,social network},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
month = {oct},
pages = {334--337},
publisher = {Ieee},
title = {{An Enhanced Adaboost Algorithm for Information Recommendation System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6079805},
year = {2011}
}
@article{Lamborn2006,
author = {Lamborn, Peter and Williams, Pamela J.},
doi = {10.1117/12.665850},
editor = {Dasarathy, Belur V.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lamborn, Williams - 2006 - Data fusion on a distributed heterogeneous sensor network.pdf:pdf},
keywords = {data fusion,data fusion on a,distributed heterogeneous sensor network,machines,neural networks,self organizing maps,sensor network support vector},
mendeley-groups = {CLAAS itsowl/Sensorfusion},
month = {apr},
pages = {8},
title = {{Data fusion on a distributed heterogeneous sensor network}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1286983},
volume = {6242},
year = {2006}
}
@misc{Dammann2004,
author = {Dammann, Ludwig and Thiemann, Holger and Uhlending, Hubert},
mendeley-groups = {CLAAS itsowl/Patente},
title = {{Vorrichtung und Verfahren zur Lagesteuerung eines Erntegutaufnahmeger{\"{a}}tes landwirtschaftlicher Erntemaschinen}},
year = {2004}
}
@misc{Diekhans2011,
author = {Diekhans, Norbert and Brunnert, Andreas and {Meyer zu Helligen}, Lars Peter and Beermann, Ingo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Diekhans et al. - 2011 - Routenplanungssystem zur Erzeugung von Referenzfahrspuren f{\"{u}}r landwirtschaftliche Arbeitsmaschinen.pdf:pdf},
mendeley-groups = {CLAAS itsowl/Patente},
number = {19},
pages = {1--12},
title = {{Routenplanungssystem zur Erzeugung von Referenzfahrspuren f{\"{u}}r landwirtschaftliche Arbeitsmaschinen}},
volume = {1},
year = {2011}
}
@article{Wienke2011,
author = {Wienke, Johannes and Wrede, Sebastian},
doi = {10.1109/SII.2011.6147617},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wienke, Wrede - 2011 - A middleware for collaborative research in experimental robotics.pdf:pdf},
isbn = {978-1-4577-1524-2},
journal = {2011 IEEE/SICE International Symposium on System Integration (SII)},
mendeley-groups = {Robotics/RSB},
month = {dec},
pages = {1183--1190},
publisher = {Ieee},
title = {{A middleware for collaborative research in experimental robotics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6147617},
year = {2011}
}
@article{Wienke2012,
author = {Wienke, Johannes and Nordmann, Arne and Wrede, Sebastian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wienke, Nordmann, Wrede - 2012 - A meta-model and toolchain for improved interoperability of robotic frameworks.pdf:pdf},
journal = {{\ldots} Programming for Autonomous Robots},
mendeley-groups = {Robotics/RSB},
title = {{A meta-model and toolchain for improved interoperability of robotic frameworks}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-34327-8{\_}30},
year = {2012}
}
@article{Wu2006,
author = {Wu, Bin and Lai, Tze Leung and Chen, Yuguo},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wu, Lai, Chen - Unknown - Sequential Planning for Robotic Navigation and Exploration under Uncertainty.pdf:pdf},
mendeley-groups = {Robotics/Exploration},
title = {{Sequential Planning for Robotic Navigation and Exploration under Uncertainty}}
}
@article{Berthold2009,
author = {Berthold, Oswald},
file = {:home/tkorthals/Documents/Mendeley Desktop/Berthold - 2009 - Collaborative sensors and distributed information acquisition Preamble Applications Collaborative sensing.pdf:pdf},
mendeley-groups = {Robotics/Sensing},
number = {August},
title = {{Collaborative sensors and distributed information acquisition Preamble Applications Collaborative sensing}},
year = {2009}
}
@article{Herbrechtsmeier2009,
author = {Herbrechtsmeier, Stefan and Witkowski, Ulf and R{\"{u}}ckert, U},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herbrechtsmeier, Witkowski, R{\"{u}}ckert - 2009 - Bebot A modular mobile miniature robot platform supporting hardware reconfiguration and mu.pdf:pdf},
journal = {Progress in Robotics},
mendeley-groups = {Robotics,Robotics/TeleWerkBank/DOCs},
pages = {346--356},
title = {{Bebot: A modular mobile miniature robot platform supporting hardware reconfiguration and multi-standard communication}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-03986-7{\_}40},
year = {2009}
}
@book{Shuzhi2009,
address = {Berlin, Heidelberg},
author = {Shuzhi, Jong-hwan Kim and Ge, Sam and Vadakkepat, Prahlad},
doi = {10.1007/978-3-642-03986-7},
editor = {Kim, Jong-Hwan and Ge, Shuzhi Sam and Vadakkepat, Prahlad and Jesse, Norbert and {Al Manum}, Abdullah and {Puthusserypady K}, Sadasivan and R{\"{u}}ckert, Ulrich and Sitte, Joaquin and Witkowski, Ulf and Nakatsu, Ryohei and Braunl, Thomas and Baltes, Jacky and Anderson, John and Wong, Ching-Chang and Verner, Igor and Ahlgren, David},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shuzhi, Ge, Vadakkepat - 2009 - Progress in Robotics.pdf:pdf},
isbn = {978-3-642-03985-0},
mendeley-groups = {Robotics},
publisher = {Springer Berlin Heidelberg},
series = {Communications in Computer and Information Science},
title = {{Progress in Robotics}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-03986-7},
volume = {44},
year = {2009}
}
@phdthesis{Kempkes2012,
author = {Kempkes, Barbara},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kempkes - 2012 - Local strategies for robot formation problems.pdf:pdf},
mendeley-groups = {Robotics},
number = {March},
school = {University of Paderborn},
title = {{Local strategies for robot formation problems}},
year = {2012}
}
@article{Couceiro2011,
author = {Couceiro, Micael S and Rocha, Rui P},
file = {:home/tkorthals/Documents/Mendeley Desktop/Couceiro, Rocha - 2011 - A Novel Multi-Robot Exploration Approach based on Particle Swarm Optimization Algorithms.pdf:pdf},
keywords = {search robotics,survival-of-the-fittest,swarm robots},
mendeley-groups = {Robotics,Robotics/Exploration},
pages = {327--332},
title = {{A Novel Multi-Robot Exploration Approach based on Particle Swarm Optimization Algorithms}},
year = {2011}
}
@article{Shia,
author = {Shia, Angie},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shia - Unknown - Survey of Swarm Robotics Techniques – A Tutorial.pdf:pdf},
mendeley-groups = {Robotics},
title = {{Survey of Swarm Robotics Techniques – A Tutorial}}
}
@article{Liu2013,
author = {Liu, Yugang and Nejat, Goldie},
doi = {10.1007/s10846-013-9822-x},
file = {:home/tkorthals/Documents/Mendeley Desktop/Liu, Nejat - 2013 - Robotic Urban Search and Rescue A Survey from the Control Perspective.pdf:pdf},
issn = {0921-0296},
journal = {Journal of Intelligent {\&} Robotic Systems},
keywords = {multi-robot control,rescue robots,robot autonomy,semi-autonomous control,slam,urban search and rescue},
mendeley-groups = {Robotics},
month = {mar},
number = {2},
pages = {147--165},
title = {{Robotic Urban Search and Rescue: A Survey from the Control Perspective}},
url = {http://link.springer.com/10.1007/s10846-013-9822-x},
volume = {72},
year = {2013}
}
@article{Shue2013,
author = {Shue, Sam and Conrad, James M.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shue, Conrad - 2013 - A Survey of Robotic Applications in Wireless Sensor Networks.pdf:pdf},
isbn = {9781479900534},
keywords = {ii,in wsns to solve,localization,mobile sensor networks,n etworks,problems and,r obotics i n,robotics,robotics can be used,w ireless s ensor,wireless sensor networks},
mendeley-groups = {Robotics},
pages = {1--5},
title = {{A Survey of Robotic Applications in Wireless Sensor Networks}},
year = {2013}
}
@article{Bayindir2007,
author = {Bayindir, L and Sahin, E},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bayindir, Sahin - 2007 - A review of studies in swarm robotics.pdf:pdf},
journal = {Turkish Journal of Electrical {\ldots}},
mendeley-groups = {Robotics},
number = {2},
pages = {115--147},
title = {{A review of studies in swarm robotics}},
url = {http://zenithlib.googlecode.com/svn-hist/trunk/papers/si/2007-A{\_}Review{\_}of{\_}Studies{\_}in{\_}Swarm{\_}Robotics.pdf},
volume = {15},
year = {2007}
}
@book{ShiZhiguoandTuJunandZhangQiaoandLiuLeiandWei2012,
author = {{Shi, Zhiguo and Tu, Jun and Zhang, Qiao and Liu, Lei and Wei}, Junming},
doi = {10.1007/978-3-642-30976-2_68},
editor = {{Tan, Ying and Shi, Yuhui and Ji}, Zhen},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shi, Zhiguo and Tu, Jun and Zhang, Qiao and Liu, Lei and Wei - 2012 - Advances in Swarm Intelligence.pdf:pdf},
isbn = {978-3-642-30975-5},
keywords = {Distributed Control,Swarm Intelligence,Swarm Robotics},
mendeley-groups = {Robotics},
mendeley-tags = {Distributed Control,Swarm Intelligence,Swarm Robotics},
publisher = {Springer Berlin Heidelberg},
title = {{Advances in Swarm Intelligence}},
url = {http://dx.doi.org/10.1007/978-3-642-30976-2{\_}68},
year = {2012}
}
@article{Shi2012,
author = {Shi, Zhiguo and Tu, Jun and Zhang, Qiao and Liu, Lei and Wei, Junming},
file = {:home/tkorthals/Documents/Mendeley Desktop/Shi et al. - 2012 - A Survey of Swarm Robotics System.1007{\_}978-3:1007{\_}978-3},
keywords = {distributed control,swarm intelligence,swarm robotics},
mendeley-groups = {Robotics,Robotics/Multirobotics},
pages = {564--572},
title = {{A Survey of Swarm Robotics System}},
year = {2012}
}
@article{Guo2007,
author = {Guo, Yi and Parker, LE and Madhavan, Raj},
file = {:home/tkorthals/Documents/Mendeley Desktop/Guo, Parker, Madhavan - 2007 - Collaborative robots for infrastructure security applications.pdf:pdf},
journal = {{\ldots} Robots: The Evolutionary Approach},
mendeley-groups = {Robotics,Robotics/Exploration},
pages = {185--200},
title = {{Collaborative robots for infrastructure security applications}},
url = {http://link.springer.com/content/pdf/10.1007/978-3-540-49720-2{\_}9.pdf},
volume = {200},
year = {2007}
}
@article{Gausemeier2011,
author = {Gausemeier, Jurgen and Schierbaum, Thomas and Dumitrescu, Roman and Herbrechtsmeier, Stefan and Jungmann, Alexander},
doi = {10.1109/INDIN.2011.6034921},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gausemeier et al. - 2011 - Miniature robot BeBot Mechatronic test platform for self-x properties.pdf:pdf},
isbn = {978-1-4577-0435-2},
journal = {2011 9th IEEE International Conference on Industrial Informatics},
mendeley-groups = {Robotics},
month = {jul},
pages = {451--456},
publisher = {Ieee},
title = {{Miniature robot BeBot: Mechatronic test platform for self-x properties}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6034921},
year = {2011}
}
@article{Mondada2009,
author = {Mondada, Francesco and Bonani, Michael and Raemy, Xavier},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mondada, Bonani, Raemy - 2009 - The e-puck, a robot designed for education in engineering.pdf:pdf},
journal = {{\ldots} on autonomous robot {\ldots}},
mendeley-groups = {Robotics},
title = {{The e-puck, a robot designed for education in engineering}},
url = {http://81.180.214.82/aE/Elab/Lab4/epuck-robotica2009.pdf},
year = {2009}
}
@article{Pugh2009,
author = {Pugh, J. and Raemy, X. and Favre, C. and Falconi, R. and Martinoli, A.},
doi = {10.1109/TMECH.2008.2011810},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pugh et al. - 2009 - A fast onboard relative positioning module for multirobot systems.pdf:pdf},
issn = {1083-4435},
journal = {IEEE/ASME Transactions on Mechatronics},
mendeley-groups = {Robotics},
month = {apr},
number = {2},
pages = {151--162},
title = {{A fast onboard relative positioning module for multirobot systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4787109},
volume = {14},
year = {2009}
}
@article{Mondada2004,
author = {Mondada, Francesco and Pettinaro, Giovanni C. and Guignard, Andre and Kwee, Ivo W. and Floreano, Dario and Deneubourg, Jean-Louis and Nolfi, Stefano and Gambardella, Luca Maria and Dorigo, Marco},
doi = {10.1023/B:AURO.0000033972.50769.1c},
file = {:home/tkorthals/Documents/Mendeley Desktop/Mondada et al. - 2004 - Swarm-Bot A New Distributed Robotic Concept.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
mendeley-groups = {Robotics,Robotics/Robots},
month = {sep},
number = {2/3},
pages = {193--221},
title = {{Swarm-Bot: A New Distributed Robotic Concept}},
url = {http://link.springer.com/10.1023/B:AURO.0000033972.50769.1c},
volume = {17},
year = {2004}
}
@article{Lang2011,
author = {Lang, Dagmar and Marcel, H and Prinzen, Martin and Bauschke, Simone and Gemmel, Alexander and Giesen, Julian and Hahn, Ruwen and Harak, Laura and Reimche, Paul and Sonnen, Guido and Steimker, Matthias Von and Thierfelder, Susanne and Paulus, Dietrich},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lang et al. - 2011 - RoboCupRescue 2011 - Robot League Team resko @ UniKoblenz ( Germany ).pdf:pdf},
mendeley-groups = {Robotics},
pages = {1--11},
title = {{RoboCupRescue 2011 - Robot League Team resko @ UniKoblenz ( Germany )}},
year = {2011}
}
@article{Couceiro2013,
address = {New York, New York, USA},
author = {Couceiro, Micael S. and Portugal, David and Rocha, Rui P.},
doi = {10.1145/2480362.2480377},
file = {:home/tkorthals/Documents/Mendeley Desktop/Couceiro, Portugal, Rocha - 2013 - A collective robotic architecture in search and rescue scenarios.pdf:pdf},
isbn = {9781450316569},
journal = {Proceedings of the 28th Annual ACM Symposium on Applied Computing - SAC '13},
keywords = {Collective Architectures, Distributed Multi-Robot,collective architecture,distributed multi-robot systems,group},
mendeley-groups = {Robotics},
pages = {64},
publisher = {ACM Press},
title = {{A collective robotic architecture in search and rescue scenarios}},
url = {http://dl.acm.org/citation.cfm?doid=2480362.2480377},
year = {2013}
}
@article{Miller1993,
author = {Miller, DP},
file = {:home/tkorthals/Documents/Mendeley Desktop/Miller - 1993 - A twelve-step program to more efficient robotics.pdf:pdf},
journal = {AI Magazine},
mendeley-groups = {Robotics,4{\_}Students},
number = {1},
pages = {60--63},
title = {{A twelve-step program to more efficient robotics}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1033},
volume = {14},
year = {1993}
}
@article{Izturta2011,
author = {Izturta, EJ},
file = {:home/tkorthals/Documents/Mendeley Desktop/Izturta - 2011 - Advances towards behaviour-based indoor robotic exploration.pdf:pdf},
isbn = {9788498606119},
mendeley-groups = {Robotics,Robotics/Control},
title = {{Advances towards behaviour-based indoor robotic exploration}},
url = {http://dialnet.unirioja.es/servlet/tesis?codigo=23814},
year = {2011}
}
@article{Koester,
author = {Koester, Markus},
file = {:home/tkorthals/Documents/Mendeley Desktop/Koester - Unknown - BeBot - Software Installation Guide.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{BeBot - Software Installation Guide}},
url = {http://geekswithblogs.net/WindowsEmbeddedCookbook/archive/2010/08/31/installing-windows-ce-6.0-tools-on-a-windows7-64bit-pc.aspx}
}
@book{StefanHerbrechtsmeierUlrichRuckert2012,
address = {Berlin, Heidelberg},
author = {Herbrechtsmeier, Stefan and R{\"{u}}ckert, Ulrich and Sitte, Joaquin},
doi = {10.1007/978-3-642-27482-4},
editor = {R{\"{u}}ckert, Ulrich and Joaquin, Sitte and Felix, Werner},
file = {:home/tkorthals/Documents/Mendeley Desktop/Herbrechtsmeier, R{\"{u}}ckert, Sitte - 2012 - AMiRo - Autonomous Mini Robot for research and education.pdf:pdf},
isbn = {978-3-642-27481-7},
keywords = {AMIRo},
mendeley-groups = {Robotics/AMiRo},
mendeley-tags = {AMIRo},
publisher = {Springer Berlin Heidelberg},
title = {{AMiRo - Autonomous Mini Robot for research and education}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-27482-4},
year = {2012}
}
@misc{Zorn2012,
author = {Zorn},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zorn - 2012 - Sportsproject.ppt:ppt},
keywords = {Sportsproject},
mendeley-groups = {Vision/Tracking},
mendeley-tags = {Sportsproject},
title = {{Sportsproject}},
year = {2012}
}
@misc{Spektrum2013,
author = {Spektrum},
file = {:home/tkorthals/Documents/Mendeley Desktop/Spektrum - 2013 - Rat navigation.pdf:pdf},
keywords = {navigation,rat},
mendeley-groups = {Vision/Tracking},
mendeley-tags = {navigation,rat},
title = {{Rat navigation}},
year = {2013}
}
@unpublished{ZdenekKalalKrystianMikolajczyk2010,
author = {{Zdenek Kalal, Krystian Mikolajczyk}, and Jiri Matas},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zdenek Kalal, Krystian Mikolajczyk - 2010 - Tracking-Learning-Detection.pdf:pdf},
keywords = {BibTeX,bookmarks,collaborative tagging,folksonomy,knowledge management,publication management},
mendeley-groups = {Vision/Tracking},
title = {{Tracking-Learning-Detection.}},
url = {http://www.bibsonomy.org/bibtex/2a0a873792cae12e8a8249d0f98e1f272/dblp},
year = {2010}
}
@article{Zhao2002,
author = {Zhao, Ying and Karypis, George},
file = {:home/tkorthals/Documents/Mendeley Desktop/Zhao, Karypis - 2001 - Criterion functions for document clustering Experiments and analysis.pdf:pdf},
journal = {Machine Learning},
mendeley-groups = {Master},
pages = {1--30},
title = {{Criterion functions for document clustering: Experiments and analysis}},
url = {https://wwws.cs.umn.edu/tech{\_}reports{\_}upload/tr2001/01-040.pdf},
year = {2001}
}
@book{Acknowledgments,
author = {{University of Chicago Press}},
booktitle = {Chicago Press},
file = {:home/tkorthals/Documents/Mendeley Desktop/University of Chicago Press - 2010 - The Chicago Manual of Style.pdf:pdf},
isbn = {978-0-226-10420-1},
mendeley-groups = {Style,Master},
title = {{The Chicago Manual of Style}},
url = {http://medcontent.metapress.com/index/A65RM03P4874243N.pdf http://www.muict.polppolservice.com/Year4{\_}1/SeniorProject2010/docs/LaTeX/Sample{\_}BibTeX{\_}database{\_}file.pdf},
year = {2010}
}
@article{Chow,
author = {Chow, Yen-lu and Schwartz, Richard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chow, Schwartz - Unknown - The N-Best Algorithm An Efficient Procedure for Finding Top N Sentence Hypotheses.pdf:pdf},
mendeley-groups = {Master},
pages = {199--202},
title = {{The N-Best Algorithm : An Efficient Procedure for Finding Top N Sentence Hypotheses}}
}
@article{Schaeffer2007,
author = {Schaeffer, Satu Elisa},
doi = {10.1016/j.cosrev.2007.05.001},
file = {:home/tkorthals/Documents/Mendeley Desktop/Schaeffer - 2007 - Graph clustering.pdf:pdf},
issn = {15740137},
journal = {Computer Science Review},
keywords = {- see front matter,001,05,10,1016,1574-0137,2007,all rights reserved,ap 126-f,c 2007 elsevier ltd,ciudad universitaria,com,cosrev,doi,e-mail address,elisa,garza,gmail,j,mexico,nl 66450,pisis,san nicol{\'{a}}s de los,schaeffer},
mendeley-groups = {Master},
month = {aug},
number = {1},
pages = {27--64},
title = {{Graph clustering}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1574013707000020},
volume = {1},
year = {2007}
}
@book{Grimm2007,
author = {Grimm, M and Kroschel, K},
file = {:home/tkorthals/Documents/Mendeley Desktop/Grimm, Kroschel - 2007 - Robust speech recognition and understanding.pdf:pdf},
mendeley-groups = {Master},
title = {{Robust speech recognition and understanding}},
url = {http://gen.lib.rus.ec/get?nametype=orig{\&}md5=BA87587C558EFEF9EBDC8FFF5E824A61},
year = {2007}
}
@article{Rabiner1989,
author = {Rabiner, LR},
file = {:home/tkorthals/Documents/Mendeley Desktop/Rabiner - 1989 - A tutorial on hidden Markov models and selected applications in speech recognition.pdf:pdf},
journal = {Proceedings of the IEEE},
mendeley-groups = {Master},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=18626},
year = {1989}
}
@article{Pedersen2012,
author = {Pedersen, Michael Syskind},
file = {:home/tkorthals/Documents/Mendeley Desktop/Pedersen - 2012 - The Matrix Cookbook.pdf:pdf},
keywords = {acknowledgements,and suggestions,bill baxter,brian templeton,christian,christian rish{\o}j,contributions,derivative of,derivative of inverse matrix,determinant,differentiate a matrix,matrix algebra,matrix identities,matrix relations,thank the following for,we would like to},
mendeley-groups = {Master},
title = {{The Matrix Cookbook}},
year = {2012}
}
@article{Vor2006,
author = {Vor, Theoretische},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vor - 2006 - H{\"{a}}ufigkeiten von Wortl{\"{a}}ngen und Wortl{\"{a}}ngenpaaren Untersuchungen am Beispiel russischer Texte von Viktor Pelevin P.pdf:pdf},
mendeley-groups = {Master},
title = {{H{\"{a}}ufigkeiten von Wortl{\"{a}}ngen und Wortl{\"{a}}ngenpaaren: Untersuchungen am Beispiel russischer Texte von Viktor Pelevin P}},
year = {2006}
}
@article{Park2008,
author = {Park, Alex S and Glass, James R and Member, Senior},
file = {:home/tkorthals/Documents/Mendeley Desktop/Park, Glass, Member - 2008 - Unsupervised Pattern Discovery in Speech.pdf:pdf},
mendeley-groups = {Master},
number = {1},
pages = {186--197},
title = {{Unsupervised Pattern Discovery in Speech}},
volume = {16},
year = {2008}
}
@article{Newman,
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0309508v1},
author = {Newman, M E J},
eprint = {0309508v1},
file = {:home/tkorthals/Documents/Mendeley Desktop/Newman - Unknown - Fast algorithm for detecting community structure in networks.pdf:pdf},
mendeley-groups = {Master},
number = {2},
pages = {1--5},
primaryClass = {arXiv:cond-mat},
title = {{Fast algorithm for detecting community structure in networks}}
}
@article{Thesis1994,
author = {Thesis, Diploma and Purnhagen, Heiko and Hannover, Universitat},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thesis, Purnhagen, Hannover - 1994 - N-Best Search Methods Applied to Speech Recognition N-Best Search Methods Applied to Speech Recogni.pdf:pdf},
mendeley-groups = {Master},
number = {May},
title = {{N-Best Search Methods Applied to Speech Recognition N-Best Search Methods Applied to Speech Recognition}},
year = {1994}
}
@article{Macropol,
author = {Macropol, By Kathy},
file = {:home/tkorthals/Documents/Mendeley Desktop/Macropol - Unknown - Clustering on Graphs The Markov Cluster Algorithm ( MCL ) By Kathy Macropol.pdf:pdf},
mendeley-groups = {Master},
number = {Mcl},
title = {{Clustering on Graphs : The Markov Cluster Algorithm ( MCL ) By Kathy Macropol}}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - Unknown - Clustering characteristics of the MCL algorithm.pdf:pdf},
mendeley-groups = {Master},
number = {i},
pages = {111--124},
title = {{Clustering characteristics of the MCL algorithm}}
}
@article{Steyer2009,
author = {Steyer, Michael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Steyer - 2009 - Markov Clustering ( MCL ).pdf:pdf},
mendeley-groups = {Master},
number = {Mcl},
title = {{Markov Clustering ( MCL )}},
year = {2009}
}
@article{Luxburg2007,
author = {Luxburg, Ulrike},
doi = {10.1007/s11222-007-9033-z},
file = {:home/tkorthals/Documents/Mendeley Desktop/Luxburg - 2007 - A tutorial on spectral clustering.pdf:pdf},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {graph laplacian,spectral clustering},
mendeley-groups = {Master},
month = {aug},
number = {4},
pages = {395--416},
title = {{A tutorial on spectral clustering}},
url = {http://link.springer.com/10.1007/s11222-007-9033-z},
volume = {17},
year = {2007}
}
@article{Walck2007,
author = {Walck, Christian and Group, Particle Physics},
file = {:home/tkorthals/Documents/Mendeley Desktop/Walck, Group - 2007 - Hand-book on STATISTICAL for experimentalists.pdf:pdf},
mendeley-groups = {Master},
number = {September},
title = {{Hand-book on STATISTICAL for experimentalists}},
year = {2007}
}
@book{Krishnamoorthy2006,
author = {Krishnamoorthy, K and Crc, Hall and Group, Francis},
file = {:home/tkorthals/Documents/Mendeley Desktop/Krishnamoorthy, Crc, Group - 2006 - Handbook of Statistical Distributions with Applications.pdf:pdf},
isbn = {9781584886358},
mendeley-groups = {Master},
title = {{Handbook of Statistical Distributions with Applications}},
year = {2006}
}
@article{Nilsson1989,
author = {Nilsson, Dennis and E, Bajers Vej and {\O}st, Aalborg},
file = {:home/tkorthals/Documents/Mendeley Desktop/Nilsson, E, {\O}st - 1989 - Sequentially finding the N -Best List in Hidden Markov Models.pdf:pdf},
mendeley-groups = {Master},
number = {2},
title = {{Sequentially finding the N -Best List in Hidden Markov Models}},
year = {1989}
}
@book{Euler,
author = {Euler, Stephen},
file = {:home/tkorthals/Documents/Mendeley Desktop/Euler - Unknown - Grundkurs Spracherkennung.pdf:pdf},
isbn = {3834800031},
mendeley-groups = {Master},
title = {{Grundkurs Spracherkennung}}
}
@article{Gales2007,
author = {Gales, Mark and Young, Steve},
doi = {10.1561/2000000004},
file = {:home/tkorthals/Documents/Mendeley Desktop/Gales, Young - 2007 - The Application of Hidden Markov Models in Speech Recognition.pdf:pdf},
issn = {1932-8346},
journal = {Foundations and Trends{\textregistered} in Signal Processing},
mendeley-groups = {Master},
number = {3},
pages = {195--304},
title = {{The Application of Hidden Markov Models in Speech Recognition}},
url = {http://www.nowpublishers.com/product.aspx?product=SIG{\&}doi=2000000004},
volume = {1},
year = {2007}
}
@article{Nilsson2002,
author = {Nilsson, Mikael},
file = {:home/tkorthals/Documents/Mendeley Desktop/Nilsson - 2002 - Speech Recognition using Hidden Markov Model performance evaluation in noisy environment.pdf:pdf},
mendeley-groups = {Master},
title = {{Speech Recognition using Hidden Markov Model performance evaluation in noisy environment}},
year = {2002}
}
@article{Au2007,
author = {Au, Benjamin},
file = {:home/tkorthals/Documents/Mendeley Desktop/Au - 2007 - Spectral Graph Clustering.pdf:pdf},
mendeley-groups = {Master},
pages = {1--12},
title = {{Spectral Graph Clustering}},
year = {2007}
}
@article{Report,
author = {Report, Fianal Project},
file = {:home/tkorthals/Documents/Mendeley Desktop/Report - Unknown - N-best Hypotheses.pdf:pdf},
mendeley-groups = {Master},
pages = {1--8},
title = {{N-best Hypotheses}}
}
@article{Matrix-algebra2006,
author = {Matrix-algebra, Moderne and Ein, Reelle Matrix and Zeilen, Die and Sei, Transponierte Matrix},
file = {:home/tkorthals/Documents/Mendeley Desktop/Matrix-algebra et al. - 2006 - A Matrix-Algebra.pdf:pdf},
mendeley-groups = {Master},
title = {{A Matrix-Algebra}},
year = {2006}
}
@article{Papageorgiou1990,
author = {Papageorgiou, Constantine P},
file = {:home/tkorthals/Documents/Mendeley Desktop/Papageorgiou - 1990 - I JUMAN.pdf:pdf},
mendeley-groups = {Master},
pages = {283--288},
title = {{I JUMAN}},
year = {1990}
}
@article{Young2006,
author = {Young, Steve and Evermann, G},
file = {:home/tkorthals/Documents/Mendeley Desktop/Young, Evermann - 2002 - The HTK book.pdf:pdf},
journal = {Cambridge {\ldots}},
mendeley-groups = {Master},
number = {July 2000},
title = {{The HTK book}},
url = {http://speech.ee.ntu.edu.tw/courses/DSP2011spring/hw2/HTKBook-3.4.1.pdf},
year = {2002}
}
@techreport{Fadali,
author = {Fadali, M. Sami},
file = {:home/tkorthals/Documents/Mendeley Desktop/Fadali - 2009 - The EM Algorithm.pdf:pdf},
keywords = {EM,Expectation Maximization},
mendeley-groups = {Master},
mendeley-tags = {EM,Expectation Maximization},
title = {{The EM Algorithm}},
year = {2009}
}
@article{Ist,
author = {Ist, Eigenvektoren and Ev, Eigenvektor and Bezeichnungen, Andere and Fall, Im and Vektor, Ein and Hv, Hauptvektor and Eigenraum, Vielfachheit and Eigenwert, Polynom and Eigenvektor, E W and Wegen, E V and Hauptraum, Der and Dimension, Seine},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ist et al. - Unknown - Eigenwerte und Eigenvektoren.pdf:pdf},
mendeley-groups = {Master},
title = {{Eigenwerte und Eigenvektoren}}
}
@article{Wunsch2001,
author = {Wunsch, Holger},
file = {:home/tkorthals/Documents/Mendeley Desktop/Wunsch - 2001 - Der Baum-Welch Algorithmus f u ¨ r Hidden Markov Models , ein Spezialfall Inhaltsverzeichnis.pdf:pdf},
mendeley-groups = {Master},
number = {August},
title = {{Der Baum-Welch Algorithmus f u ¨ r Hidden Markov Models , ein Spezialfall Inhaltsverzeichnis}},
year = {2001}
}
@article{Newman2004,
author = {Newman, M.},
doi = {10.1103/PhysRevE.70.056131},
file = {:home/tkorthals/Documents/Mendeley Desktop/Newman - 2004 - Analysis of weighted networks.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
mendeley-groups = {Master},
month = {nov},
number = {5},
pages = {056131},
title = {{Analysis of weighted networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.70.056131},
volume = {70},
year = {2004}
}
@article{Kepstrumanalyse,
author = {Kepstrumanalyse, Die},
file = {:home/tkorthals/Documents/Mendeley Desktop/Kepstrumanalyse - Unknown - Anwendungsbeispiel.pdf:pdf},
mendeley-groups = {Master},
pages = {1--4},
title = {{Anwendungsbeispiel}}
}
@article{White,
author = {White, Scott and Smyth, Padhraic},
file = {:home/tkorthals/Documents/Mendeley Desktop/White, Smyth - Unknown - A Spectral Clustering Approach To Finding Communities in Graphs.pdf:pdf},
mendeley-groups = {Master},
title = {{A Spectral Clustering Approach To Finding Communities in Graphs}}
}
@book{Duda2012,
author = {Duda, RO and Hart, PE and Stork, DG},
file = {:home/tkorthals/Documents/Mendeley Desktop/Duda, Hart, Stork - 2012 - Pattern classification.pdf:pdf},
mendeley-groups = {Machine Learning,Master},
title = {{Pattern classification}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Br33IRC3PkQC{\&}oi=fnd{\&}pg=PR3{\&}dq=Pattern+Classification{\&}ots=2vEQIz8bDs{\&}sig=s352SjlzQ-LoOKJAWMMRpehIPzY http://books.google.com/books?hl=en{\&}lr={\&}id=Br33IRC3PkQC{\&}oi=fnd{\&}pg=PR3{\&}dq=Pattern+classification{\&}ots=2vESLAf7Gt{\&}sig=-gjLpzxf53zsOIq2dAJotXVsEQo},
year = {2012}
}
@article{Models1998,
author = {Models, Hidden Markov},
file = {:home/tkorthals/Documents/Mendeley Desktop/Models - 1998 - International computer science institute 1947.pdf:pdf},
mendeley-groups = {Master},
title = {{International computer science institute 1947}},
year = {1998}
}
@article{Simulation,
author = {Simulation, Flow},
file = {:home/tkorthals/Documents/Mendeley Desktop/Simulation - Unknown - Graph clustering.pdf:pdf},
mendeley-groups = {Master},
title = {{Graph clustering}}
}
@article{Dongen2000,
author = {Dongen, S Van},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dongen - 2000 - A stochastic uncoupling process for graphs.pdf:pdf},
mendeley-groups = {Master},
title = {{A stochastic uncoupling process for graphs}},
year = {2000}
}
@article{Dongen,
author = {Dongen, Stijn Van},
file = {:home/tkorthals/Documents/Mendeley Desktop/Dongen - Unknown - A New Cluster Algorithm for Graphs.pdf:pdf},
keywords = {2,and phrases,clustering,digital libraries,flow simulation,graph clustering,markov matrix,note,project ins 3,random walk,work carried out under},
mendeley-groups = {Master},
title = {{A New Cluster Algorithm for Graphs}}
}
@article{Introduction1980,
author = {Introduction, I},
file = {:home/tkorthals/Documents/Mendeley Desktop/Introduction - 1980 - Comparison of Parametric Representations for.pdf:pdf},
mendeley-groups = {Master},
number = {4},
title = {{Comparison of Parametric Representations for}},
year = {1980}
}
@article{,
file = {:home/tkorthals/Documents/Mendeley Desktop/Unknown - Unknown - Chinese whispers.pdf:pdf},
mendeley-groups = {Master},
title = {{Chinese whispers}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0305498870130109}
}
@article{Chaudhuri2012,
author = {Chaudhuri, Sourish and Raj, B},
file = {:home/tkorthals/Documents/Mendeley Desktop/Chaudhuri, Raj - 2012 - Unsupervised structure discovery for semantic analysis of audio.pdf:pdf},
journal = {{\ldots} in Neural Information Processing Systems 25},
mendeley-groups = {Master},
pages = {1--9},
title = {{Unsupervised structure discovery for semantic analysis of audio}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}0581.pdf},
year = {2012}
}
@article{Carlin2011,
author = {Carlin, MA and Thomas, Samuel},
file = {:home/tkorthals/Documents/Mendeley Desktop/Carlin, Thomas - 2011 - Rapid Evaluation of Speech Representations for Spoken Term Discovery.pdf:pdf},
journal = {{\ldots}},
keywords = {and spoken term discov-,are unable to construct,error rate are of,ery,here,little use since we,of phone and word,ognizers,requisite transcribed speech to,spotting,the,the usual evaluation metrics,topic identification,train rec-,we are without the},
mendeley-groups = {Master},
title = {{Rapid Evaluation of Speech Representations for Spoken Term Discovery.}},
url = {http://old-site.clsp.jhu.edu/people/samuel/pdfs/spoken{\_}term.pdf},
year = {2011}
}
@article{Biemann2007,
author = {Biemann, Christian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Biemann - 2007 - Unsupervised and knowledge-free natural language processing in the structure discovery paradigm.pdf:pdf},
mendeley-groups = {Master},
title = {{Unsupervised and knowledge-free natural language processing in the structure discovery paradigm.}},
url = {http://www.fmi.uni-leipzig.de/cms/fileadmin/html/fmi/Promotionen/abstract.biemann.pdf},
year = {2007}
}
@article{Biemann2006,
author = {Biemann, Chris},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biemann - 2006 - Chinese whispers an efficient graph clustering algorithm and its application to natural language processing problems.pdf:pdf},
journal = {{\ldots} Based Methods for Natural Language Processing},
mendeley-groups = {Master},
title = {{Chinese whispers: an efficient graph clustering algorithm and its application to natural language processing problems}},
url = {http://dl.acm.org/citation.cfm?id=1654774},
year = {2006}
}
@article{Schmalenstroeer2011,
author = {Schmalenstroeer, Joerg and Bartek, Markus and Haeb-umbach, Reinhold},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmalenstroeer, Bartek, Haeb-umbach - 2011 - Unsupervised learning of acoustic events using dynamic time warping and hierarchical K-mea.pdf:pdf},
keywords = {[Electronic Manuscript]},
mendeley-groups = {Master},
number = {August},
pages = {305--308},
title = {{Unsupervised learning of acoustic events using dynamic time warping and hierarchical K-means ++ clustering}},
year = {2011}
}
@article{Bartek2011,
author = {Bartek, Markus},
file = {:home/tkorthals/Documents/Mendeley Desktop/Bartek - 2011 - Diplomarbeit Un{\"{u}}berwachtes Lernen von akustischen Ereignissen mit Methoden der dynamischen Programmierung.pdf:pdf},
mendeley-groups = {Master},
title = {{Diplomarbeit Un{\"{u}}berwachtes Lernen von akustischen Ereignissen mit Methoden der dynamischen Programmierung}},
year = {2011}
}
@article{Ladefoged1888,
author = {Ladefoged, P and Shoup, J E and Lea, W A and Zue, V W and Seneff, S},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ladefoged et al. - 1888 - ARPABET and the TIMIT alphabet.pdf:pdf},
mendeley-groups = {Master},
pages = {1--2},
title = {{ARPABET and the TIMIT alphabet}},
year = {1888}
}
@article{Azran,
author = {Azran, Arik},
file = {:home/tkorthals/Documents/Mendeley Desktop/Azran - Unknown - A Tutorial on Spectral Clustering Good clustering – we know it when we see it.pdf:pdf},
mendeley-groups = {Master},
title = {{A Tutorial on Spectral Clustering Good clustering – we know it when we see it}}
}
@article{Jansen2013,
author = {Jansen, Aren and Dupoux, Emmanuel and Goldwater, Sharon},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jansen, Dupoux, Goldwater - 2013 - A SUMMARY OF THE 2012 JHU CLSP WORKSHOP ON ZERO RESOURCE SPEECH TECHNOLOGIES AND MODELS OF EARLY LANG.pdf:pdf},
journal = {Proceedings of {\ldots}},
mendeley-groups = {Master},
title = {{A SUMMARY OF THE 2012 JHU CLSP WORKSHOP ON ZERO RESOURCE SPEECH TECHNOLOGIES AND MODELS OF EARLY LANGUAGE ACQUISITION}},
url = {http://www.cs.cmu.edu/{~}fmetze/interACT/Publications{\_}files/publications/ICASSP13a{\_}sub0{\_}4624.pdf},
year = {2013}
}
@article{Trautman2013,
author = {Trautman, Pete},
file = {:home/tkorthals/Documents/Mendeley Desktop/Trautman - 2013 - Robot navigation in dense crowds Statistical models and experimental studies of human robot cooperation.pdf:pdf},
mendeley-groups = {Vision/Tracking},
title = {{Robot navigation in dense crowds: Statistical models and experimental studies of human robot cooperation}},
url = {http://thesis.library.caltech.edu/7724/},
volume = {2013},
year = {2013}
}
@article{ReneGriesslMarioPorrmannUniversityofPaderbornStefanHerbrechtsmeier2011,
author = {{Rene Griessl , Mario Porrmann University of Paderborn Stefan Herbrechtsmeier}, Ulrich Rueckert},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rene Griessl , Mario Porrmann University of Paderborn Stefan Herbrechtsmeier - 2011 - A Low-Power Vision Processing Platform for Mobile.pdf:pdf},
mendeley-groups = {Robotics/AMiRo},
title = {{A Low-Power Vision Processing Platform for Mobile Robots}},
year = {2011}
}
@article{Lang2011a,
author = {Lang, T},
file = {:home/tkorthals/Documents/Mendeley Desktop/Lang - 2011 - Planning and exploration in stochastic relational worlds.pdf:pdf},
mendeley-groups = {Vision/Tracking},
title = {{Planning and exploration in stochastic relational worlds}},
url = {http://www.diss.fu-berlin.de/diss/servlets/MCRFileNodeServlet/FUDISS{\_}derivate{\_}000000009596/thesis-server.pdf?hosts=local},
year = {2011}
}
@inproceedings{Lefevre2003,
abstract = {In this paper, we are dealing with color object tracking. We propose to use hidden Markov models in a different way as classical approaches. Indeed, we use these mathematical tools to model the object in the spatial domain rather than in the temporal domain. Besides in order to manage multidimensional (color) data, multidimensional hidden Markov models are involved. Object learning step is performed using the GHOSP algorithm whereas object tracking step is done by approximate object position prediction and then precise object position localisation. This last step can be seen as an object recognition problem and will be solved using a method based on the forward algorithm.},
author = {Lefevre, S. and Bouton, E. and Brouard, T. and Vincent, N.},
booktitle = {Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)},
doi = {10.1109/ICIP.2003.1247195},
file = {:home/tkorthals/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vincent - Unknown - A NEW WAY TO USE HIDDEN MARKOV MODELS FOR OBJECT TRACKING IN VIDEO SEQUENCES Laboratoire d ' Informatique , Unive.pdf:pdf},
isbn = {0-7803-7750-8},
issn = {1522-4880},
keywords = {Character generation,GHOSP algorithm,Hidden Markov models,Mathematical model,Motion estimation,Multidimensional systems,Object recognition,Pattern recognition,Random variables,Stochastic processes,Video sequences,color object tracking,forward algorithm,genetic algorithms,image colour analysis,image sequences,multidimensional data,object detection,object learning,object position localisation,object position prediction,spatial domain,video sequence},
mendeley-groups = {Vision/Tracking},
pages = {III--117--20},
publisher = {IEEE},
shorttitle = {Image Processing, 2003. ICIP 2003. Proceedings. 20},
title = {{A new way to use hidden Markov models for object tracking in video sequences}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1247195},
volume = {2},
year = {2003}
}
@article{Johnson2011,
author = {Johnson, Richard K.},
file = {:home/tkorthals/Documents/Mendeley Desktop/Johnson - 2011 - The Elements of MATLAB Style.pdf:pdf},
isbn = {9780521732581},
mendeley-groups = {Vision/Tracking},
title = {{The Elements of MATLAB Style}},
url = {http://medcontent.metapress.com/index/A65RM03P4874243N.pdf},
year = {2011}
}
@article{Al-khawaldah2010,
author = {Al-khawaldah, Mohammad and Badran, Omar and Al-adwan, Ibrahim and Technology, Engineering},
file = {:home/tkorthals/Documents/Mendeley Desktop/Al-khawaldah et al. - 2010 - Exploration algorithm technique for multi-robot.pdf:pdf},
keywords = {collaboration,exploration,robot,wall-following},
mendeley-groups = {Robotics/Exploration},
number = {September},
pages = {27--29},
title = {{Exploration algorithm technique for multi-robot}},
year = {2010}
}
@article{Yamauchi1999,
author = {Yamauchi, B. and Schultz, A. and Adams, W.},
doi = {10.1177/105971239900700204},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yamauchi, Schultz, Adams - 1999 - Integrating exploration and localization for mobile robots.pdf:pdf},
issn = {1059-7123},
journal = {Adaptive Behavior},
mendeley-groups = {Robotics/Exploration},
month = {mar},
number = {2},
pages = {217--229},
title = {{Integrating exploration and localization for mobile robots}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/105971239900700204 http://adb.sagepub.com/content/7/2/217.short},
volume = {7},
year = {1999}
}
@article{Malik2009,
author = {Malik, Andreas},
file = {:home/tkorthals/Documents/Mendeley Desktop/Malik - 2009 - Explorationsstrategien f{\"{u}}r Roboter in Rettungsszenarien.pdf:pdf},
mendeley-groups = {Robotics/Exploration},
title = {{Explorationsstrategien f{\"{u}}r Roboter in Rettungsszenarien}},
year = {2009}
}
@article{Freda2008,
author = {Freda, L. and Oriolo, G. and Vecchioli, F.},
doi = {10.1109/IROS.2008.4651143},
file = {:home/tkorthals/Documents/Mendeley Desktop/Freda, Oriolo, Vecchioli - 2008 - Sensor-based exploration for general robotic systems.pdf:pdf},
isbn = {978-1-4244-2057-5},
journal = {Intelligent Robots and Systems, {\ldots}},
keywords = {Autonomous Agents,Mapping,Path Planning for Manipulators},
mendeley-groups = {Robotics/Exploration},
month = {sep},
pages = {2157--2164},
publisher = {Ieee},
title = {{Sensor-based exploration for general robotic systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4651143 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4651143},
year = {2008}
}
@article{Ardo2007,
author = {Ardo, H and Astrom, K and Berthilsson, Rikard},
file = {:home/tkorthals/Documents/Mendeley Desktop/Ardo, Astrom, Berthilsson - 2007 - Real time viterbi optimization of hidden markov models for multi target tracking.pdf:pdf},
isbn = {0769527930},
journal = {Motion and Video Computing {\ldots}},
mendeley-groups = {Vision/Tracking},
title = {{Real time viterbi optimization of hidden markov models for multi target tracking}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4118798},
year = {2007}
}
@article{Schaul2011,
author = {Schaul, Tom and Sun, Yi and Wierstra, Daan and Gomez, Fausino and Schmidhuber, Jurgen},
doi = {10.1109/CEC.2011.5949772},
file = {:home/tkorthals/Documents/Mendeley Desktop/Schaul et al. - 2011 - Curiosity-driven optimization.pdf:pdf},
isbn = {978-1-4244-7834-7},
journal = {2011 IEEE Congress of Evolutionary Computation (CEC)},
mendeley-groups = {Robotics/Exploration},
month = {jun},
pages = {1343--1349},
publisher = {Ieee},
title = {{Curiosity-driven optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5949772},
year = {2011}
}
@article{Park2012,
author = {Park, DW and Kwon, Junseok and Lee, KM},
doi = {10.1109/CVPR.2012.6247898},
file = {:home/tkorthals/Documents/Mendeley Desktop/Park, Kwon, Lee - 2012 - Robust visual tracking using autoregressive hidden Markov Model.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
mendeley-groups = {Vision/Tracking},
month = {jun},
pages = {1964--1971},
publisher = {Ieee},
title = {{Robust visual tracking using autoregressive hidden Markov Model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247898},
year = {2012}
}
@article{Yamauchi1998,
address = {New York, New York, USA},
author = {Yamauchi, Brian},
doi = {10.1145/280765.280773},
file = {:home/tkorthals/Documents/Mendeley Desktop/Yamauchi - 1998 - Frontier-based exploration using multiple robots.pdf:pdf},
isbn = {0897919831},
journal = {Proceedings of the second international conference on {\ldots}},
mendeley-groups = {Robotics/Exploration},
pages = {47--53},
publisher = {ACM Press},
title = {{Frontier-based exploration using multiple robots}},
url = {http://portal.acm.org/citation.cfm?doid=280765.280773 http://dl.acm.org/citation.cfm?id=280773},
year = {1998}
}
@article{Digor2010,
author = {Digor, Elena and Birk, Andreas and N{\"{u}}chter, A},
file = {:home/tkorthals/Documents/Mendeley Desktop/Digor, Birk, N{\"{u}}chter - 2010 - Exploration strategies for a robot with a continously rotating 3D scanner.pdf:pdf},
journal = {{\ldots} , and Programming for Autonomous Robots},
mendeley-groups = {Robotics/Exploration},
title = {{Exploration strategies for a robot with a continously rotating 3D scanner}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-17319-6{\_}35},
year = {2010}
}
@article{Thrun2001,
author = {Thrun, Sebastian},
file = {:home/tkorthals/Documents/Mendeley Desktop/Thrun - 2001 - Is robotics going statistics The field of probabilistic robotics.pdf:pdf},
journal = {Communications of the ACM},
mendeley-groups = {Robotics},
pages = {1--8},
title = {{Is robotics going statistics? The field of probabilistic robotics}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.8332{\&}rep=rep1{\&}type=pdf},
year = {2001}
}
@article{Morlok2007,
author = {Morlok, Ryan and Gini, Maria},
file = {:home/tkorthals/Documents/Mendeley Desktop/Morlok, Gini - 2007 - Dispersing robots in an unknown environment.pdf:pdf},
journal = {Distributed Autonomous Robotic Systems 6},
keywords = {exploration,swarm},
mendeley-groups = {Robotics/Exploration},
mendeley-tags = {exploration,swarm},
title = {{Dispersing robots in an unknown environment}},
url = {http://link.springer.com/chapter/10.1007/978-4-431-35873-2{\_}25},
year = {2007}
}
